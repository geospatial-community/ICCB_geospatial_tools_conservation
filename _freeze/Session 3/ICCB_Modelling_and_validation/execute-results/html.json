{
  "hash": "4de35e07f46e55f603fef5bd0e35d1cb",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"ICCB Species distribution modelling\"\nauthor: \"Scott Forrest and Charlotte Patterson\"\ndate: \"2025-06-11\"\nexecute: \n  cache: false\n  warning: false\nbibliography: paperpile_references.bib\ntoc: true\nnumber-sections: false\nformat: \n  html:\n    self-contained: true\n    code-fold: show\n    code-tools: true\n    df-print: paged\n    code-line-numbers: true\n    code-overflow: scroll\n    fig-format: png\n    fig-dpi: 300\n  pdf:\n    geometry: \n      - top=30mm\n      - left=30mm\neditor: source\nabstract: |\n  In this script we are fitting species distribution models to the data of koalas (Phascolarctos cinereus) in the South-East Queensland (SEQ) region under current environmental conditions, which we will predict into future environmental conditions. Our modelling protocol follows these steps:\n  1. Load the koala presence data and environmental covariates.\n  2. Sample background points. \n  3. Select environmental covariates based on expert knowledge and correlation analysis.\n  4. Exploration of the koala presence and background data.\n  5. Fit a Generalised Linear Model (GLM) to the data based on current climatic conditions.\n  6. Fit a Random Forest Model to the data based on current climatic conditions.\n  7. Evaluate the model performance with spatial block cross validation. \n  8. Predict the model into future environmental conditions.\n  9. Summarise model uncertainty. \n---\n\n\n\n\n\n\nUp to date references can be downloaded from: https://paperpile.com/eb/EnPQSBmTeb \n\nWe wrote this script drawing on some of the following resources:\n\n-   Ecocommons Notebooks <https://www.ecocommons.org.au/notebooks/>\n-   Damaris Zurell's SDM Intro <https://damariszurell.github.io/SDM-Intro/>\n\n## Import packages\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# general R functions\nlibrary(tidyverse)\nlibrary(RColorBrewer)\n\n# for downloading species data\nlibrary(galah)\n\n# for general spatial operations\nlibrary(terra)\nlibrary(sf)\nlibrary(tidyterra)\n\n# for SDM analyses\nlibrary(predicts)\nlibrary(blockCV)\nlibrary(ecospat)\nlibrary(usdm)\nlibrary(precrec)\nlibrary(corrplot)\n```\n:::\n\n\n\n\n\n\n## Load South East Queensland (SEQ) boundary\n\nWe start by defining our study area, which is the South East Queensland (SEQ) region. In a previous session we used the Local Government Areas (LGA) shapefile to define the extent of SEQ.\n\nWhat we'll load is a polygon of our boundary which becomes our model domain.\n\nFor our coordinate reference system throughout, we'll be using GDA2020 / MGA zone 56, which is identified by the EPSG code 7856.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nSEQ_extent.vect <- vect(\"Data/Environmental_variables/seq_boundary.gpkg\")\n\n# Define an sf object as well (used later)\nSEQ_extent <- st_as_sf(SEQ_extent.vect, \n                        coords = c(\"x\", \"y\"), \n                        crs = 7856)\n\nplot(SEQ_extent.vect)\n```\n\n::: {.cell-output-display}\n![](ICCB_Modelling_and_validation_files/figure-html/unnamed-chunk-2-1.png)\n:::\n:::\n\n\n\n\n\n\n# Step 1. Load the koala presence data and environmental covariates.\n\nFirst, we're going to get some koala occurrence data. We will use the `galah` package to access the Atlas of Living Australia (ALA) data. The ALA is a great resource for Australian biodiversity data, and the `galah` package provides a convenient interface to access it.\n\nWe won't have time to explore these, but there are plenty of options for those using data outside of Australia. For example, the `rgbif` package provides access to the Global Biodiversity Information Facility (GBIF) data, and the `spocc` package provides access to a range of biodiversity data sources.\n\n### To cite the `galah` package\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Package citation\ncitation(package = \"galah\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTo cite galah in publications use:\n\n  Westgate M, Kellie D, Stevenson M, Newman P (2025). _galah:\n  Biodiversity Data from the GBIF Node Network_. R package version\n  2.1.1, <https://CRAN.R-project.org/package=galah>.\n\nA BibTeX entry for LaTeX users is\n\n  @Manual{,\n    title = {galah: Biodiversity Data from the GBIF Node Network},\n    author = {Martin Westgate and Dax Kellie and Matilda Stevenson and Peggy Newman},\n    year = {2025},\n    note = {R package version 2.1.1},\n    url = {https://CRAN.R-project.org/package=galah},\n  }\n```\n\n\n:::\n:::\n\n\n\n\n\n\n### Atlas of Living Australia using \"galah\" package\n\nTo access records from the ALA, you will need to be registered.\n\nThere are two registration options:\n\n1.  If you are affiliated with an Australian institution, you should be able to register for ALA through your institution. Find your institution in the list of institutions when you select 'Login' [on the ALA website](https://www.ala.org.au/). Follow the prompts to enter your institution email and password. If your institution is not listed, you will need to register for an ALA account.\n\n2.  If you are not affiliated with an Australian institution, you will need to register for an ALA account. You can do this by selecting 'Register' [on the ALA website](https://www.ala.org.au/). Follow the prompts to enter your email and password.\n\nOnce you're registered, you can set up your galah access configuration. This is a one-time setup that allows you to access the ALA data through the `galah` package. For now, we'll just use Scott's email address, but you should use your own email address once you've registered for an ALA account.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngalah_config(atlas = \"ALA\",\n             email = \"scott.forrest@hdr.qut.edu.au\"\n             )\n```\n:::\n\n\n\n\n\n\n### Download koala data from ALA\n\nWe're using a species name call with a state filter to identify all Presence-Only occurrence records of koala for Queensland.\n\nTo prevent calling from the ALA every time we run this script, we will save the data to a CSV file. You can uncomment the code below to download the data again if you need to.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# koala_occurrences <- galah_call() %>% \n#   galah_identify(\"Phascolarctos cinereus\") %>% \n#   galah_filter(\n#     stateProvince == \"Queensland\",\n#     occurrenceStatus == \"PRESENT\"\n#   ) %>% \n#   atlas_occurrences()\n\n# save the csv\n# write_csv(koala_occurrences, \"Data/Biological_records/koala_occurrences.csv\")\n\nkoala_occurrences <- read_csv(\"Data/Biological_records/koala_occurrences.csv\")\n```\n:::\n\n\n\n\n\n\nThis download takes a minute or so, and we end up with a dataframe of 93456 records of koala!\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnrow(koala_occurrences)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 93544\n```\n\n\n:::\n\n```{.r .cell-code}\nnames(koala_occurrences)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"recordID\"         \"scientificName\"   \"taxonConceptID\"   \"decimalLatitude\" \n[5] \"decimalLongitude\" \"eventDate\"        \"occurrenceStatus\" \"dataResourceName\"\n```\n\n\n:::\n:::\n\n\n\n\n\n\n### Cleaning koala data\n\nNot all data are created equal, and it's always important to spend some time examining and cleaning your species occurrence data before using it in a model. This is particularly relevant for us because we're using records collated into a database from a bunch of different sources. We don't have time to explore this today, but here's a few examples of things you might check at this stage and some functions / packages available to help:\n\n-   When downloading data from the ALA or directly from GBIF, you can filter for specific fields. For example, you can filter for records with a specific coordinate precision or quality, or remove those records older than a certain date. You can use the `galah_filter()` function for this.\n-   Check for duplicates in the data. You can use the `dplyr` package with functions like `distinct()`.\n-   Common issues like spatial outliers, taxonomic errors or coordinate errors are tested for with packages like: `spocc`, `CoordinateCleaner`, and `bdc`.\n-   Usually you would check that the CRS for the occurrences is the same as the shapefile. However, we know that the \\`galah' package operates in WGS84.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Check for missing values in decimalLongitude and decimalLatitude\npaste0(\"Number of NAs in 'longitude' \", sum(is.na(koala_occurrences$decimalLongitude)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Number of NAs in 'longitude' 215\"\n```\n\n\n:::\n\n```{.r .cell-code}\npaste0(\"Number of NAs in 'latitude' \", sum(is.na(koala_occurrences$decimalLatitude)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Number of NAs in 'latitude' 215\"\n```\n\n\n:::\n\n```{.r .cell-code}\nkoala_occ_sf <- koala_occurrences %>% \n  tidyr::drop_na(decimalLongitude, decimalLatitude) %>% # remove NA values\n  st_as_sf(coords = c(\"decimalLongitude\", \"decimalLatitude\"), \n           crs = 4326) %>%\n  st_transform(7856) # Transform to the same CRS as SEQ_extent\n```\n:::\n\n\n\n\n\n\n### Plot the koala data across Queensland\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load a shapefile for Queensland just for plotting\nqld_shp = st_read('Data/Environmental_variables/QLD_State_Mask.shp') %>% \n  st_transform(7856) # Transform to the same CRS as SEQ_extent\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `QLD_State_Mask' from data source \n  `/Users/scottforrest/Library/CloudStorage/OneDrive-QueenslandUniversityofTechnology/PhD - Scott Forrest/GIT/ICCB_geospatial_tools_conservation/Session 3/Data/Environmental_variables/QLD_State_Mask.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 1 feature and 1 field\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 137.9946 ymin: -29.17927 xmax: 153.5519 ymax: -9.219566\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n\n```{.r .cell-code}\n# Create a map using ggplot2\nggplot() +\n  geom_sf(data = qld_shp, color = \"black\") +\n  geom_sf(data = koala_occ_sf,\n             color = \"blue\", size = 0.5) + # Add points for occurrences\n  ggtitle(\"Koala occurrences across Queensland\") +             # Add title\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](ICCB_Modelling_and_validation_files/figure-html/unnamed-chunk-8-1.png)\n:::\n:::\n\n\n\n\n\n\n### Filter by SEQ region\n\nThis takes a minute or two.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkoala_occ_sf <- koala_occ_sf %>% \n  st_intersection(SEQ_extent) %>% # Mask to extent\n  distinct() # drop any duplicated records\n```\n:::\n\n\n\n\n\n\n### Plot the filtered koala data\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot() +\n  geom_sf(data = SEQ_extent, fill = \"purple3\", alpha = 0.5, color = \"black\", size = 0.2) +\n  geom_sf(data = koala_occ_sf,                                 # Add koala presence locations\n          aes(geometry = geometry),\n             color = \"blue\", size = 0.5) +                     # Add points for occurrences\n  ggtitle(\"Koala occurrences in South East Queensland\") +      # Add title\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](ICCB_Modelling_and_validation_files/figure-html/unnamed-chunk-10-1.png)\n:::\n:::\n\n\n\n\n\n\n# Step 2. Sample background points\n\nChoosing background points to sample the availability of different environmental conditions is an important step in presence-only modelling. These points are contrasted against environmental conditions where your species was found (the presences) to help the model learn what conditions are suitable for the species. Background selection is a critical step in presence-only SDMs. Choices reflect your understanding of your study species. There's lots of good discussion about approaches to background selection in the literature, and we recommend reading some of these papers to understand the implications of your choices.\n\nFor this tutorial, we will use random sampling of background points across the SEQ region to keep it simple.\n\nA few other approaches include:\n\n-   **Buffering**: Create a buffer around the presence points and sample points within that buffer. Figure from [Velazco et al.](https://sjevelazco.github.io/flexsdm/articles/v01_pre_modeling.html#background-and-pseudo-absence-sampling).\n\n[Buffered background locations](Figures/Buffered_Background.png)\n\n\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n\n\n-   **Minimum convex hull**: Create a minimum convex hull around the presence points and sample points within that hull. Figure from [Velazco et al.](https://sjevelazco.github.io/flexsdm/articles/v01_pre_modeling.html#background-and-pseudo-absence-sampling).\n\n[Minimum convex hull background locations](Figures/Minimum_convex_polygon_Background.png)\n\n\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n\n\n## Random background sampling\n\nWe need to load a template grid for creating background points. This matches the grid our covariates are on, which we'll load soon.\n\nWe're using a function from the `predicts` package for this.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndomain <- rast(\"Data/Environmental_variables/SEQ_current_bioclim.tif\")\n\n# Make a blank raster of all 1s of the same dimensions as our covariate grid\ndomain <- domain[[1]]\ndomain <- ifel(is.na(domain), NA, 1) # Set all values to 1 except for NA values (which are outside the SEQ extent\n\nnames(domain) <- \"SEQ_extent\"\n\nplot(domain, main = \"SEQ extent for background sampling\")\n```\n\n::: {.cell-output-display}\n![](ICCB_Modelling_and_validation_files/figure-html/unnamed-chunk-13-1.png)\n:::\n\n```{.r .cell-code}\n# Set the location and number of background points\n# The mask means that any NA (not SEQ) locations do not include background points\nbackground <- predicts::backgroundSample(mask = domain, \n                                         n = 2500)\n\n# Convert to terra SpatVector object\nbackground <- terra::vect(background[,1:2], crs = \"EPSG:7856\")\n\n# Convert background points (SpatVector) to data frame\nbackground_df <- as.data.frame(geom(background))\n\nkoala_occ.vect <- vect(koala_occ_sf)\n\n# Plot the presences (blue) and the background points (grey)\nggplot() +\n  geom_sf(data = SEQ_extent, fill = \"purple3\", alpha = 0.5, color = \"black\", size = 0.2) +\n  geom_spatvector(data = background,                           # Add koala presence locations\n             color = \"gray\", cex = 0.5) +               # Add points for occurrences\n  geom_spatvector(data = koala_occ.vect, \n                  aes(geometry = geometry), \n                  color = \"blue\", cex = 0.5) + # Add background points\n  ggtitle(\"Koala occurrences (blue) and background points (grey) in South East Queensland\") +      # Add title\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](ICCB_Modelling_and_validation_files/figure-html/unnamed-chunk-13-2.png)\n:::\n:::\n\n\n\n\n\n\n### Combine koala presence and background points as dataframes\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Make a dataframe of just x, y and presence\nkoala_occ_df <- koala_occ_sf %>%\n  dplyr::mutate(x = sf::st_coordinates(.)[,1],\n                y = sf::st_coordinates(.)[,2]) %>%\n\t\t\t\tst_drop_geometry() %>% \n  dplyr::select(x,y) %>% \n  mutate(Presence = 1)\n  \nhead(koala_occ_df)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"x\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"y\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Presence\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"522861.4\",\"2\":\"6951030\",\"3\":\"1\"},{\"1\":\"500098.7\",\"2\":\"6982060\",\"3\":\"1\"},{\"1\":\"495930.5\",\"2\":\"6981622\",\"3\":\"1\"},{\"1\":\"527833.8\",\"2\":\"6955310\",\"3\":\"1\"},{\"1\":\"510776.4\",\"2\":\"6955199\",\"3\":\"1\"},{\"1\":\"527933.4\",\"2\":\"6955294\",\"3\":\"1\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\nbackground_df <- background %>% \n  as.data.frame(geom = \"XY\") %>% \n  dplyr::select(x,y) %>% \n  mutate(Presence = 0)\n\nhead(background_df)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"x\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"y\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Presence\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"492450.8\",\"2\":\"7105286\",\"3\":\"0\",\"_rn_\":\"1\"},{\"1\":\"498041.7\",\"2\":\"7105286\",\"3\":\"0\",\"_rn_\":\"2\"},{\"1\":\"503632.6\",\"2\":\"7105286\",\"3\":\"0\",\"_rn_\":\"3\"},{\"1\":\"509223.5\",\"2\":\"7105286\",\"3\":\"0\",\"_rn_\":\"4\"},{\"1\":\"481268.9\",\"2\":\"7099695\",\"3\":\"0\",\"_rn_\":\"5\"},{\"1\":\"486859.8\",\"2\":\"7099695\",\"3\":\"0\",\"_rn_\":\"6\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\n# Combine to one dataframe\npr_bg <- rbind(koala_occ_df, background_df)\n```\n:::\n\n\n\n\n\n\n# Step 3. Environmental covariate selection\n\nFirst, we load the rasters describing the current environmental conditions. We did some pre-formatting of these rasters so they match the koala data in projection and extent.\n\nLayers were made available to us by the EcoCommons team and were created by Toombs and Ma (2025):\n\nToombs, N., and Ma S., 2025, A High-Resolution Dataset of 19 Bioclimatic Indices over Australia, Climate Projections and Services – Queensland Treasury, Brisbane, Queensland. \\[https://longpaddock.qld.gov.au/qld-future-climate/data-info/tern/\\]\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncovs_current <- rast(\"Data/Environmental_variables/SEQ_current_bioclim.tif\")\n\n\n# Define the BIOCLIM names for the raster layers\nlayer_names <- c(\n  \"BIO1_Annual_Mean_Temp\",\n  \"BIO2_Mean_Diurnal_Temp_Range\",\n  \"BIO3_Isothermality\",\n  \"BIO4_Temperature_Seasonality\",\n  \"BIO5_Max_Temp_Warmest_Month\",\n  \"BIO6_Min_Temp_Coldest_Month\",\n  \"BIO7_Temperature_Annual_Range\",\n  \"BIO8_Mean_Temp_Wettest_Quarter\",\n  \"BIO9_Mean_Temp_Driest_Quarter\",\n  \"BIO10_Mean_Temp_Warmest_Quarter\",\n  \"BIO11_Mean_Temp_Coldest_Quarter\",\n  \"BIO12_Annual_Precipitation\",\n  \"BIO13_Precip_Wettest_Month\",\n  \"BIO14_Precip_Driest_Month\",\n  \"BIO15_Precip_Seasonality\",\n  \"BIO16_Precip_Wettest_Quarter\",\n  \"BIO17_Precip_Driest_Quarter\",\n  \"BIO18_Precip_Warmest_Quarter\",\n  \"BIO19_Precip_Coldest_Quarter\")\n\nnames(covs_current) <- layer_names\n```\n:::\n\n\n\n\n\n\n### One approach: Narrow down potential covariates based on ecological or expert knowledge\n\nFor this example, we had advice from scientists at [CSIRO](https://www.csiro.au/en/) who conducted an expert elicitation to gather a set of potential covariates that are likely to be important for koalas.\n\nThis is an example of one approach for deciding what covariates are candidates for inclusion in your model. We use this expert knowledge to filter out the key bioclim variables.\n\nWe select the following:\n\n-   Bio5 : Max temp of the warmest month (mainly for the northern populations)\n-   Bio6 : Min temp of the coldest month (mainly for southern populations, which essentially excludes alpine regions)\n-   Bio12 : Annual Precipitation\n-   Bio15 : Precipitation seasonality (coefficient of variation).\n\n#### Plotting our four covariates from expert elicitation\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# select only the covariates we are using by their names\ncovs_current_expert <- subset(covs_current, \n                              names(covs_current) %in% c(\"BIO5_Max_Temp_Warmest_Month\",\n                                                         \"BIO6_Min_Temp_Coldest_Month\",\n                                                         \"BIO12_Annual_Precipitation\",\n                                                         \"BIO15_Precip_Seasonality\"))\n\nfor(i in 1:nlyr(covs_current_expert)) {\n  plot(covs_current_expert[[i]], main = names(covs_current_expert)[[i]])\n}\n```\n\n::: {.cell-output-display}\n![](ICCB_Modelling_and_validation_files/figure-html/unnamed-chunk-16-1.png)\n:::\n\n::: {.cell-output-display}\n![](ICCB_Modelling_and_validation_files/figure-html/unnamed-chunk-16-2.png)\n:::\n\n::: {.cell-output-display}\n![](ICCB_Modelling_and_validation_files/figure-html/unnamed-chunk-16-3.png)\n:::\n\n::: {.cell-output-display}\n![](ICCB_Modelling_and_validation_files/figure-html/unnamed-chunk-16-4.png)\n:::\n:::\n\n\n\n\n\n\n## Covariate to account for sampling bias\n\n### CHARLOTTE PLEASE CHECK PARAGRAPH, and add any relevant refs ###\n\nAs these data were collected from a wide number of sources, we have to consider whether any of the data, such as that which was opportunistically collected [@Kery2010-aa], might be biased towards areas of higher human activity. This is a common issue in species occurrence data and is typpically called smapling bias or preferential sampling, and occurs because areas that are more accessible or have higher human activity are more likely to be opportunistically sampled [@Conn2017-lh].\n\nThis means that if there are environmental variables that happen correlated with human activity (which is often the case, humans also select for environmental features), it will appear that these variables are more influential than they actually are, because we associating that environmental covariate with 'more' presence records.\n\nThere are several different ways to account for this when modelling [@Pennino2019-sy; @Makinen2024-th; @Dubos2022-ye]. Some of the common approaches include:\n\n- Sampling pseudo-absences where there are more points where there is higher sampling effort\n- Using a covariate to attempt to capture the sampling bias, such as human population density or distance to roads\n- Using a model or model structure that explicitly accounts for sampling bias, such as including a spatial random effect\n\nIn our case, we have will use a covariate for the [Global Human Footprint Index (HFP)](https://hub.arcgis.com/maps/65518e782be04e7db31de65d53d591a9/about) , which is a measure of human impact on the environment. This is a raster layer with continuous (percentage values) that we will use to account for sampling bias in our model.\n\nYou will be able to see Brisbane as the largest area of human footprint, Moreton Bay to the right, the Gold Coast to the south, the Sunshine Coast to the north, and Toowoomba to the west (about 2 hours drive).\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhuman_footprint <- rast(\"Data/Environmental_variables/cost_hfp2013.tif\")\nnames(human_footprint) <- \"human_footprint\"\n\n# Update CRS to EPSG:7856 (GDA2020 / MGA zone 56)\nhuman_footprint <- terra::project(human_footprint, \"EPSG:7856\")\n\n# Resample to match the extent and resolution of the covariates\nhuman_footprint <- resample(human_footprint, covs_current_expert, method = \"bilinear\")\n\n# Mask to SEQ extent\nhuman_footprint <- terra::mask(human_footprint, covs_current_expert[[1]]) \n\nplot(human_footprint, main = \"Human Footprint Index\")\n```\n\n::: {.cell-output-display}\n![](ICCB_Modelling_and_validation_files/figure-html/unnamed-chunk-17-1.png)\n:::\n:::\n\n\n\n\n\n\nAlthough this isn't a thorough comparison, we can see that this variable is correlated with the presence of koalas.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(human_footprint, main = \"Human Footprint Index\")\npoints(koala_occ_sf, col = \"red\", alpha = 0.1, pch = 20, cex = 0.5)\n```\n\n::: {.cell-output-display}\n![](ICCB_Modelling_and_validation_files/figure-html/unnamed-chunk-18-1.png)\n:::\n:::\n\n\n\n\n\n\nYou would want to put some more thought into your own study and the best way to account for sampling bias, but in our case we will try using the human footprint index as a covariate in our model, and assess how our predictions change.\n\n### Add the human footprint layer to our covariates\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncovs_current_expert_HF <- c(covs_current_expert, human_footprint)\nplot(covs_current_expert_HF)\n```\n\n::: {.cell-output-display}\n![](ICCB_Modelling_and_validation_files/figure-html/unnamed-chunk-19-1.png)\n:::\n:::\n\n\n\n\n\n\n### Extract environmental covariate values from presence and background locations (training locations)\n\nThis will create a dataframe where each row is a koala presence or background location and each column is a value for our four bioclimatic variables at that location.\n\nWe use a function from `terra` for this.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# this will give us the covariate values for each presence and background point\nPB_covs <- terra::extract(\n  x = covs_current_expert_HF,   # Raster with environmental variables\n  y = pr_bg[, c(\"x\", \"y\")],  # Dataframe with x, y and presence\n  ID = FALSE                 # Don't return an ID column for each location\n)\n\ntrain_PB_covs <- cbind(pr_bg, PB_covs) # Combine the presence column with the covariate values\n\n# drop any NAs\ntrain_PB_covs <- train_PB_covs %>% drop_na()\n\nhead(train_PB_covs)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"x\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"y\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Presence\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"BIO5_Max_Temp_Warmest_Month\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"BIO6_Min_Temp_Coldest_Month\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"BIO12_Annual_Precipitation\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"BIO15_Precip_Seasonality\"],\"name\":[7],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"human_footprint\"],\"name\":[8],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"522861.4\",\"2\":\"6951030\",\"3\":\"1\",\"4\":\"29.86404\",\"5\":\"9.045586\",\"6\":\"1231.603\",\"7\":\"95.31358\",\"8\":\"27.52487\",\"_rn_\":\"1\"},{\"1\":\"500098.7\",\"2\":\"6982060\",\"3\":\"1\",\"4\":\"30.44493\",\"5\":\"8.930631\",\"6\":\"1174.339\",\"7\":\"99.00175\",\"8\":\"37.59798\",\"_rn_\":\"2\"},{\"1\":\"495930.5\",\"2\":\"6981622\",\"3\":\"1\",\"4\":\"30.44493\",\"5\":\"8.930631\",\"6\":\"1174.339\",\"7\":\"99.00175\",\"8\":\"37.59798\",\"_rn_\":\"3\"},{\"1\":\"527833.8\",\"2\":\"6955310\",\"3\":\"1\",\"4\":\"29.71574\",\"5\":\"9.618237\",\"6\":\"1231.261\",\"7\":\"91.62077\",\"8\":\"36.49710\",\"_rn_\":\"4\"},{\"1\":\"510776.4\",\"2\":\"6955199\",\"3\":\"1\",\"4\":\"30.43131\",\"5\":\"8.725674\",\"6\":\"1076.065\",\"7\":\"98.15495\",\"8\":\"37.08822\",\"_rn_\":\"5\"},{\"1\":\"527933.4\",\"2\":\"6955294\",\"3\":\"1\",\"4\":\"29.71574\",\"5\":\"9.618237\",\"6\":\"1231.261\",\"7\":\"91.62077\",\"8\":\"36.49710\",\"_rn_\":\"6\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\n\n\n## Thin the koala presence points (for tutorial only)\n\nWe now thin the presences to reduce the number of points to a manageable size for plotting and modelling. *This is just for the purpose of this tutorial*, and is done here to make the tutorial run faster and to make the plots clearer. There are some reasons you would want to thin (such as bias correction), but you would want to carefully consider whether this is appropriate for your modelling.\n\nWe only thin the presence points as the background points are already limited by the number of cells in the SEQ region.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain_PB_covs_pres <- train_PB_covs %>% filter(Presence == 1)\ntrain_PB_covs_bg <- train_PB_covs %>% filter(Presence == 0)\n\n# Thin the presences - 10000 presence points\ntrain_PB_covs_pres_thinned <- train_PB_covs_pres[sample(nrow(train_PB_covs_pres), 10000), ]\n\n# Combine back into both presence and background\ntrain_PB_covs_thinned <- rbind(train_PB_covs_pres_thinned, train_PB_covs_bg, make.row.names = FALSE)\n```\n:::\n\n\n\n\n\n\n## Check correlation and multicollinearity of covariates\n\nAlthough we've narrowed down our covariates already based on discussion with experts, there's a chance that our remaining variables might be correlated or collinear. This would cause issues with models, particularly because we're hoping to predict our model into the future. We're going to inspect our covariates for signs of correlation and multicolinearity.\n\nThere are several different methods for creating correlation plots, we just show two.\n\n### Correlation plot from the ecospat package\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# use the dataframe we just created, dropping the x, y, and presence columns (1-3)\necospat::ecospat.cor.plot(train_PB_covs_thinned[, -1:-3])\n```\n\n::: {.cell-output-display}\n![](ICCB_Modelling_and_validation_files/figure-html/unnamed-chunk-22-1.png)\n:::\n:::\n\n\n\n\n\n\nWhat the correlation test plot suggests is that we have some correlated covariates. Particularly our Bio6 and Bio12.\n\nOften a rule of thumb of \\~ 0.7 correlation is used to decide what a 'too correlated' covariate pair are (REF). In practice, it's important to think carefully before dropping covariates.\n\n### Variance Inflation Factor (VIF)\n\nIf you find corrplot is hard for you to use to make decisions, we can also look at the Variance Inflation Factor (VIF). VIF is another statistical measure used to detect multicollinearity in a set of explanatory (independent) variables in a regression model.\n\n**Interpretation:**\n\n-   VIF = 1: No correlation\n-   VIF \\> 1 and \\<= 5: Moderate correlation; may not require corrective action.\n-   VIF \\> 5: Indicates high correlation. Multicollinearity may be problematic, and further investigation is recommended.\n-   VIF \\> 10: Strong multicollinearity. The variable is highly collinear with others, and steps should be taken to address this.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nusdm::vifstep(covs_current_expert_HF) # Variance Inflation Factor and test for multicollinearity\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNo variable from the 5 input variables has collinearity problem. \n\nThe linear correlation coefficients ranges between: \nmin correlation ( BIO15_Precip_Seasonality ~ BIO6_Min_Temp_Coldest_Month ):  -0.1420642 \nmax correlation ( BIO12_Annual_Precipitation ~ BIO6_Min_Temp_Coldest_Month ):  0.8762638 \n\n---------- VIFs of the remained variables -------- \n                    Variables      VIF\n1 BIO5_Max_Temp_Warmest_Month 2.658798\n2 BIO6_Min_Temp_Coldest_Month 5.916991\n3  BIO12_Annual_Precipitation 7.552088\n4    BIO15_Precip_Seasonality 1.330505\n5             human_footprint 1.551557\n```\n\n\n:::\n:::\n\n\n\n\n\n\n# Step 4. Exploration of the koala presence and background data\n\nIt is good practice to assess where in the environmental space the presence and background points are located. This can help to identify if there are any potential issues with the data, such as a lack of background points in certain areas of environmental space. It's also a good way to have a first look at any patterns in the species data and the environmental covariates.\n\n::: panel-tabset\n\n## Bio5 Max. temperature warmest month\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot() +\n  geom_density(data = train_PB_covs_thinned,\n               aes(x = .data[[\"BIO5_Max_Temp_Warmest_Month\"]], fill = as.factor(Presence)),\n               alpha = 0.5,\n               bw = 0.25) + # we can try different bandwidth values to smooth the densities\n  theme_bw() +\n  labs(title = \"BIO5_Max_Temp_Warmest_Month\",\n       fill = \"Presence\") +\n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](ICCB_Modelling_and_validation_files/figure-html/unnamed-chunk-24-1.png)\n:::\n:::\n\n\n\n\n\n\n## Bio6 Min. temperature coldest month\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot() +\n          geom_density(data = train_PB_covs_thinned,\n                       aes(x = .data[[\"BIO6_Min_Temp_Coldest_Month\"]], fill = as.factor(Presence)),\n               alpha = 0.5,\n               bw = 0.25) + # we can try different bandwidth values to smooth the densities\n    theme_bw() +\n    labs(title = \"BIO6_Min_Temp_Coldest_Month\",\n       fill = \"Presence\") +\n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](ICCB_Modelling_and_validation_files/figure-html/unnamed-chunk-25-1.png)\n:::\n:::\n\n\n\n\n\n\n## Bio12 Annual precipitation\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot() +\n          geom_density(data = train_PB_covs_thinned,\n                       aes(x = .data[[\"BIO12_Annual_Precipitation\"]], fill = as.factor(Presence)),\n               alpha = 0.5,\n               bw = 50) + # we can try different bandwidth values to smooth the densities\n    theme_bw() +\n    labs(title = \"BIO12_Annual_Precipitation\",\n       fill = \"Presence\") +\n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](ICCB_Modelling_and_validation_files/figure-html/unnamed-chunk-26-1.png)\n:::\n:::\n\n\n\n\n\n\n## Bio15 Precipitation seasonality\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot() +\n          geom_density(data = train_PB_covs_thinned,\n                       aes(x = .data[[\"BIO15_Precip_Seasonality\"]], fill = as.factor(Presence)),\n               alpha = 0.5,\n               bw = 1) + # we can try different bandwidth values to smooth the densities\n    theme_bw() +\n    labs(title = \"BIO15_Precip_Seasonality\",\n       fill = \"Presence\") +\n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](ICCB_Modelling_and_validation_files/figure-html/unnamed-chunk-27-1.png)\n:::\n:::\n\n\n\n\n\n:::\n\n## Scaling the covariates\n\nIt is common to scale the covariates before fitting a model. This is because some models, such as Generalised Linear Models (GLMs), can be sensitive to the scale of the covariates. Scaling the covariates can also make the coefficients more interpretable comparable, as they are now on similar scales to each other.\n\nA typical scaling approach is to subtract the mean and divide by the standard deviation of each covariate, which is also known as z-scaling, and after this operation, all covariates will have a mean of 0 and a standard deviation of 1.\n\nWe can use base R to scale the covariates, and the default is to centre (subtract the mean) and scale (divide by the standard deviation).\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# pull out just the covariate values from the dataframe\ncovariate_values <- train_PB_covs_thinned[, -1:-3]\n\n# scale the covariates - returns a matrix\nscaled_covariates <- base::scale(covariate_values, \n                                 center = TRUE, \n                                 scale = TRUE)\n\n# convert back to a dataframe (and remove row names)\nscaled_covariates_df <- data.frame(scaled_covariates)\n\nhead(scaled_covariates_df)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"BIO5_Max_Temp_Warmest_Month\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"BIO6_Min_Temp_Coldest_Month\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"BIO12_Annual_Precipitation\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"BIO15_Precip_Seasonality\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"human_footprint\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"-0.51043836\",\"2\":\"0.5952684\",\"3\":\"0.1405271\",\"4\":\"-0.2327469\",\"5\":\"0.56344168\",\"_rn_\":\"1\"},{\"1\":\"-0.58598094\",\"2\":\"0.8693514\",\"3\":\"0.6869213\",\"4\":\"-1.9141568\",\"5\":\"-0.82400209\",\"_rn_\":\"2\"},{\"1\":\"-1.00805490\",\"2\":\"0.7748346\",\"3\":\"1.9430944\",\"4\":\"-0.9726051\",\"5\":\"0.02750393\",\"_rn_\":\"3\"},{\"1\":\"-0.43082990\",\"2\":\"0.7556031\",\"3\":\"0.6600307\",\"4\":\"-1.3140508\",\"5\":\"0.32458576\",\"_rn_\":\"4\"},{\"1\":\"-0.66800637\",\"2\":\"0.7040912\",\"3\":\"0.4654736\",\"4\":\"-0.9796623\",\"5\":\"0.24385894\",\"_rn_\":\"5\"},{\"1\":\"-0.07496118\",\"2\":\"0.4704655\",\"3\":\"0.1248596\",\"4\":\"1.0110001\",\"5\":\"0.88406239\",\"_rn_\":\"6\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\n# Add the presence column back to the scaled covariates\ntrain_PB_covs_thinned_scaled <- cbind(train_PB_covs_thinned[, 1:3], scaled_covariates_df)\n```\n:::\n\n\n\n\n\n\nThe scaling operation also returns the particular scaling values that were used, which is helpful for generating predictions later on. We can access these using the attributes of the returned dataframe. We only need the scaling factor, as we will rescale the coefficients before generating predictions.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get the attributes of the scaled covariates\nscaled_attributes <- attributes(scaled_covariates)\nscaled_attributes$`scaled:scale` # the SD/scaling factor of each covariate\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nBIO5_Max_Temp_Warmest_Month BIO6_Min_Temp_Coldest_Month \n                  0.9809104                   1.7530776 \n BIO12_Annual_Precipitation    BIO15_Precip_Seasonality \n                228.2151437                   3.2637999 \n            human_footprint \n                 11.1026101 \n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n# Step 5. Fit a model: A generalised linear model (GLM)\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Make a folder to save outputs\ndir.create(\"Outputs/GLM_outputs\", showWarnings = F)\n```\n:::\n\n\n\n\n\n\n## Null model\n\nNull model: no explanatory variables or predictors are included.\n\nIt is always helpful to create a null model as a benchmark to assess how the inclusion of explanatory variables improves the model.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit a null model with only the intercept\nnull_model <- glm(Presence ~ 1,\n                  data = train_PB_covs_thinned_scaled,\n                  family = binomial(link = \"logit\"))\n\n# Check the model results\nsummary(null_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = Presence ~ 1, family = binomial(link = \"logit\"), \n    data = train_PB_covs_thinned_scaled)\n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  2.10046    0.03028   69.37   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 7734  on 11223  degrees of freedom\nResidual deviance: 7734  on 11223  degrees of freedom\nAIC: 7736\n\nNumber of Fisher Scoring iterations: 4\n```\n\n\n:::\n:::\n\n\n\n\n\n\n## GLM - expert variables with linear terms\n\nIn this model, we include linear terms for the covariates. You can also do things like add quadratic terms to account for non-linear relationships between the predictors and the response variable. This increases the complexity of the model and allows for more flexibility in fitting the data.\n\nYou can also try fitting the model with and without the scaled covariates. The z- and p-values of each covariate should be the same (but not for the intercept and centering the covariates affects that), as well as the AIC.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglm_model <- glm(Presence ~\n                     BIO5_Max_Temp_Warmest_Month +\n                     BIO6_Min_Temp_Coldest_Month +\n                     BIO12_Annual_Precipitation +\n                     BIO15_Precip_Seasonality +\n                     human_footprint,\n                   data=train_PB_covs_thinned_scaled,\n                   family = binomial(link = \"logit\"))\n\n# Check the model results\nsummary(glm_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = Presence ~ BIO5_Max_Temp_Warmest_Month + BIO6_Min_Temp_Coldest_Month + \n    BIO12_Annual_Precipitation + BIO15_Precip_Seasonality + human_footprint, \n    family = binomial(link = \"logit\"), data = train_PB_covs_thinned_scaled)\n\nCoefficients:\n                            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)                  3.50063    0.07449  46.996  < 2e-16 ***\nBIO5_Max_Temp_Warmest_Month -0.42735    0.05567  -7.676 1.64e-14 ***\nBIO6_Min_Temp_Coldest_Month  0.42248    0.07457   5.665 1.47e-08 ***\nBIO12_Annual_Precipitation  -0.07054    0.07762  -0.909    0.363    \nBIO15_Precip_Seasonality     0.69618    0.04488  15.511  < 2e-16 ***\nhuman_footprint              1.39543    0.06765  20.628  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 7734.0  on 11223  degrees of freedom\nResidual deviance: 4458.5  on 11218  degrees of freedom\nAIC: 4470.5\n\nNumber of Fisher Scoring iterations: 7\n```\n\n\n:::\n:::\n\n\n\n\n\n\n## Model effect evaluation\n\nHere we use a function presented in an EcoCommons Australia notebook to evaluate the model performance. The notebook can be found on their GitHub: https://github.com/EcoCommonsAustralia/notebooks/tree/main/notebooks.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# Function to plot effect size graph\nplot_effect_size <- function(glm_model) {\n  # Check if required libraries are installed\n  if (!requireNamespace(\"ggplot2\", quietly = TRUE)) {\n    stop(\"Please install the 'ggplot2' package to use this function.\")\n  }\n  library(ggplot2)\n\n  # Extract effect sizes (coefficients) from the model\n  coefs <- summary(glm_model)$coefficients\n  effect_sizes <- data.frame(\n    Variable = rownames(coefs)[-1],  # Exclude the intercept\n    Effect_Size = coefs[-1, \"Estimate\"],\n    Std_Error = coefs[-1, \"Std. Error\"]\n  )\n\n  # Sort by effect size\n  effect_sizes <- effect_sizes[order(-abs(effect_sizes$Effect_Size)), ]\n\n  # Plot the effect sizes with error bars\n  ggplot(effect_sizes, aes(x = reorder(Variable, Effect_Size), y = Effect_Size)) +\n    geom_hline(yintercept = 0, linetype = \"dashed\", color = \"black\", alpha = 0.5) +\n    geom_point(stat = \"identity\", colour = \"#11aa96\") +\n    geom_errorbar(aes(ymin = Effect_Size - Std_Error, ymax = Effect_Size + Std_Error), \n                  colour = \"#11aa96\", width = 0.1) +\n    coord_flip() +\n    labs(\n      title = \"Effect Sizes of Variables\",\n      x = \"Variable\",\n      y = \"Effect Size (Coefficient Estimate)\"\n    ) +\n    theme_bw()\n}\n```\n:::\n\n\n\n\n\n\nRun the function on the covariates used in the model.\n\nInterestingly, the human footprint index has the largest effect size, followed by the annual precipitation and the minimum temperature of the coldest month, both of which were positive. The maximum temperature of the warmest month has a negative coefficient, which suggests that koalas are less likely to be found in areas with higher temperatures during the warmest month.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_effect_size(glm_model)\n```\n\n::: {.cell-output-display}\n![](ICCB_Modelling_and_validation_files/figure-html/unnamed-chunk-34-1.png)\n:::\n:::\n\n\n\n\n\n\n## Response curves\n\nAgain, we can use a function from the EcoCommons notebook to plot the response curves from the model.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nplot_species_response <- function(glm_model, predictors, data) {\n  # Check if required libraries are installed\n  if (!requireNamespace(\"ggplot2\", quietly = TRUE) || !requireNamespace(\"gridExtra\", quietly = TRUE)) {\n    stop(\"Please install the 'ggplot2' and 'gridExtra' packages to use this function.\")\n  }\n  library(ggplot2)\n  library(gridExtra)\n\n  # Create empty list to store response plots\n  response_plots <- list()\n\n  # Loop through each predictor variable\n  for (predictor in predictors) {\n    # Create new data frame to vary predictor while keeping others constant\n    pred_range <- seq(\n      min(data[[predictor]], na.rm = TRUE),\n      max(data[[predictor]], na.rm = TRUE),\n      length.out = 100\n    )\n    const_data <- data[1, , drop = FALSE]  # Use first row to keep other predictors constant\n    response_data <- const_data[rep(1, 100), ]  # Duplicate the row\n    response_data[[predictor]] <- pred_range\n\n    # Predict probabilities\n    predicted_response <- predict(glm_model, newdata = response_data, type = \"response\")\n\n    # Create data frame for plotting\n    plot_data <- data.frame(\n      Predictor_Value = pred_range,\n      Predicted_Probability = predicted_response\n    )\n\n    # Add presence and absence data\n    presence_absence_data <- data.frame(\n      Predictor_Value = data[[predictor]],\n      Presence_Absence = data$Presence\n    )\n\n    # Generate the response plot\n    p <- ggplot() +\n\n      geom_line(data = plot_data,\n                aes(x = Predictor_Value, y = Predicted_Probability),\n                color = \"#61c6fa\", linewidth = 1) +\n\n      geom_point(data = presence_absence_data[presence_absence_data$Presence_Absence == 1, ],\n                 aes(x = Predictor_Value, y = Presence_Absence),\n                 color = \"#11aa96\", alpha = 0.2) +\n\n      geom_point(data = presence_absence_data[presence_absence_data$Presence_Absence == 0, ],\n                 aes(x = Predictor_Value, y = Presence_Absence),\n                 color = \"#f6aa70\", alpha = 0.2) +\n\n      labs(x = predictor, y = NULL) +\n      theme_bw() +\n      theme(axis.title.y = element_blank())\n\n    # Store the plot in the list\n    response_plots[[predictor]] <- p\n  }\n\n  # Arrange all plots in one combined plot with a single shared y-axis label\n  grid.arrange(\n    grobs = response_plots,\n    ncol = 3,\n    left = \"Predicted Probability / Presence-Absence\"\n  )\n}\n```\n:::\n\n\n\n\n\n\n### Plot the response curves\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# get the names of the covariates in the model (drop the intercept)\npredictors <- names(glm_model$coefficients)[-1]\n\n# Plot the response curves for the predictors in the model\nplot_species_response(glm_model, predictors, train_PB_covs_thinned_scaled)\n```\n\n::: {.cell-output-display}\n![](ICCB_Modelling_and_validation_files/figure-html/unnamed-chunk-36-1.png)\n:::\n:::\n\n\n\n\n\n\n### Scale the raster layers with the same scaling as the covariates\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Scale your prediction rasters using the same scaling parameters\ncovs_current_expert_HF_scaled <- scale(covs_current_expert_HF, \n                                   center = attr(scaled_covariates, \"scaled:center\"),\n                                   scale = attr(scaled_covariates, \"scaled:scale\"))\n\n# plot to check the scaling worked\nplot(covs_current_expert_HF_scaled)\n```\n\n::: {.cell-output-display}\n![](ICCB_Modelling_and_validation_files/figure-html/unnamed-chunk-37-1.png)\n:::\n:::\n\n\n\n\n\n\n## GLM predictions to current environment\n\n### Model 1\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Predict the presence probability across the entire raster extent\npredicted_current_biased <- predicts::predict(covs_current_expert_HF_scaled, glm_model, type = \"response\")\n\n# Plot the species distribution raster\nplot(\n  predicted_current_biased,\n  range = c(0, 1),  # Set min and max values for the color scale\n  main = \"Climatic Suitability of Koalas in SEQ (biased)\"\n)\n```\n\n::: {.cell-output-display}\n![](ICCB_Modelling_and_validation_files/figure-html/unnamed-chunk-38-1.png)\n:::\n:::\n\n\n\n\n\n\n## Accounting for the sampling bias\n\nWhat we did above did not account for the sampling bias, as the predictions we generated maintained the bias process. We need to instead set the human footprint index to a constant value across the entire extent, which represents if the process that produces the bias is the same everywhere.\n\nThe approach that we've taken is not perfect, and would require some thinking and investigation, but it illustrates the potential impact of sampling bias and how you might account for it.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# pull out the scaled human footprint index layer\nconstant_HF <- covs_current_expert_HF_scaled[[5]]\n\n# Set the human footprint index to a constant value across the entire extent\n# Mean value of the human footprint index\nconstant_HF[] <- mean(constant_HF[], na.rm = TRUE)\n# mask to the extent of the covariates\nconstant_HF <- terra::mask(constant_HF, covs_current_expert_HF_scaled[[5]])\n\n# add the constant human footprint back into the raster layers\ncovs_current_expert_constHF_scaled <- c(covs_current_expert_HF_scaled[[1:4]], constant_HF)\n\n# check the new human footprint layer\nplot(covs_current_expert_constHF_scaled)\n```\n\n::: {.cell-output-display}\n![](ICCB_Modelling_and_validation_files/figure-html/unnamed-chunk-39-1.png)\n:::\n:::\n\n\n\n\n\n\nGenerate predictions with the constant human footprint layer\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Predict the presence probability across the entire raster extent\npredicted_current <- predicts::predict(covs_current_expert_constHF_scaled, glm_model, type = \"response\")\n\n# Plot the species distribution raster\nplot(\n  predicted_current,\n  range = c(0, 1),  # Set min and max values for the color scale\n  main = \"Climatic Suitability of Koalas in SEQ\"\n)\n```\n\n::: {.cell-output-display}\n![](ICCB_Modelling_and_validation_files/figure-html/unnamed-chunk-40-1.png)\n:::\n:::\n\n\n\n\n\n\n# Model evaluation with spatial block cross-validation\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Convert training data to sf\ntrain_PB_covs_thinned_sf <- st_as_sf(train_PB_covs_thinned[, c(\"x\", \"y\", \"Presence\")], coords = c(\"x\", \"y\"), crs = \"EPSG:7856\")\n\n# Generate spatial blocks\nspblock <- cv_spatial(x = train_PB_covs_thinned_sf,\n                      column = \"Presence\",\n                      r = NULL,\n                      size = 50000, # Size of the blocks in metres\n                      k = 5,\n                      hexagon = TRUE,\n                      selection = \"random\",\n                      iteration = 100, # to find evenly-dispersed folds\n                      biomod2 = FALSE,\n                      progress = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  train_0 train_1 test_0 test_1\n1     902    5032    322   4968\n2     986    8089    238   1911\n3    1002    8079    222   1921\n4    1003    9339    221    661\n5    1003    9461    221    539\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](ICCB_Modelling_and_validation_files/figure-html/unnamed-chunk-41-1.png)\n:::\n\n```{.r .cell-code}\ncv_plot(cv = spblock,\n        x = train_PB_covs_thinned_sf,\n        points_alpha = 0.5,\n        nrow = 2)\n```\n\n::: {.cell-output-display}\n![](ICCB_Modelling_and_validation_files/figure-html/unnamed-chunk-41-2.png)\n:::\n\n```{.r .cell-code}\n# Extract the folds to save\nspfolds <- spblock$folds_list\n\n# We now have a list of 5 folds, where the first object is the training data, and the second is the testing data\nstr(spfolds)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nList of 5\n $ :List of 2\n  ..$ : int [1:5934] 10641 10734 10736 10733 10639 10685 10638 10687 10595 10688 ...\n  ..$ : int [1:5290] 11101 10977 10973 11066 10832 10931 10877 11067 11065 10880 ...\n $ :List of 2\n  ..$ : int [1:9075] 10641 10734 10736 10733 10639 10685 10638 10687 10595 10688 ...\n  ..$ : int [1:2149] 6972 10414 10352 10322 10483 10351 10386 10324 6471 10293 ...\n $ :List of 2\n  ..$ : int [1:9081] 10641 10734 10736 10733 10639 10685 10638 10687 10595 10688 ...\n  ..$ : int [1:2143] 11165 11159 11133 1095 11160 11136 11161 11134 11164 11135 ...\n $ :List of 2\n  ..$ : int [1:10342] 10641 10734 10736 10733 10639 10685 10638 10687 10595 10688 ...\n  ..$ : int [1:882] 10990 10850 10897 11038 10942 11036 11078 10853 10993 11042 ...\n $ :List of 2\n  ..$ : int [1:10464] 11101 10977 10973 11066 10832 10931 10877 11067 11065 10880 ...\n  ..$ : int [1:760] 10641 10734 10736 10733 10639 10685 10638 10687 10595 10688 ...\n```\n\n\n:::\n:::\n\n\n\n\n\n\n## Run the model for every fold and evaluate\n\n### Model evaluation - metrics\n\nTypically, it helps to evaluate your model with several metrics that describe different features of model performance and prediction. Here, we define a function to feed in a model prediction and calculate several evaluation metrics.\n\nThe metrics are:\n\n**Area under the receiver operating characteristic curve (AUC ROC)**\n\n- Higher values of this (closer to 1) suggest a model is good at distinguishing presence points from the background.\n\n**Continuous boyce index**\n\n- Higher values of this (closer to 1) suggest a model is good at predicting higher suitability at spots where there were presences.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Start a dataframe to save results\neval_df <- data.frame(fold = numeric(),\n                      ROC = numeric(),\n                      boyce = numeric())\n\nfor(f in seq_along(spfolds)) {\n\n  # Subset the training and testing data (spatial cross validation) (for the fth fold)\n\n  train_PB_covs_scv <- train_PB_covs_thinned[spfolds[[f]][[1]], ]\n  test_PB_covs_scv <- train_PB_covs_thinned[spfolds[[f]][[2]], ]\n\n  glm_model_fold <- glm(Presence ~\n                          BIO5_Max_Temp_Warmest_Month +\n                          BIO6_Min_Temp_Coldest_Month +\n                          BIO12_Annual_Precipitation +\n                          BIO15_Precip_Seasonality +\n                          human_footprint,\n                        data=train_PB_covs_scv,\n                        family = binomial(link = \"logit\"))\n\n    # Predict to the testing data of fold f\n  test_PB_covs_scv$pred <- predict(glm_model_fold, newdata = test_PB_covs_scv, type = \"response\")\n\n  # Evaluate prediction on test set\n  ROC = precrec::auc(precrec::evalmod(scores = test_PB_covs_scv$pred, labels = test_PB_covs_scv$Presence))[1,4]\n\n  boyce = ecospat::ecospat.boyce(fit = test_PB_covs_scv$pred,\n                                 obs = test_PB_covs_scv$pred[which(test_PB_covs_scv$Presence==1)],\n                                 nclass = 0, # Calculate continuous index\n                                 method = \"pearson\",\n                                 PEplot = F)[[\"cor\"]]\n\n  # Add results to dataframe\n  eval_df <- eval_df %>% add_row(fold = f, ROC = ROC, boyce = boyce)\n\n}\n```\n:::\n\n\n\n\n\n\n### Summarise the evaluation metrics\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Mean AUC & boyce\neval_df %>%\n  summarise(mean_AUC = mean(ROC),\n            mean_boyce = mean(boyce),\n            sd_AUC = sd(ROC),\n            sd_boyce = sd(boyce))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"mean_AUC\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"mean_boyce\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"sd_AUC\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"sd_boyce\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"0.8453582\",\"2\":\"0.8802\",\"3\":\"0.109771\",\"4\":\"0.06404061\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\n\n\n# Make predictions to future climates\n\n## Load future environmental data\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncovs_future_SSP370 <- rast(\"Data/Environmental_variables/SEQ_future_bioclim.2090.SSP370.tif\")\nnames(covs_future_SSP370) <- layer_names\ncovs_future_SSP370\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nclass       : SpatRaster \ndimensions  : 44, 51, 19  (nrow, ncol, nlyr)\nresolution  : 5590.925, 5590.925  (x, y)\nextent      : 271609.2, 556746.4, 6862081, 7108082  (xmin, xmax, ymin, ymax)\ncoord. ref. : GDA2020 / MGA zone 56 (EPSG:7856) \nsource      : SEQ_future_bioclim.2090.SSP370.tif \nnames       : BIO1_~_Temp, BIO2_~Range, BIO3_~ality, BIO4_~ality, BIO5_~Month, BIO6_~Month, ... \nmin values  :    19.07255,     6.59230,    38.32245,    301.0822,    28.04017,    6.774293, ... \nmax values  :    24.52122,    14.53494,    50.96117,    530.5290,    37.41868,   15.740561, ... \n```\n\n\n:::\n\n```{.r .cell-code}\ncovs_future_SSP370 <- terra::mask(covs_future_SSP370, covs_current) # Crop to SEQ extent using current layers\n\ncovs_future_SSP370_expert <- subset(covs_future_SSP370, \n                                    names(covs_future_SSP370) %in% c(\"BIO5_Max_Temp_Warmest_Month\",\n                                                                     \"BIO6_Min_Temp_Coldest_Month\",\n                                                                     \"BIO12_Annual_Precipitation\",\n                                                                     \"BIO15_Precip_Seasonality\"))\n```\n:::\n\n\n\n\n\n\n## Plot the future rasters\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(covs_future_SSP370_expert)\n```\n\n::: {.cell-output-display}\n![](ICCB_Modelling_and_validation_files/figure-html/unnamed-chunk-45-1.png)\n:::\n:::\n\n\n\n\n\n\n### Compare the current and future rasters\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(covs_future_SSP370_expert - covs_current_expert)\n```\n\n::: {.cell-output-display}\n![](ICCB_Modelling_and_validation_files/figure-html/unnamed-chunk-46-1.png)\n:::\n:::\n\n\n\n\n\n\n## Test the environmental distance between current data and future conditions\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmess <- predicts::mess(covs_future_SSP370_expert,\n                       train_PB_covs_thinned[, c(\"BIO5_Max_Temp_Warmest_Month\",\n                                                 \"BIO6_Min_Temp_Coldest_Month\",\n                                                 \"BIO12_Annual_Precipitation\",\n                                                 \"BIO15_Precip_Seasonality\")])\n\nplot(mess)\n```\n\n::: {.cell-output-display}\n![](ICCB_Modelling_and_validation_files/figure-html/unnamed-chunk-47-1.png)\n:::\n\n```{.r .cell-code}\nr_mess_mask <- mess < 0\nplot(r_mess_mask)\n```\n\n::: {.cell-output-display}\n![](ICCB_Modelling_and_validation_files/figure-html/unnamed-chunk-47-2.png)\n:::\n:::\n\n\n\n\n\n\nTest which areas you might mask out because they are 'novel' in environmental space and therefore require model extrapolation.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanalog_fut <- predicted_current\n\nvalues(analog_fut)[values(mess)<0] <- NA\n\nplot(analog_fut,\n     range = c(0, 1),  # Set min and max values for the color scale\n     main = \"Koala relative occurrence in regions with analogue conditions\")\n```\n\n::: {.cell-output-display}\n![](ICCB_Modelling_and_validation_files/figure-html/unnamed-chunk-48-1.png)\n:::\n\n```{.r .cell-code}\nnovel_fut <- predicted_current\n\nvalues(novel_fut)[values(mess)>0] <- NA\n\nplot(novel_fut,\n     range = c(0, 1),  # Set min and max values for the color scale\n     main = \"Koala relative occurrence in regions with novel conditions\")\n```\n\n::: {.cell-output-display}\n![](ICCB_Modelling_and_validation_files/figure-html/unnamed-chunk-48-2.png)\n:::\n:::\n\n\n\n\n\n\n# GLM future predictions\n\n## Scale future layers and add human footprint\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Scale the future covariates using the same scaling parameters as the training data\ncovs_future_SSP370_expert_scaled <- scale(covs_future_SSP370_expert, \n                                   center = attr(scaled_covariates, \"scaled:center\")[-5],\n                                   scale = attr(scaled_covariates, \"scaled:scale\")[-5])\n\n# Add the human footprint layer to the future covariates\ncovs_future_SSP370_expert_HF_scaled <- c(covs_future_SSP370_expert_scaled, constant_HF)\n```\n:::\n\n\n\n\n\n\n## Model 1\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Predict the presence probability across the entire raster extent\npredicted_future370 <- predict(covs_future_SSP370_expert_HF_scaled, glm_model, type = \"response\")\n\n# Plot the species distribution raster\nplot(\n  predicted_future370,\n  range = c(0, 1),  # Set min and max values for the color scale\n  main = \"Future Climatic Suitability of Koalas in SEQ - SSP370\"\n)\n```\n\n::: {.cell-output-display}\n![](ICCB_Modelling_and_validation_files/figure-html/unnamed-chunk-50-1.png)\n:::\n:::\n\n\n\n\n\n\n## Show the predictions side-by-side\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mfrow = c(1, 2))\n\nplot(\n  predicted_current,\n  range = c(0, 1),\n  main = \"Current\"\n)\n\nplot(\n  predicted_future370,\n  range = c(0, 1),\n  main = \"Future (SSP 3.70)\"\n)\n```\n\n::: {.cell-output-display}\n![](ICCB_Modelling_and_validation_files/figure-html/unnamed-chunk-51-1.png)\n:::\n:::\n\n\n\n\n\n\n## Plot the different between current and future\n\nRed is **less** suitable in the Future SSP370 scenario, and blue is **more** suitable in the Future SSP370 scenario.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# return to single plotting\npar(mfrow = c(1, 1))\n\n# Create symmetric breaks centered at 0\nbreaks <- seq(-1, 1, length.out = 101)\n\n# Create the color palette\ncols <- colorRampPalette(c(\"red\", \"white\", \"blue\"))(100)\n\n\nplot(predicted_future370 - predicted_current,\n     main = \"Future (SSP370) - Current Predictions \",\n     col = cols,\n     range = c(-1, 1))\n```\n\n::: {.cell-output-display}\n![](ICCB_Modelling_and_validation_files/figure-html/unnamed-chunk-52-1.png)\n:::\n:::\n\n\n\n\n\n\n## Presenting predictions with uncertainty\n\nThere are many sources of model uncertainty that should be explored and ideally, presented alongside model predictions.\n\nOne that we'll focus on here is climate scenario uncertainty. We do so by fitting a second model to future climate data from a lower emission shared socioeconomic path scenario (SSP 1.26).\n\n## Load future environmental data (SSP 1.26)\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncovs_future_SSP126 <- rast(\"Data/Environmental_variables/SEQ_future_bioclim.2090.SSP126.tif\")\nnames(covs_future_SSP126) <- layer_names\ncovs_future_SSP126\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nclass       : SpatRaster \ndimensions  : 44, 51, 19  (nrow, ncol, nlyr)\nresolution  : 5590.925, 5590.925  (x, y)\nextent      : 271609.2, 556746.4, 6862081, 7108082  (xmin, xmax, ymin, ymax)\ncoord. ref. : GDA2020 / MGA zone 56 (EPSG:7856) \nsource      : SEQ_future_bioclim.2090.SSP126.tif \nnames       : BIO1_~_Temp, BIO2_~Range, BIO3_~ality, BIO4_~ality, BIO5_~Month, BIO6_~Month, ... \nmin values  :    17.11955,    6.654293,    39.11226,    298.1248,    26.08138,     3.96662, ... \nmax values  :    22.42196,   14.853741,    51.27921,    546.6645,    35.57761,    13.50076, ... \n```\n\n\n:::\n\n```{.r .cell-code}\ncovs_future_SSP126_expert <- subset(covs_future_SSP126, names(covs_future_SSP126) %in% c(\"BIO5_Max_Temp_Warmest_Month\",\n                                                                                          \"BIO6_Min_Temp_Coldest_Month\",\n                                                                                          \"BIO12_Annual_Precipitation\",\n                                                                                          \"BIO15_Precip_Seasonality\"))\n\nplot(covs_future_SSP126_expert) # to plot the layers\n```\n\n::: {.cell-output-display}\n![](ICCB_Modelling_and_validation_files/figure-html/unnamed-chunk-53-1.png)\n:::\n:::\n\n\n\n\n\n\n### Plot the difference between the two future scenarios\n\nThis is SSP370 - SSP126, so positive values indicate that the SSP370 scenario has higher values than the SSP126 scenario.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nterra::plot(covs_future_SSP370_expert - covs_future_SSP126_expert)\n```\n\n::: {.cell-output-display}\n![](ICCB_Modelling_and_validation_files/figure-html/unnamed-chunk-54-1.png)\n:::\n:::\n\n\n\n\n\n\n## GLM future predictions (SSP 1.26)\n\n### Model 1\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Scale the future covariates using the same scaling parameters as the training data\ncovs_future_SSP126_expert_scaled <- scale(covs_future_SSP126_expert, \n                                   center = attr(scaled_covariates, \"scaled:center\")[-5],\n                                   scale = attr(scaled_covariates, \"scaled:scale\")[-5])\n\n# Add the human footprint layer to the future covariates\ncovs_future_SSP126_expert_HF_scaled <- c(covs_future_SSP126_expert_scaled, constant_HF)\n\n# Predict the presence probability across the entire raster extent\npredicted_future126 <- predict(covs_future_SSP126_expert_HF_scaled, glm_model, type = \"response\")\n```\n:::\n\n\n\n\n\n\n## Plot the different between current and future (SSP126)\n\nRed is **less** suitable in the Future SSP126 scenario, and blue is **more** suitable in the Future SSP126 scenario.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# return to single plotting\npar(mfrow = c(1, 1))\n\n# Create symmetric breaks centered at 0\nbreaks <- seq(-1, 1, length.out = 101)\n\n# Create the color palette\ncols <- colorRampPalette(c(\"red\", \"white\", \"blue\"))(100)\n\n\nplot(predicted_future126 - predicted_current,\n     main = \"Future (SSP370) - Current Predictions \",\n     col = cols,\n     range = c(-1, 1))\n```\n\n::: {.cell-output-display}\n![](ICCB_Modelling_and_validation_files/figure-html/unnamed-chunk-56-1.png)\n:::\n:::\n\n\n\n\n\n\n## Compare the two future predictions\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mfrow = c(1, 2))\n\n# Plot the predicted suitability \nplot(\n  predicted_future126,\n  range = c(0,1),\n  main = \"Suitability SSP126\"\n)\n\nplot(\n  predicted_future370,\n  range = c(0,1),\n  main = \"Suitability SSP370\"\n)\n```\n\n::: {.cell-output-display}\n![](ICCB_Modelling_and_validation_files/figure-html/unnamed-chunk-57-1.png)\n:::\n:::\n\n\n\n\n\n\n## Plot the different between the two future predictions\n\nRed is **less** suitable in the Future SSP370 scenario than the SSP126 scenario, and blue is **more** suitable in Future SSP370 scenario than the SSP126 scenario.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# return to single plotting\npar(mfrow = c(1, 1))\n\n# Create symmetric breaks centered at 0\nbreaks <- seq(-1, 1, length.out = 101)\n\n# Create the color palette\ncols <- colorRampPalette(c(\"red\", \"white\", \"blue\"))(100)\n\n\nplot(predicted_future370 - predicted_future126,\n     main = \"Future (SSP370) - Future (SSP126) Predictions \",\n     col = cols,\n     range = c(-1, 1))\n```\n\n::: {.cell-output-display}\n![](ICCB_Modelling_and_validation_files/figure-html/unnamed-chunk-58-1.png)\n:::\n:::\n\n\n\n\n\n\n## Model uncertainty\n\nAnother element of uncertainty that can be represented is model uncertainty, or the standard error around the coefficient estimates.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Extract standard errors of coefficients\ncoef_se <- summary(glm_model)$coefficients[, \"Std. Error\"]\nprint(coef_se)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                (Intercept) BIO5_Max_Temp_Warmest_Month \n                 0.07448802                  0.05567149 \nBIO6_Min_Temp_Coldest_Month  BIO12_Annual_Precipitation \n                 0.07457315                  0.07762200 \n   BIO15_Precip_Seasonality             human_footprint \n                 0.04488347                  0.06764752 \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncovs_df <- as.data.frame(covs_future_SSP126_expert_HF_scaled, na.rm = FALSE)\n\npred_link <- predict(glm_model, newdata = covs_df, type = \"link\", se.fit = TRUE)\n\n# Linear predictor (eta)\neta <- pred_link$fit\nse_eta <- pred_link$se.fit\n\n# Confidence intervals (95%)\nz <- 1.96\neta_lower <- eta - z * se_eta\neta_upper <- eta + z * se_eta\n\n# Transform back to response scale\nlinkinv <- glm_model$family$linkinv\npredicted <- linkinv(eta)\nlower_ci <- linkinv(eta_lower)\nupper_ci <- linkinv(eta_upper)\n\n\n# Add to covs_df\ncovs_df$predicted <- predicted\ncovs_df$lower_ci <- lower_ci\ncovs_df$upper_ci <- upper_ci\n\n\npredicted_r <- setValues(rast(covs_future_SSP126_expert_HF_scaled, nlyr = 1), predicted)\nlower_ci_r <- setValues(rast(covs_future_SSP126_expert_HF_scaled, nlyr = 1), lower_ci)\nupper_ci_r <- setValues(rast(covs_future_SSP126_expert_HF_scaled, nlyr = 1), upper_ci)\n\n# Step 2: Name the layers\nnames(predicted_r) <- \"SSP126 Mean Estimate\"\nnames(lower_ci_r) <- \"SSP126 Lower CI\"\nnames(upper_ci_r) <- \"SSP126 Upper CI\"\n\nprediction_w_uncertainty <- c(predicted_r, lower_ci_r, upper_ci_r)\n\nplot(prediction_w_uncertainty, range = c(0, 1))\n```\n\n::: {.cell-output-display}\n![](ICCB_Modelling_and_validation_files/figure-html/unnamed-chunk-60-1.png)\n:::\n:::\n\n\n\n\n\n\n# References\n\n::: {#refs}\n:::\n\n# Session information\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsessionInfo()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nR version 4.5.0 (2025-04-11)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS Sequoia 15.5\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Australia/Brisbane\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] gridExtra_2.3      corrplot_0.95      precrec_0.14.5     usdm_2.1-7        \n [5] ecospat_4.1.2      blockCV_3.1-5      predicts_0.1-19    tidyterra_0.7.2   \n [9] sf_1.0-20          terra_1.8-50       galah_2.1.1        RColorBrewer_1.1-3\n[13] lubridate_1.9.4    forcats_1.0.0      stringr_1.5.1      dplyr_1.1.4       \n[17] purrr_1.0.4        readr_2.1.5        tidyr_1.3.1        tibble_3.2.1      \n[21] ggplot2_3.5.2      tidyverse_2.0.0   \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.6       xfun_0.52          raster_3.6-32      httr2_1.1.2       \n [5] htmlwidgets_1.6.4  lattice_0.22-6     tzdb_0.5.0         vctrs_0.6.5       \n [9] tools_4.5.0        generics_0.1.3     parallel_4.5.0     proxy_0.4-27      \n[13] pkgconfig_2.0.3    KernSmooth_2.23-26 data.table_1.17.0  assertthat_0.2.1  \n[17] lifecycle_1.0.4    compiler_4.5.0     farver_2.1.2       codetools_0.2-20  \n[21] rrapply_1.2.7      htmltools_0.5.8.1  potions_0.2.0      class_7.3-23      \n[25] yaml_2.3.10        pillar_1.10.2      crayon_1.5.3       classInt_0.4-11   \n[29] iterators_1.0.14   foreach_1.5.2      tidyselect_1.2.1   digest_0.6.37     \n[33] stringi_1.8.7      labeling_0.4.3     fastmap_1.2.0      grid_4.5.0        \n[37] cli_3.6.5          magrittr_2.0.3     dichromat_2.0-0.1  e1071_1.7-16      \n[41] withr_3.0.2        scales_1.4.0       rappdirs_0.3.3     bit64_4.6.0-1     \n[45] sp_2.2-0           timechange_0.3.0   rmarkdown_2.29     lobstr_1.1.2      \n[49] bit_4.6.0          hms_1.1.3          evaluate_1.0.3     knitr_1.50        \n[53] rlang_1.1.6        Rcpp_1.0.14        glue_1.8.0         DBI_1.2.3         \n[57] vroom_1.6.5        rstudioapi_0.17.1  jsonlite_2.0.0     R6_2.6.1          \n[61] units_0.8-7       \n```\n\n\n:::\n:::\n",
    "supporting": [
      "ICCB_Modelling_and_validation_files/figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}