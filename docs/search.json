[
  {
    "objectID": "Session 1/session_1_code.html",
    "href": "Session 1/session_1_code.html",
    "title": "Getting started with geospatial coding in R using the terra and sf packages",
    "section": "",
    "text": "No prior experience of spatial data is assumed, but this introduction will not have time to delve deeply into some important aspects of spatial data such as projections. We will use the two most commonly used R packages for geospatial data manipulation: sf for manipulating vector data, and terra for manipulating raster and vector data. If you are still using the raster package, you should move to terra; it is simpler, faster and can do more!\nResources:"
  },
  {
    "objectID": "Session 1/session_1_code.html#prerequisites",
    "href": "Session 1/session_1_code.html#prerequisites",
    "title": "Getting started with geospatial coding in R using the terra and sf packages",
    "section": "Prerequisites",
    "text": "Prerequisites\nYou will need the terra and sf packages installed. We will also make an interactive map with terra, which requires the leaflet package to be installed, and we will need the dplyr package for data manipulation.\n\ninstall.packages(c(\"sf\", \"terra\", \"leaflet\", \"dplyr\"))\n\nIf you have problems, there are more details about installing terra here and sf here.\nWe can now load the packages:\n\nlibrary(dplyr)\nlibrary(terra)\nlibrary(sf)\nlibrary(tmap)"
  },
  {
    "objectID": "Session 1/session_1_code.html#vector-data",
    "href": "Session 1/session_1_code.html#vector-data",
    "title": "Getting started with geospatial coding in R using the terra and sf packages",
    "section": "Vector data",
    "text": "Vector data\nCan be points, lines or polygons. Vectors are useful for representing things like survey locations, rivers, and boundaries.\n\n\nCode\npts &lt;- rbind(c(3.2,4), c(3,4.6), c(3.8,4.4), c(3.5,3.8), c(3.4,3.6), c(3.9,4.5)) |&gt;\n  vect()\n\nlnes &lt;- as.lines(vect(rbind(c(3,4.6), c(3.2,4), c(3.5,3.8)))) |&gt;\n  rbind(as.lines(vect(rbind(c(3.9, 4.5), c(3.8, 4.4), c(3.5,3.8), c(3.4,3.6)))))\n\nlux &lt;- vect(system.file(\"ex/lux.shp\", package = \"terra\"))\n\npar(mfrow = c(1,3))\npar(mar = rep(0.1,4))\n\nplot(pts, axes = F, main = \"Points\")\nplot(lnes, col = \"blue\", axes = F, main = \"Lines\")\nplot(lux, \"NAME_2\", col = terrain.colors(12), las = 1, axes = F, main = \"Polygons\")"
  },
  {
    "objectID": "Session 1/session_1_code.html#raster-data",
    "href": "Session 1/session_1_code.html#raster-data",
    "title": "Getting started with geospatial coding in R using the terra and sf packages",
    "section": "Raster data",
    "text": "Raster data\nRaster data is a grid of rectangles, normally called cells. Each cell has a value, making rasters useful for storing continuous data, such as temperature and elevation.\nHere is an example of raster data, where each cell in the raster represents elevation.\n\n\nCode\npar(mfrow = c(1,1)) #return to defaults\npar(mar = c(5, 4, 4, 2) + 0.1)\n\nelev &lt;- system.file(\"ex/elev.tif\", package = \"terra\") |&gt;\n  rast() |&gt;\n  aggregate(fact = 2)\n\nplot(elev, las = 1, main = \"Elevation map\", col = terrain.colors(100))\n\nelev |&gt;\n  as.polygons(aggregate = FALSE, na.rm = FALSE) |&gt;\n  lines(col = \"grey40\", lwd = 0.2)"
  },
  {
    "objectID": "Session 1/session_1_code.html#making-and-inspecting-a-raster",
    "href": "Session 1/session_1_code.html#making-and-inspecting-a-raster",
    "title": "Getting started with geospatial coding in R using the terra and sf packages",
    "section": "Making and inspecting a raster",
    "text": "Making and inspecting a raster\nLets start by creating our own raster. We will be doing all manipulation of rasters with the terra package. To create rasters from scratch or load them from a file we use the function rast(). We can create a simple raster by specifying the x and y limits for the raster and the resolution (how big each cell is).\n\n#create raster\nras &lt;- rast(xmin = 0, xmax = 10, ymin = 0, ymax = 10, resolution = 2)\n\n#see what we've created\nras\n\nclass       : SpatRaster \ndimensions  : 5, 5, 1  (nrow, ncol, nlyr)\nresolution  : 2, 2  (x, y)\nextent      : 0, 10, 0, 10  (xmin, xmax, ymin, ymax)\ncoord. ref. : lon/lat WGS 84 (CRS84) (OGC:CRS84) \n\n\nThe figure below shows what most of the terms above refer to. As you can see, you don’t need to use all the terms to define a raster. Some other important points to note:\n\nEvery object in R has a class, such as data.frame and as you can see, rasters in terra are of class SpatRaster.\nWe did not tell rast() which coordinate reference system to use, so it defaults to using longitude latitude coordinates, also known as EPSG 4326. We will come back to coordinate reference systems later.\n\n\n\n\n\n\n\n\n\n\nBut what does the raster we created actually look like when plotted. Lets see. All we need is plot()\n\nplot(ras)\n\n\n\n\n\n\n\n\nWhy is there no plot? Because the raster we created is empty; there are no values associated with the the cells. Lets assign some values to each cell in the raster and try again. First we will find out how many cells are in our raster using `ncell()\n\nncell(ras)\n\n[1] 25\n\n\nOk, now we know this lets give our raster cells values from 1 to 25:\n\nvalues(ras) &lt;- 1:25\n\nplot(ras)\n\n\n\n\n\n\n\n\nNow our raster has values, we get a plot! Each cell has an integer value between 1 and 25, with cell values increasing from left to right and top to bottom. So the values start being “filled up” in the top left, and finish in the bottom right.\nLets have another look at our raster properties\n\nras\n\nclass       : SpatRaster \ndimensions  : 5, 5, 1  (nrow, ncol, nlyr)\nresolution  : 2, 2  (x, y)\nextent      : 0, 10, 0, 10  (xmin, xmax, ymin, ymax)\ncoord. ref. : lon/lat WGS 84 (CRS84) (OGC:CRS84) \nsource(s)   : memory\nname        : lyr.1 \nmin value   :     1 \nmax value   :    25 \n\n\nWe can now see a few extra pieces of information compared to last time:\n\nsources(s): where is the data held on your computer? It says memory for this raster, indicating that the raster is in the computer memory. Rasters can also be held on your hard disk, in which case this will be the file name of the raster. We won’t go into details here, but terra is smart about loading data into memory, only doing so when it needs to and it thinks it will have enough space.\nname: what is the raster called?\nmin value & max value: the minimum and maximum values in the raster\n\nOk, now we understand the basic structure of a raster, lets look at vector data using the sf package."
  },
  {
    "objectID": "Session 1/session_1_code.html#making-and-inspecting-a-vector",
    "href": "Session 1/session_1_code.html#making-and-inspecting-a-vector",
    "title": "Getting started with geospatial coding in R using the terra and sf packages",
    "section": "Making and inspecting a vector",
    "text": "Making and inspecting a vector\nAs mentioned earlier, vector data can be points, lines or polygons. Let’s start by making a single spatial point and plot it:\n\npt &lt;- st_point(c(1,3))\n\nplot(pt, axes = TRUE)\n\n\n\n\n\n\n\n\nSimple! But this is just a point. What if we want our point to have some information attached to it? For example, what the temperature is at that point. Well first we need to convert it into a simple feature collection:\n\npt_sf &lt;- pt |&gt; \n  st_sfc() |&gt; \n  st_as_sf()\n\npt_sf\n\n\n  \n\n\n\nInspecting the simple feature collection, pt_sf, that we created, we see that there is only 1 feature; our point. There is also a bounding box, which is the same concept as the x and y limits we had for our raster. Like the raster, we also have coordinate reference system (CRS), that is currently not defined.\nNow our point is a simple feature collection, we can add some information to it. We will add a column called “temperature” and give our point a value of 25.\n\npt_sf$temperature &lt;- 25\n\npt_sf\n\n\n  \n\n\n\nNow our point has a “field” attached to it with temperature data. The fields are simply columns that have information for each geometry; in our case a point."
  },
  {
    "objectID": "Session 1/session_1_code.html#vectors",
    "href": "Session 1/session_1_code.html#vectors",
    "title": "Getting started with geospatial coding in R using the terra and sf packages",
    "section": "Vectors",
    "text": "Vectors\n\nLoading and plotting\nMost of the time, we won’t be making our own data from scratch, but reading in data that we have downloaded or been provided with. In this workshop, you are going to be doing a case study of Koalas in south-east Queensland (SEQ). One of the first pieces of spatial data we normally need are the boundaries of the area we are working in. We will use spatial data of the local government areas (LGAs) in Queensland downloaded from the Queensland government website to define our SEQ boundary.\nWe use st_read() to read the data which is in the data folder you should have downloaded with the code from Github. The file is a Geopackage, which is widely used for storing geospatial data, and is similar (but better!) than shapefile. The st_read() command can read data in many different spatial formats: run st_drivers() to see a complete list of formats.\n\nlgas &lt;- st_read(\"data/Local_Government_Areas.gpkg\") \n\nReading layer `Local_Government_Areas' from data source \n  `/Users/scottforrest/Library/CloudStorage/OneDrive-QueenslandUniversityofTechnology/PhD - Scott Forrest/GIT/ICCB_geospatial_tools_conservation/Session 1/data/Local_Government_Areas.gpkg' \n  using driver `GPKG'\nSimple feature collection with 78 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 137.9947 ymin: -29.17925 xmax: 153.5519 ymax: -9.087977\nGeodetic CRS:  WGS 84\n\n\nsf gives us some information about the data we have read: we can see it is MULTIPOLYGON and has 78 features and 6 fields, i.e. 78 rows of geometry and 6 columns of data, and its CRS is WGS 84. We will come back to the coordinate reference system (CRS) later, so for now, lets have a look at the first few rows (features):\n\nhead(lgas)\n\n\n  \n\n\n\nNow we can see that the 6 fields contain information about each LGA, including various name formats and the areas. The final column called “Shape” contains the spatial information: the coordinates for each point that makes up the polygons. This column is most commonly labelled “geometry”.\nThe fields in our sf data are just like columns in a data frame. So if we want all the values in one column, we can just select that column in the same way as a data frame:\n\nlgas$lga\n\n [1] \"Aurukun Shire\"                    \"Balonne Shire\"                   \n [3] \"Banana Shire\"                     \"Barcaldine Regional\"             \n [5] \"Barcoo Shire\"                     \"Blackall Tambo Regional\"         \n [7] \"Boulia Shire\"                     \"Brisbane City\"                   \n [9] \"Burdekin Shire\"                   \"Burke Shire\"                     \n[11] \"Cairns Regional\"                  \"Carpentaria Shire\"               \n[13] \"Cassowary Coast Regional\"         \"Central Highlands Regional\"      \n[15] \"Charters Towers Regional\"         \"Maranoa Regional\"                \n[17] \"Mareeba Shire\"                    \"Mckinlay Shire\"                  \n[19] \"Moreton Bay City\"                 \"Mornington Shire\"                \n[21] \"Mount Isa City\"                   \"Murweh Shire\"                    \n[23] \"Napranum Aboriginal Shire\"        \"Noosa Shire\"                     \n[25] \"North Burnett Regional\"           \"Northern Peninsula Area Regional\"\n[27] \"Palm Island Aboriginal Shire\"     \"Paroo Shire\"                     \n[29] \"Pormpuraaw Aboriginal Shire\"      \"Quilpie Shire\"                   \n[31] \"Redland City\"                     \"Richmond Shire\"                  \n[33] \"Rockhampton Regional\"             \"Scenic Rim Regional\"             \n[35] \"Somerset Regional\"                \"South Burnett Regional\"          \n[37] \"Southern Downs Regional\"          \"Sunshine Coast Regional\"         \n[39] \"Tablelands Regional\"              \"Toowoomba Regional\"              \n[41] \"Torres Shire\"                     \"Torres Strait Island Regional\"   \n[43] \"Townsville City\"                  \"Bulloo Shire\"                    \n[45] \"Bundaberg Regional\"               \"Cherbourg Aboriginal Shire\"      \n[47] \"Cloncurry Shire\"                  \"Cook Shire\"                      \n[49] \"Croydon Shire\"                    \"Diamantina Shire\"                \n[51] \"Isaac Regional\"                   \"Kowanyama Aboriginal Shire\"      \n[53] \"Livingstone Shire\"                \"Lockhart River Aboriginal Shire\" \n[55] \"Lockyer Valley Regional\"          \"Logan City\"                      \n[57] \"Longreach Regional\"               \"Mackay Regional\"                 \n[59] \"Mapoon Aboriginal Shire\"          \"Doomadgee Aboriginal Shire\"      \n[61] \"Douglas Shire\"                    \"Etheridge Shire\"                 \n[63] \"Flinders Shire\"                   \"Fraser Coast Regional\"           \n[65] \"Gladstone Regional\"               \"Gold Coast City\"                 \n[67] \"Goondiwindi Regional\"             \"Gympie Regional\"                 \n[69] \"Hinchinbrook Shire\"               \"Hope Vale Aboriginal Shire\"      \n[71] \"Ipswich City\"                     \"Weipa Town\"                      \n[73] \"Western Downs Regional\"           \"Whitsunday Regional\"             \n[75] \"Winton Shire\"                     \"Woorabinda Aboriginal Shire\"     \n[77] \"Wujal Wujal Aboriginal Shire\"     \"Yarrabah Aboriginal Shire\"       \n\n\nLet’s plot the data to see what we have:\n\nplot(lgas)\n\n\n\n\n\n\n\n\nLooks like Queensland! We got one map for each field (column). If we want a map of just one field we can select only the field we want:\n\nplot(lgas[, \"lga\"], axes = TRUE)\n\n\n\n\n\n\n\n\nWe added axes using the axes = TRUE argument.\n\n\nSubsetting and merging\nOur data has local government areas (LGAs) for the whole of Queensland, but we just want a polygon of south-east Queensland (SEQ). How do we get that?\nFirst, we make a vector containing the names of all the LGAs in SEQ:\n\nseq_lga_names &lt;- c(\n  \"Brisbane City\",\n  \"Moreton Bay City\",\n  \"Logan City\",\n  \"Ipswich City\",\n  \"Redland City\",\n  \"Scenic Rim Regional\",\n  \"Somerset Regional\",\n  \"Lockyer Valley Regional\",\n  \"Gold Coast City\",\n  \"Sunshine Coast Regional\",\n  \"Toowoomba Regional\",\n  \"Noosa Shire\"\n)\n\nNow we can subset our LGAs spatial data for just these LGAs:\n\nlgas_seq &lt;- lgas |&gt; \n  filter(lga %in% seq_lga_names) #select only the rows of data with LGA names that we have listed\n\nplot(lgas_seq[, \"lga\"])\n\n\n\n\n\n\n\n\nGreat! We’ve got only the LGAs in SEQ. But at the moment we have many polygons that make up SEQ:\n\nhead(lgas_seq)\n\n\n  \n\n\n\nHow do we get just one polygon that is the boundary of the area? We use st_union():\n\nseq_boundary &lt;- st_union(lgas_seq)\n\nplot(seq_boundary)\n\n\n\n\n\n\n\n\nThis merges all our polygons into one polygon. Note that we lose all the fields when we do this:\n\nhead(seq_boundary)\n\nGeometry set for 1 feature \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 150.7027 ymin: -28.36387 xmax: 153.5519 ymax: -26.13711\nGeodetic CRS:  WGS 84\n\n\nMULTIPOLYGON (((153.2366 -27.43647, 153.2385 -2..."
  },
  {
    "objectID": "Session 1/session_1_code.html#rasters",
    "href": "Session 1/session_1_code.html#rasters",
    "title": "Getting started with geospatial coding in R using the terra and sf packages",
    "section": "Rasters",
    "text": "Rasters\n\nLoading and plotting\nWe now want to get some climate data for our south-east Queensland study area that we will use in a later session to do species modelling. Climate data is normally stored in raster format, so we will be using the terra package to manipulate the data. Example climate data is already in the data folder, and you will learn about how to create these data in the following session. For now, let’s load one of the climate rasters and have a look at it:\n\nclimate1 &lt;- rast(\"data/Current_climate_QLD/bioclim_01.tif\")\n\nclimate1\n\nclass       : SpatRaster \ndimensions  : 681, 841, 1  (nrow, ncol, nlyr)\nresolution  : 0.05, 0.05  (x, y)\nextent      : 111.975, 154.025, -44.025, -9.975  (xmin, xmax, ymin, ymax)\ncoord. ref. : lon/lat WGS 84 (EPSG:4326) \nsource      : bioclim_01.tif \nname        : bioclim_01 \n\n\nIt is a raster with 0.05 degree resolution: we know it is in degrees because it is unprojected, in the EPSG 4326 coordinate reference system. Let’s plot the data:\n\nplot(climate1)\n\n\n\n\n\n\n\n\nWe can see that the data covers the whole of Australia. What type of data do you think this is?\n\n\nCropping and masking\nThe raster data we have at the moment is for a much larger area than just SEQ. Let’s plot our raster and SEQ polygon together to see:\n\nseq_vect &lt;- vect(seq_boundary) #we need to convert our sf polygon into a SpatVector, which is the vector format that the terra package uses\n\nplot(climate1) \nlines(seq_vect) #adds the SEQ polygon as lines on top of the raster\n\n\n\n\n\n\n\n\nTo get only SEQ data, we need to crop and mask the raster data using our SEQ polygon.\nCropping means that we keep only the data inside the extent of the vector we are using. Mask means that all the data outside the vector is set to NA or some other value we specify. Lets have a look how this works.\nFirst lets have a look at the extent of the SEQ polygon. We can get the extent of a raster or vector using ext(). We need to convert this into a SpatVector object for plotting using vect(). We only need to do this for plotting; when we crop, we can just use the SEQ polygon as the input.\n\nseq_vect_extent &lt;- ext(seq_vect) |&gt; \n  vect()\n\nplot(climate1)\nlines(seq_vect)\nlines(seq_vect_extent, col = \"blue\")\n\n\n\n\nCropping means we remove everything outside the extent (blue box) of our polygon. Masking sets all values outside our polygon to NA.\n\n\n\n\nSo when we crop, we get only the area within the blue box.\nWe crop using the crop() function, using the raster we want to crop as the first argument and the vector we are cropping as the second.\n\n#crop\nclimate1_cropped &lt;- crop(climate1, seq_vect)\n\n#plot\nplot(climate1_cropped)\nlines(seq_vect)\n\n\n\n\n\n\n\n\nNow we have cropped our raster, we can mask it so that we only have values for the area within the SEQ boundary. We do this using mask:\n\n#mask\nclimate_seq &lt;- mask(climate1_cropped, seq_vect)\n\n#plot\nplot(climate_seq)\nlines(seq_vect)\n\n\n\n\n\n\n\n\nNow we only see raster values for cells that are within the SEQ boundary. But remember that the areas that are white, still have values, they are just NA values. We can confirm this by plotting the NA cells in grey (or any other colour):\n\nplot(climate_seq, colNA = \"grey\")\nlines(seq_vect)\n\n\n\n\n\n\n\n\nOften we want to crop and mask one after the other, and you can do this in one command using crop(climate1_projected, seq_vect, mask = TRUE).\nFor reference, here is a figure comparing what crop, mask and crop(mask = TRUE) do:\n\n\nCode\npar(mfrow = c(2,2))\n\nplot(climate1, main = \"Original raster\")\nlines(seq_vect)\n\nplot(climate1_cropped, main = \"Cropped\")\nlines(seq_vect)\n\nclimate1 |&gt;\n  mask(seq_vect) |&gt;\n  plot(main = \"Masked\")\nlines(seq_vect)\n\nplot(crop(climate1, seq_vect, mask = TRUE), main = \"Cropped and masked\")\nlines(seq_vect)\n\n\n\n\n\n\n\n\n\nWhy not just mask rather than crop and mask? As we see in the figure above, this would mean we have a lot of area we are not interested in and even though most of those cells would be NA they take up space in our raster, so it is not efficient.\n\n\nRaster values\nRemember that each cell in our raster has a value. We might want to examine some summaries of these raster values. We can get a histogram of all the values in a raster using the hist() function:\n\nhist(climate_seq)\n\n\n\n\n\n\n\n\nThere is a tail of low values, which are mostly from the south-east of Australia (Tasmania is chilly!). What is the mean value for the whole of Australia?\n\nglobal(climate_seq, \"mean\", na.rm = TRUE)\n\n\n  \n\n\n\nWe can also get a statistical summary of the raster values just by using the summary() function:\n\nsummary(climate_seq)\n\n   bioclim_01   \n Min.   :15.36  \n 1st Qu.:18.72  \n Median :19.39  \n Mean   :19.43  \n 3rd Qu.:20.32  \n Max.   :21.49  \n NA's   :1118   \n\n\n\n\nRaster math\nThe great thing about rasters are you can do maths with them! For example, doing climate1 + 1 just adds one to each raster value, and doing climate1*2 multiplies each raster value by two.\nAs an example, lets convert our temperature data into Fahrenheit for our confused colleagues from the U.S. The conversion from Celsius to Fahrenheit is: Fahrenheit = (Celsius * 1.8) + 32.\n\n#do the conversion\nclimate_seq_fahrenheit &lt;- (climate_seq*1.8) + 32\n\n#plot our new raster\nplot(climate_seq_fahrenheit)\n\n\n\n\n\n\n\n\n\n\nCoordinate reference systems and projection\nRemember that the CRS of our data is WGS 84. What does this mean? We can get some more information using st_crs():\n\ncrs(climate_seq)\n\n[1] \"GEOGCRS[\\\"WGS 84\\\",\\n    ENSEMBLE[\\\"World Geodetic System 1984 ensemble\\\",\\n        MEMBER[\\\"World Geodetic System 1984 (Transit)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G730)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G873)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G1150)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G1674)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G1762)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G2139)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G2296)\\\"],\\n        ELLIPSOID[\\\"WGS 84\\\",6378137,298.257223563,\\n            LENGTHUNIT[\\\"metre\\\",1]],\\n        ENSEMBLEACCURACY[2.0]],\\n    PRIMEM[\\\"Greenwich\\\",0,\\n        ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n    CS[ellipsoidal,2],\\n        AXIS[\\\"geodetic latitude (Lat)\\\",north,\\n            ORDER[1],\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n        AXIS[\\\"geodetic longitude (Lon)\\\",east,\\n            ORDER[2],\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n    USAGE[\\n        SCOPE[\\\"Horizontal component of 3D system.\\\"],\\n        AREA[\\\"World.\\\"],\\n        BBOX[-90,-180,90,180]],\\n    ID[\\\"EPSG\\\",4326]]\"\n\n\nThis is the well-known text (wkt) description of the CRS, which gives a lot of detail. Let’s get a simpler version:\n\ncrs(climate_seq, describe = TRUE)\n\n\n  \n\n\n\nWe often have to deal with spatial data that have different CRS’s, which involves transforming the data from one CRS to another. But first, what is a CRS?\n\nCoordinate reference systems\n\n\nClick here to expand this section\n\nIf we want to know where things are in space, we need to use some kind of spatial reference. We can use our own arbitrary system, e.g. a sampling grid like the one shown in the photo below where we could define the location of each square relative to one of the corners. But normally we want to know where something is on Earth.\n\n\n\n\n\n\n\n\n\nThere are two types of coordinate systems we can use to represent locations on Earth:\n\nGeographic coordinate systems (GCS): uses a 3-D surface (e.g. globe) to define locations on the Earth using longitude and latitude. The 3-D surface is normally an ellipsoid which approximates the Earth but cannot be exact since the Earth is not a smooth surface. This approximation of the Earth is called a datum and can be aligned with the true Earth (the geoid) in different ways depending on whether we are trying to get a good approximation at some particular location (local datum), e.g. Brisbane, or best approximation across the whole Earth (geocentric datum). The figure below (sourced from here) shows examples of these datums.\n\n\n\n\n\n\n\n\n\n\nA commonly used geocentric datum is World Geodetic Survey for 1984 (WGS84). This is almost synonymous with the commonly used coordinate reference system EPSG 4326, but EPSG 4326 defines the latitude and longitude coordinates used on the WGS84 ellipsoid (Ref)\n\nProjected coordinate system (projection): Unfortunately, we can’t carry around globes all the time when we want to look at a map, and doing calculations, such as distance and area, in 3-D is much more difficult than 2-D. So we need a way of getting from our 3-D globe to a piece of paper (or for younger people, a screen). To do this we need to ‘project’ from a GCS to a projected coordinate system, which is called projection because we can think of this as putting a light in the centre of a globe and the light shines through the globe projecting features onto a flat piece of paper. The figure below (from QGIS docs) illustrates this, showing the 3 projection families:\n\n\n\n\n\n\na) Cylindrical; b) conical, and; c) planar projecions\n\n\n\n\nAll projections are a compromise because they will always distort the shape, area, distances, and directions of the original GCS. A map that preserves shape is called conformal; one that preserves area is called equal-area; one that preserves distance is called equidistant; and one that preserves direction is called azimuthal. There are a huge number of projections available and choosing the correct one can be challenging. Often your choice will be to use the a local projection that is used by goverment or other authorities in the location you are working, e.g. for this workshop we will use EPSG 7856, GDA2020 / MGA zone 56, which is suitable for our study area of south-east Queensland. For global work where equal area is important, the Mollweide projection is commonly used.\nWe have only covered the basics of coordinate reference systems because it is a big topic to cover. The following resources are useful for understanding in more depth:\n\nThe QGIS software documentation\nThe Geocomputation with R book section\nR for Spatial Data Science book section\nStackexchange question about WGS84\n\n\nComing back to our Queensland data, you will remember that it is in the WGS 84 CRS, which is a geographic CRS. We want to transform it into a suitable projected CRS. We will be using GDA2020 / MGA zone 56, which is identified by the EPSG code 7843. Let’s check if this is a suitable projection:\n\ncrs(\"EPSG:7856\", describe = TRUE)\n\n\n  \n\n\n\nIt says it’s suitable for Australia between 150°E and 156°E. Is our data between those bounds? We can check by finding the extent of the unprojected data, which is in degrees longitude and latitude:\n\next(climate_seq)\n\nSpatExtent : 150.725, 153.575, -28.375, -26.125 (xmin, xmax, ymin, ymax)\n\n\nYep, we’re good!\nSo now we can go ahead and project the data:\n\nclimate_seq_projected &lt;- project(climate_seq, \"EPSG:7856\")\n\nplot(climate_seq_projected)\n\n\n\n\n\n\n\n\nThe data looks the same, but our axes are no longer in degrees latitude and longitude. What are our units of measurement in our projected CRS? Normally they would be metres (unless you’re in some weird American projection and you’re using feet), but lets check. We need to use sf’s crs function for this:\n\nst_crs(climate_seq_projected)$units_gdal\n\n[1] \"metre\"\n\n\nYep, we’re in metres. Compare this to the units for the unprojected data:\n\nst_crs(climate_seq)$units_gdal\n\n[1] \"degree\"\n\n\nIt is really important to understand that when we project a raster, we are changing the raster, because we have to create a new raster in the new CRS.\nLets compare our original raster and the projected version:\n\nclimate_seq\n\nclass       : SpatRaster \ndimensions  : 45, 57, 1  (nrow, ncol, nlyr)\nresolution  : 0.05, 0.05  (x, y)\nextent      : 150.725, 153.575, -28.375, -26.125  (xmin, xmax, ymin, ymax)\ncoord. ref. : lon/lat WGS 84 (EPSG:4326) \nsource(s)   : memory\nvarname     : bioclim_01 \nname        : bioclim_01 \nmin value   :   15.35748 \nmax value   :   21.49342 \n\n\n\nclimate_seq_projected\n\nclass       : SpatRaster \ndimensions  : 48, 55, 1  (nrow, ncol, nlyr)\nresolution  : 5184.076, 5184.076  (x, y)\nextent      : 272527.9, 557652.1, 6861637, 7110473  (xmin, xmax, ymin, ymax)\ncoord. ref. : GDA2020 / MGA zone 56 (EPSG:7856) \nsource(s)   : memory\nname        : bioclim_01 \nmin value   :   15.44909 \nmax value   :   21.47693 \n\n\nThe extent, resolution, and dimensions of the projected raster are all different from the unprojected one. This projected CRS has units of meters, which means the size of each raster cell is 5184.08m x 5184.08m.\nLet’s compare the statistics for the two rasters:\n\nsummary(climate_seq)\n\n   bioclim_01   \n Min.   :15.36  \n 1st Qu.:18.72  \n Median :19.39  \n Mean   :19.43  \n 3rd Qu.:20.32  \n Max.   :21.49  \n NA's   :1118   \n\nsummary(climate_seq_projected)\n\n   bioclim_01   \n Min.   :15.45  \n 1st Qu.:18.67  \n Median :19.38  \n Mean   :19.42  \n 3rd Qu.:20.27  \n Max.   :21.48  \n NA's   :1172   \n\n\nThe statistics are similar, but not exactly the same. There are more NA values in the projected raster, largely because there are more cells: 2565 in the original and 2640 in the projected raster.\nThese changes in the raster are really important to think about when making decisions about projecting rasters. In general avoid projecting rasters if you can. You can find more information about the methods you can use when project in the project() help file (?project).\nWe can also project vector data. For this we use the sf function st_transform(). Let’s project our SEQ boundary polygon into the local projection:\n\nseq_boundary_projected &lt;- st_transform(seq_boundary, 7856)\n\nseq_boundary_projected\n\nGeometry set for 1 feature \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 273950.9 ymin: 6862464 xmax: 554186.6 ymax: 7109132\nProjected CRS: GDA2020 / MGA zone 56\n\n\nMULTIPOLYGON (((523385.9 6965198, 523570.3 6965...\n\n\nNote that we don’t need to use the “EPSG:” part like we did when using project().\nThe nice thing about projecting vector data is that the values stay the same. So if you can, project your vector data into the CRS of your raster data.\n\n\n\nMany raster layers\nWe’ve been working with just one raster, but what if we want to do the same thing to many rasters at the same time?\nIn the data/Current_climate_QLD folder, there are 19 raster files. It would be painful to have to load, crop, mask and project each file individually. A very useful feature of rasters is that they can have many layers. These layers often represent different time periods, such as days or months, or different variables, such as temperature maximum, minimum and mean.\nFirst we need to load all 19 rasters. We can do this by getting the file names and then reading those file into a list.\n\nbioclim_list &lt;- list.files(\"data/Current_climate_QLD\", full.names = TRUE) |&gt; \n  lapply(FUN = rast)\n\nThe lapply() applies the rast() function to each file name, i.e. loads each raster, and places them into a list. If you haven’t encountered lists before, they can be a little confusing, but they are very helpful for holding any type of data. In our case, each element in the list is a raster. We can access each list element using the index. For example, to get the first object (in our case, raster), we do:\n\nbioclim_list[[1]]\n\nclass       : SpatRaster \ndimensions  : 681, 841, 1  (nrow, ncol, nlyr)\nresolution  : 0.05, 0.05  (x, y)\nextent      : 111.975, 154.025, -44.025, -9.975  (xmin, xmax, ymin, ymax)\ncoord. ref. : lon/lat WGS 84 (EPSG:4326) \nsource      : bioclim_01.tif \nname        : bioclim_01 \n\n\nWe can find out how long our list is using length():\n\nlength(bioclim_list)\n\n[1] 19\n\n\nThis is the same number of files that we read in: each raster is 1 element in the list.\nWe can manipulate the rasters in the list, but it is a little easier if we can just create a single raster object to work with. Happily we can create a multi-layer raster, with each of our rasters as one layer.\n\nbioclim_ras &lt;- rast(bioclim_list)\nbioclim_ras\n\nclass       : SpatRaster \ndimensions  : 681, 841, 19  (nrow, ncol, nlyr)\nresolution  : 0.05, 0.05  (x, y)\nextent      : 111.975, 154.025, -44.025, -9.975  (xmin, xmax, ymin, ymax)\ncoord. ref. : lon/lat WGS 84 (EPSG:4326) \nsources     : bioclim_01.tif  \n              bioclim_02.tif  \n              bioclim_03.tif  \n              ... and 16 more sources\nnames       : bioclim_01, bioclim_02, bioclim_03, bioclim_04, bioclim_05, bioclim_06, ... \n\n\nWe can see that we have many raster names, and the nlyr (number of layers) variable is now 19.\nWe can think of a multi-layer raster as a data sandwich (as my colleague likes to say!):\n\n\nCode\n#This is to create a stack of maps \n#The code is modified from: https://www.urbandemographics.org/post/figures-map-layers-r/\n\n#functions\nrotate_data &lt;- function(data, y_add) {\n  x_add = 0\n  \n  shear_matrix &lt;- function(){ matrix(c(2, 1.2, 0, 1), 2, 2) }\n  \n  rotate_matrix &lt;- function(x){ \n    matrix(c(cos(x), sin(x), -sin(x), cos(x)), 2, 2) \n  }\n  data %&gt;% \n    dplyr::mutate(\n      geometry = .$geometry * shear_matrix() * rotate_matrix(pi/20) + c(x_add, y_add)\n    )\n}\n\n#aggregate and polygonize data\ntemp_poly &lt;- aggregate(bioclim_ras, fact = 4) |&gt; \n  as.polygons(aggregate = FALSE) |&gt; \n  st_as_sf()\n  \n#make tilted plot\nggplot2::ggplot() +\n  ggplot2::geom_sf(data = rotate_data(temp_poly[,1], y_add = 0), ggplot2::aes(fill = .data[[names(temp_poly)[1]]]), color=NA, show.legend = FALSE) +\n  ggplot2::scale_fill_viridis_c() +\n  ggplot2::geom_sf(data = rotate_data(temp_poly[,7], y_add = 20), ggplot2::aes(fill = .data[[names(temp_poly)[7]]]), color=NA, show.legend = FALSE) +\n  ggplot2::scale_fill_viridis_c() +\n  ggplot2::geom_sf(data = rotate_data(temp_poly[,8], y_add = 40), ggplot2::aes(fill = .data[[names(temp_poly)[8]]]), color=NA, show.legend = FALSE) +\n  ggplot2::scale_fill_viridis_c() +\n  ggplot2::geom_sf(data = rotate_data(temp_poly[,5], y_add = 60), ggplot2::aes(fill = .data[[names(temp_poly)[5]]]), color=NA, show.legend = FALSE) +\n  ggplot2::scale_fill_viridis_c() +\n  ggplot2::theme_void()\n\n\n\n\n\n\n\n\n\nWe can use functions on our new multi-layer raster in the same way as we did for just one raster layer. We can map the rasters using the plot() function as normal:\n\nplot(bioclim_ras)\n\n\n\n\n\n\n\n\nNot all the rasters fit in the window, so only the first 16 are show.\nIt’s important to remember that if you want to put rasters into a multi-layer raster like we have done here, they must be the same extent, resolution, and crs.\nNow, we want to crop, mask and project our raster, same as we did with our single raster before. We can use exactly the same commands:\n\nbioclim_seq &lt;- bioclim_ras |&gt; \n  crop(seq_vect, mask = TRUE) |&gt; \n  project(crs(climate_seq_projected))\n\nJust three lines of codes and we’ve got our 19 rasters cropped, masked and projected! Let’s check everything looks right:\n\nplot(bioclim_seq)"
  },
  {
    "objectID": "Session 1/session_1_code.html#nice-maps",
    "href": "Session 1/session_1_code.html#nice-maps",
    "title": "Getting started with geospatial coding in R using the terra and sf packages",
    "section": "Nice maps",
    "text": "Nice maps\nSo far we have been using the plot() functions from the terra and sf packages. If you want to make detailed, publication quality maps, there are many great plotting packages such as tmap and ggplot. The final session of this workshop goes into detail about making nice maps, and there is an excellent section on map making in the Geocomputation with R book. For now, we will use the tmap package to make a nice map of our rasters with the SEQ polygon boundary.\nTo make maps using tmap, you build up layers. You add data layers to the map using tm_shape() and that is followed by another tm_ function that tells tmap what kind of data you are visualizing (e.g. raster, polygons, points) and how to show it (what colours, scales, etc.). First let’s plot some of the raster data. We will use just the first two rasters from our multi-layer raster:\n\ntm_shape(bioclim_seq[[1:2]]) +\n  tm_raster()\n\n\n\n\n\n\n\n\nWe will change colours and scales in a moment, but first let’s add our SEQ boundary polygon. We use tm_shape() to tell it what data we want to map, and then tm_borders() to show it as a border, not a filled polygon.\n\ntm_shape(bioclim_seq[[1:2]]) +\n  tm_raster() +\n  tm_shape(seq_boundary_projected) +\n  tm_borders()\n\n\n\n\n\n\n\n\nWe can add a scale bar and north arrow with two simple functions:\n\ntm_shape(bioclim_seq[[1:2]]) +\n  tm_raster() +\n  tm_shape(seq_boundary_projected) +\n  tm_borders() +\n  tm_scalebar() +\n  tm_compass()\n\n\n\n\n\n\n\n\nLet’s move the north arrow to the top left of the frame where there is some space, and set the scale bar to have marks at 0, 50 and 100 km. We will also change our raster scale colour palette:\n\ntm_shape(bioclim_seq[[1:2]]) +\n  tm_raster(col.scale = tm_scale_continuous(values = \"brewer.yl_or_rd\")) +\n  tm_shape(seq_boundary_projected) +\n  tm_borders() +\n  tm_scalebar(breaks = c(0, 50, 100)) +\n  tm_compass(position = c(\"left\", \"top\"))\n\n[plot mode] fit legend/component: Some legend items or map compoments do not\nfit well, and are therefore rescaled.\nℹ Set the tmap option `component.autoscale = FALSE` to disable rescaling.\n\n\n\n\n\n\n\n\n\nThere are a HUGE variety of colour scales available. A good way to see some options is to use the cols4all package that is installed when you install the tmap package:\n\ncols4all::c4a_gui()\n\nThis brings up a window where you can view many colour palettes and lots of information about them, such as if the palette is colour blind friendly.\nWe can make a few more tweaks to our maps to make them a bit neater:\n\ntm_shape(bioclim_seq[[1:2]]) +\n  tm_raster(col.scale = tm_scale_continuous(values = \"brewer.yl_or_rd\"),\n            col.legend = tm_legend(title = \"Temperature\", #Title for legends\n                                   orientation = \"landscape\")) + #change legends to landscape (horizontal) orientation\n  tm_shape(seq_boundary_projected) +\n  tm_borders() +\n  tm_scalebar(breaks = c(0, 50, 100)) +\n  tm_compass(position = c(\"left\", \"top\")) +\n  tm_layout(panel.labels = c(\"Climate layer 1\", \"Climate layer 2\")) #labels above each map\n\n[plot mode] fit legend/component: Some legend items or map compoments do not\nfit well, and are therefore rescaled.\nℹ Set the tmap option `component.autoscale = FALSE` to disable rescaling.\n\n\n\n\n\n\n\n\n\n\nInteractive maps\nIt’s often useful to see your data on a maps that you can move around on, with basemaps, such as satellite data, already loaded. There are two quick ways to do this. One is to use the plet() function from terra, which is just like plot(), but makes an interactive map, using the leaflet package behind the scenes:\n\nplet(bioclim_seq[[1]]) #show only the first layer of the multi-layer raster\n\n\n\n\n\nWe can choose a different basemap using the tiles = argument:\n\nplet(bioclim_seq[[1]], tiles = \"Esri.WorldImagery\")\n\n\n\n\n\nAnother way of making an interactive map is using tmap and the tmap_mode() function:\n\ntmap_mode(\"view\") #all tmap plots from now on will be interactive\n\nℹ tmap mode set to \"view\".\n\n#now we copy our tmap code from above\ntm_shape(bioclim_seq[[1:2]]) +\n  tm_raster(col.scale = tm_scale_continuous(values = \"brewer.yl_or_rd\"),\n            col.legend = tm_legend(title = \"Temperature\", #Title for legends\n                                   orientation = \"landscape\")) + #change legends to landscape (horizontal) orientation\n  tm_shape(seq_boundary_projected) +\n  tm_borders()\n\n[landscape legend in view mode] doesn't support labels yet\nThis message is displayed once per session.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntmap_mode(\"plot\") #reset the plotting to non-interactive\n\nℹ tmap mode set to \"plot\"."
  },
  {
    "objectID": "Session 1/session_1_code.html#saving",
    "href": "Session 1/session_1_code.html#saving",
    "title": "Getting started with geospatial coding in R using the terra and sf packages",
    "section": "Saving",
    "text": "Saving\nWe will need the SEQ polygon later, so lets save it using st_write():\n\nst_write(seq_boundary_projected, \"data/seq_boundary.gpkg\", append = FALSE)\n\nDeleting layer `seq_boundary' using driver `GPKG'\nWriting layer `seq_boundary' to data source \n  `data/seq_boundary.gpkg' using driver `GPKG'\nWriting 1 features with 0 fields and geometry type Multi Polygon.\n\n\nYou can save in many different formats (see st_drivers()). You can change the file format just by changing the file extension, e.g. use “seq_polygon.shp” if you want a shapefile.\nWe use the append = FALSE argument to overwrite a file with the same name. This is useful if you are making changes to code and want to make sure that the most up-to-date version of your data gets saved.\nWe will also need the cropped, masked and projected climate data. We can save rasters using the writeRaster() function from the terra package:\n\nwriteRaster(bioclim_seq, \"data/bioclim_seq.tif\", overwrite = TRUE)\n\nWe don’t need to save each raster as a separate file, instead we save a single multi-band Geotiff. Geotiff is a widely used raster file format and can be loaded by pretty much any GIS software.\nWe can check that this file will load as a multi-layer raster:\n\nrast(\"data/bioclim_seq.tif\")\n\nclass       : SpatRaster \ndimensions  : 48, 55, 19  (nrow, ncol, nlyr)\nresolution  : 5184.076, 5184.076  (x, y)\nextent      : 272527.9, 557652.1, 6861637, 7110473  (xmin, xmax, ymin, ymax)\ncoord. ref. : GDA2020 / MGA zone 56 (EPSG:7856) \nsource      : bioclim_seq.tif \nnames       : bioclim_01, bioclim_02, bioclim_03, bioclim_04, bioclim_05, bioclim_06, ... \nmin values  :   15.44909,    6.61918,   41.13598,   325.6700,   25.56623,   2.795907, ... \nmax values  :   21.47693,   14.57873,   50.49781,   548.4877,   34.20971,  12.623736, ..."
  },
  {
    "objectID": "Session 1/session_1_code.html#wrapping-up",
    "href": "Session 1/session_1_code.html#wrapping-up",
    "title": "Getting started with geospatial coding in R using the terra and sf packages",
    "section": "Wrapping-up",
    "text": "Wrapping-up\nWe’ve covered the basics of vector and raster manipulation in R using the sf and terra packages, and the tmap package for making maps. This is a relatively short introduction to a lot of geospatial concepts, but should provide the background you need for the following sessions which focus on data retrieval, manipulation and modelling."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Maybe some info about contributors?\n\n\n\n Back to top"
  },
  {
    "objectID": "Session 5/session_5_home.html",
    "href": "Session 5/session_5_home.html",
    "title": "Session 5",
    "section": "",
    "text": "Landing page for Session 5.\n\n\n\n Back to top"
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html",
    "href": "Session 3/ICCB_Modelling_and_validation.html",
    "title": "ICCB Species distribution modelling and validation",
    "section": "",
    "text": "We wrote this script drawing on some of the following resources:\n-Ecocommons Notebooks https://www.ecocommons.org.au/notebooks/\n-Damaris Zurell’s SDM Intro https://damariszurell.github.io/SDM-Intro/\nhttps://damariszurell.github.io/EEC-MGC/b4_SDM_eval.html"
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#import-packages",
    "href": "Session 3/ICCB_Modelling_and_validation.html#import-packages",
    "title": "ICCB Species distribution modelling and validation",
    "section": "Import packages",
    "text": "Import packages\n\n\nCode\nlibrary(dplyr)\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCode\nlibrary(purrr)\nlibrary(ggplot2)\nlibrary(terra)\n\n\nterra 1.8.50\n\n\nCode\nlibrary(sf)\n\n\nLinking to GEOS 3.13.0, GDAL 3.8.5, PROJ 9.5.1; sf_use_s2() is TRUE\n\n\nCode\nlibrary(predicts)\nlibrary(blockCV)\n\n\nblockCV 3.1.5\n\n\nCode\nlibrary(ecospat)\nlibrary(usdm)\nlibrary(randomForest)\n\n\nrandomForest 4.7-1.2\n\n\nType rfNews() to see new features/changes/bug fixes.\n\n\n\nAttaching package: 'randomForest'\n\n\nThe following object is masked from 'package:ggplot2':\n\n    margin\n\n\nThe following object is masked from 'package:dplyr':\n\n    combine\n\n\nCode\nlibrary(precrec)\nlibrary(corrplot)\n\n\ncorrplot 0.95 loaded\n\n\nCode\n# Install the mecofun package, used in the materials at https://damariszurell.github.io/SDM-Intro/\nlibrary(devtools)\n\n\nLoading required package: usethis\n\n\nCode\ndevtools::install_git(\"https://gitup.uni-potsdam.de/macroecology/mecofun.git\")\n\n\nSkipping install of 'mecofun' from a xgit remote, the SHA1 (feb82c4a) has not changed since last install.\n  Use `force = TRUE` to force installation\n\n\nCode\n# Load the mecofun package\nlibrary(mecofun)"
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#load-koala-presences-and-background-points",
    "href": "Session 3/ICCB_Modelling_and_validation.html#load-koala-presences-and-background-points",
    "title": "ICCB Species distribution modelling and validation",
    "section": "Load koala presences and background points",
    "text": "Load koala presences and background points\nThey are loaded as spatvectors, but we also want them as dataframes for model input requirements.\n\n\nCode\nkoala_occ &lt;- vect(\"Data/Biological_records/SEQ_koala_occurrences.shp\")\nbackground &lt;- vect(\"Data/Biological_records/background_points_2.5k_random.shp\")\n\n# Make a dataframe of just x, y and presence\nkoala_occ_df &lt;- koala_occ %&gt;% \n  as.data.frame(geom = \"XY\") %&gt;% \n  dplyr::select(x,y) %&gt;% \n  mutate(Presence = 1)\n\nhead(koala_occ_df)\n\n\n\n  \n\n\n\nCode\nbackground_df &lt;- background %&gt;% \n  as.data.frame(geom = \"XY\") %&gt;% \n  dplyr::select(x,y) %&gt;% \n  mutate(Presence = 0)\n\nhead(background_df)\n\n\n\n  \n\n\n\nCode\n# Combine to one\npr_bg &lt;- rbind(koala_occ_df, background_df)"
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#load-environmental-covariates",
    "href": "Session 3/ICCB_Modelling_and_validation.html#load-environmental-covariates",
    "title": "ICCB Species distribution modelling and validation",
    "section": "Load environmental covariates",
    "text": "Load environmental covariates\nLoading current covariate rasters. We formatted these rasters in the same way as the Koala data, so that they are all in the same projection and extent. We did this in the script: ‘ICCB_Environmental_data.qmd’\n\n\nCode\ncovs_current &lt;- rast(\"Data/Environmental_variables/current_bioclim.tif\")\n\n\n# Define the BIOCLIM names for the raster layers\nlayer_names &lt;- c(\n  \"BIO1_Annual_Mean_Temp\",\n  \"BIO2_Mean_Diurnal_Temp_Range\",\n  \"BIO3_Isothermality\",\n  \"BIO4_Temperature_Seasonality\",\n  \"BIO5_Max_Temp_Warmest_Month\",\n  \"BIO6_Min_Temp_Coldest_Month\",\n  \"BIO7_Temperature_Annual_Range\",\n  \"BIO8_Mean_Temp_Wettest_Quarter\",\n  \"BIO9_Mean_Temp_Driest_Quarter\",\n  \"BIO10_Mean_Temp_Warmest_Quarter\",\n  \"BIO11_Mean_Temp_Coldest_Quarter\",\n  \"BIO12_Annual_Precipitation\",\n  \"BIO13_Precip_Wettest_Month\",\n  \"BIO14_Precip_Driest_Month\",\n  \"BIO15_Precip_Seasonality\",\n  \"BIO16_Precip_Wettest_Quarter\",\n  \"BIO17_Precip_Driest_Quarter\",\n  \"BIO18_Precip_Warmest_Quarter\",\n  \"BIO19_Precip_Coldest_Quarter\")\n\nnames(covs_current) &lt;- layer_names"
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#covariate-selection",
    "href": "Session 3/ICCB_Modelling_and_validation.html#covariate-selection",
    "title": "ICCB Species distribution modelling and validation",
    "section": "Covariate selection",
    "text": "Covariate selection\n\nOption 1. Narrow down potential covariates based on ecological knowledge\nFor this example, we had advice from CSIRO scientists who conducted an expert elicitation to gather a set of potential covariates that are likely to be important for koalas. We use this knowledge to filter out the key bioclim variables.\nWe select the following: Bio5 : Max temp of the warmest month (mainly for the northern populations) Bio6 : Min temp of the coldest month (mainly for southern populations, which essentially excludes alpine regions) Bio12 : Annual Precipitation Bio15 : Precipitation seasonality (coefficient of variation)\n\n\nCode\nfor(i in 1:nlyr(covs_current)) {\n  terra::plot(covs_current[[i]], main = names(covs_current)[[i]])\n}"
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#show-the-four-from-expert-elicitation-the-layers",
    "href": "Session 3/ICCB_Modelling_and_validation.html#show-the-four-from-expert-elicitation-the-layers",
    "title": "ICCB Species distribution modelling and validation",
    "section": "Show the four from expert elicitation the layers",
    "text": "Show the four from expert elicitation the layers\n\n\nCode\ncovs_current_expert &lt;- subset(covs_current, names(covs_current) %in% c(\"BIO5_Max_Temp_Warmest_Month\", \n                                                                       \"BIO6_Min_Temp_Coldest_Month\", \n                                                                       \"BIO12_Annual_Precipitation\", \n                                                                       \"BIO15_Precip_Seasonality\"))\n\nfor(i in 1:nlyr(covs_current_expert)) {\n  terra::plot(covs_current_expert[[i]], main = names(covs_current_expert)[[i]])\n}"
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#extract-environmental-covariate-values-from-presence-and-background-locations-training-locations",
    "href": "Session 3/ICCB_Modelling_and_validation.html#extract-environmental-covariate-values-from-presence-and-background-locations-training-locations",
    "title": "ICCB Species distribution modelling and validation",
    "section": "Extract environmental covariate values from presence and background locations (training locations)",
    "text": "Extract environmental covariate values from presence and background locations (training locations)\n\n\nCode\ntrain_PB_covs &lt;- terra::extract(covs_current, pr_bg[,c(\"x\", \"y\")], xy = T)\ntrain_PB_covs &lt;- cbind(train_PB_covs, pr_bg[\"Presence\"])\n\n# Remove rows where there's values missing from at least one covariate\nprint(paste0(\"RECORDS FROM \", nrow(train_PB_covs) - sum(complete.cases(train_PB_covs)), \" ROWS IN TRAINING DATA REMOVED DUE TO MISSING COVARIATE VALUES\"))\n\n\n[1] \"RECORDS FROM 68 ROWS IN TRAINING DATA REMOVED DUE TO MISSING COVARIATE VALUES\"\n\n\nCode\ntrain_PB_covs &lt;- train_PB_covs[complete.cases(train_PB_covs), ] \ntrain_PB_covs &lt;- dplyr::select(train_PB_covs, -ID)\n\nhead(train_PB_covs)"
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#thin-the-koala-presence-points-for-tutorial-only",
    "href": "Session 3/ICCB_Modelling_and_validation.html#thin-the-koala-presence-points-for-tutorial-only",
    "title": "ICCB Species distribution modelling and validation",
    "section": "Thin the koala presence points (for tutorial only)",
    "text": "Thin the koala presence points (for tutorial only)\nWe now thin the presences to reduce the number of points to a manageable size for plotting and modelling. This is not a recommended step for real data, but is done here to make the tutorial run faster and to make the plots clearer.\n\n\nCode\ntrain_PB_covs_pres &lt;- train_PB_covs %&gt;% filter(Presence == 1)\ntrain_PB_covs_bg &lt;- train_PB_covs %&gt;% filter(Presence == 0)\n\n# Thin the presences for plotting\ntrain_PB_covs_pres_thin &lt;- train_PB_covs_pres[sample(nrow(train_PB_covs_pres), 10000), ]\n\n# Combine back into both presence and background\ntrain_PB_covs_thinned &lt;- rbind(train_PB_covs_pres_thin, train_PB_covs_bg)"
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#check-correlation-and-multicollinearity-of-covariates",
    "href": "Session 3/ICCB_Modelling_and_validation.html#check-correlation-and-multicollinearity-of-covariates",
    "title": "ICCB Species distribution modelling and validation",
    "section": "Check correlation and multicollinearity of covariates",
    "text": "Check correlation and multicollinearity of covariates\n\nCorrelation plot\nThere are several different methods for creating correlation plots.\n\n\nCode\necospat.cor.plot(covs_current_expert)\n\n\n\n\n\n\n\n\n\n\n\nUsing the corplots package\nFor a simple and quick plot.\n\n\nCode\ncorplots &lt;- ENMTools::raster.cor.plot(covs_current_expert)\ncorplots$cor.mds.plot\n\n\n\n\n\n\n\n\n\nCode\ncorplots$cor.heatmap\n\n\n\n\n\n\n\n\n\nHere, we use the corrplot package to create a correlation plot of the selected covariates (this is taken from an EcoCommons Australia notebook).\n\n\nCode\n# Select columns by their names\ncor_data &lt;- train_PB_covs[, names(train_PB_covs) %in% c(\"BIO5_Max_Temp_Warmest_Month\", \n                                                        \"BIO6_Min_Temp_Coldest_Month\", \n                                                        \"BIO12_Annual_Precipitation\", \n                                                        \"BIO15_Precip_Seasonality\")]\n\n# Check the structure of the numeric data\nstr(cor_data)\n\n\n'data.frame':   88136 obs. of  4 variables:\n $ BIO5_Max_Temp_Warmest_Month: num  29.7 30.5 30.5 29.7 30.2 ...\n $ BIO6_Min_Temp_Coldest_Month: num  9.39 8.94 8.49 9.96 8.96 ...\n $ BIO12_Annual_Precipitation : num  1238 1165 1161 1223 1109 ...\n $ BIO15_Precip_Seasonality   : num  92.9 98.8 99.5 88.9 97.2 ...\n\n\nCode\n# Calculate the correlation matrix for the numeric columns\ncor_matrix &lt;- cor(cor_data, use = \"complete.obs\", method = \"pearson\")\n\n\ncorrplot(cor_matrix,\n         method = \"color\",            # Use colored squares for correlation\n         type = \"upper\",              # Show upper triangle only\n         order = \"hclust\",            # Reorder variables hierarchically\n         addCoef.col = \"black\",       # Show correlation coefficients in black\n         number.cex = 0.5,            # Reduce the size of correlation labels\n         tl.col = \"black\",            # Text label color\n         tl.srt = 30,                 # Rotate labels slightly for readability\n         tl.cex = 0.5,                # Reduce text size of variable labels (set smaller valu)\n         cl.cex = 0.8,                # Reduce text size of color legend\n         diag = FALSE,                # Hide diagonal\n         col = colorRampPalette(c(\"#11aa96\", \"#61c6fa\", \"#f6aa70\"))(200),\n         sig.level = 0.01, insig = \"blank\")\n\n\n\n\n\n\n\n\n\n\n\nVariance Inflation Factor (VIF)\nIf you find corrplot is hard for you to make decisions, we can use Variance Inflation Factor (VIF). VIF is another statistical measure used to detect multicollinearity in a set of explanatory (independent) variables in a regression model.\nInterpretation:\n\nVIF = 1: No correlation\nVIF &gt; 1 and &lt;= 5: Moderate correlation; may not require corrective action.\nVIF &gt; 5: Indicates high correlation. Multicollinearity may be problematic, and further investigation is recommended.\nVIF &gt; 10: Strong multicollinearity. The variable is highly collinear with others, and steps should be taken to address this.\n\n\n\nCode\n# usdm::vif(covs_current_expert) # just VIF for all covariates\nusdm::vifstep(covs_current_expert) # Variance Inflation Factor and test for multicollinearity\n\n\nNo variable from the 4 input variables has collinearity problem. \n\nThe linear correlation coefficients ranges between: \nmin correlation ( BIO15_Precip_Seasonality ~ BIO6_Min_Temp_Coldest_Month ):  -0.2756697 \nmax correlation ( BIO12_Annual_Precipitation ~ BIO6_Min_Temp_Coldest_Month ):  0.8769718 \n\n---------- VIFs of the remained variables -------- \n                    Variables      VIF\n1 BIO5_Max_Temp_Warmest_Month 2.751370\n2 BIO6_Min_Temp_Coldest_Month 4.528719\n3  BIO12_Annual_Precipitation 6.888077\n4    BIO15_Precip_Seasonality 1.263385"
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#exploration-of-the-koala-presence-and-background-data",
    "href": "Session 3/ICCB_Modelling_and_validation.html#exploration-of-the-koala-presence-and-background-data",
    "title": "ICCB Species distribution modelling and validation",
    "section": "Exploration of the koala presence and background data",
    "text": "Exploration of the koala presence and background data\nIt is good practice to assess where in the environmental space the presence and background points are located. This can help to identify if there are any potential issues with the data, such as a lack of background points in certain areas of environmental space, and should show any patterns in the data that the model should pick up.\n\n\nCode\n# Iterate over all of the variables to create density plots of the background and presence data\nfor(i in 1:ncol(train_PB_covs_thinned)) {\n  \n  print(ggplot() +\n          geom_density(data = train_PB_covs_thinned, \n                       aes(x = .data[[names(train_PB_covs_thinned)[i]]], fill = as.factor(Presence)), \n                       alpha = 0.5) +\n    theme_bw() +\n    labs(title = names(train_PB_covs_thinned)[i]))\n  \n}"
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#null-model",
    "href": "Session 3/ICCB_Modelling_and_validation.html#null-model",
    "title": "ICCB Species distribution modelling and validation",
    "section": "Null model",
    "text": "Null model\nNull model: no explanatory variables or predictors are included.\nIt is always helpful to create a null model as a benchmark to assess how the inclusion of explanatory variables improves the model.\n\n\nCode\n# Fit a null model with only the intercept\nnull_model &lt;- glm(Presence ~ 1,\n                  data = train_PB_covs,\n                  family = binomial(link = \"logit\"))\n\n# Check the model results\nsummary(null_model)\n\n\n\nCall:\nglm(formula = Presence ~ 1, family = binomial(link = \"logit\"), \n    data = train_PB_covs)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  4.08096    0.02636   154.8   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 14902  on 88135  degrees of freedom\nResidual deviance: 14902  on 88135  degrees of freedom\nAIC: 14904\n\nNumber of Fisher Scoring iterations: 7"
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#glm-model-1---expert-variables",
    "href": "Session 3/ICCB_Modelling_and_validation.html#glm-model-1---expert-variables",
    "title": "ICCB Species distribution modelling and validation",
    "section": "GLM Model 1 - expert variables",
    "text": "GLM Model 1 - expert variables\n\n\nCode\nglm_model_1 &lt;- glm(Presence ~ \n                     BIO5_Max_Temp_Warmest_Month + \n                     BIO6_Min_Temp_Coldest_Month + \n                     BIO12_Annual_Precipitation + \n                     BIO15_Precip_Seasonality,\n                   data=train_PB_covs_thinned,\n                   family = binomial(link = \"logit\"))\n\n# Check the model results\nsummary(glm_model_1)\n\n\n\nCall:\nglm(formula = Presence ~ BIO5_Max_Temp_Warmest_Month + BIO6_Min_Temp_Coldest_Month + \n    BIO12_Annual_Precipitation + BIO15_Precip_Seasonality, family = binomial(link = \"logit\"), \n    data = train_PB_covs_thinned)\n\nCoefficients:\n                              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)                 -5.1633283  1.5710088  -3.287  0.00101 ** \nBIO5_Max_Temp_Warmest_Month -0.6523178  0.0526585 -12.388  &lt; 2e-16 ***\nBIO6_Min_Temp_Coldest_Month  0.8807456  0.0283998  31.012  &lt; 2e-16 ***\nBIO12_Annual_Precipitation  -0.0030273  0.0002765 -10.949  &lt; 2e-16 ***\nBIO15_Precip_Seasonality     0.2504815  0.0108866  23.008  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 8758.5  on 11463  degrees of freedom\nResidual deviance: 5671.7  on 11459  degrees of freedom\nAIC: 5681.7\n\nNumber of Fisher Scoring iterations: 6\n\n\nCode\n# These response curves don't look very helpful\ndismo::response(glm_model_1)"
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#glm-model-2---expert-variables-with-quadratics",
    "href": "Session 3/ICCB_Modelling_and_validation.html#glm-model-2---expert-variables-with-quadratics",
    "title": "ICCB Species distribution modelling and validation",
    "section": "GLM Model 2 - expert variables with quadratics",
    "text": "GLM Model 2 - expert variables with quadratics\nIn this model, we include quadratic terms for the covariates. This is a common approach in species distribution modelling to account for non-linear relationships between the predictors and the response variable. This increases the complexity of the model and allows for more flexibility in fitting the data.\n\n\nCode\nglm_model_2 &lt;- glm(Presence ~ \n                     BIO5_Max_Temp_Warmest_Month + I(BIO5_Max_Temp_Warmest_Month^2) + \n                     BIO6_Min_Temp_Coldest_Month + I(BIO6_Min_Temp_Coldest_Month^2) + \n                     BIO12_Annual_Precipitation + I(BIO12_Annual_Precipitation^2) + \n                     BIO15_Precip_Seasonality + I(BIO15_Precip_Seasonality^2), \n                   data=train_PB_covs_thinned,\n                   family = binomial(link = \"logit\"))\n\n# Check the model results\nsummary(glm_model_2)\n\n\n\nCall:\nglm(formula = Presence ~ BIO5_Max_Temp_Warmest_Month + I(BIO5_Max_Temp_Warmest_Month^2) + \n    BIO6_Min_Temp_Coldest_Month + I(BIO6_Min_Temp_Coldest_Month^2) + \n    BIO12_Annual_Precipitation + I(BIO12_Annual_Precipitation^2) + \n    BIO15_Precip_Seasonality + I(BIO15_Precip_Seasonality^2), \n    family = binomial(link = \"logit\"), data = train_PB_covs_thinned)\n\nCoefficients:\n                                   Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)                      -7.497e+01  1.843e+01  -4.067 4.76e-05 ***\nBIO5_Max_Temp_Warmest_Month      -1.271e+00  1.212e+00  -1.048   0.2945    \nI(BIO5_Max_Temp_Warmest_Month^2)  1.113e-02  1.964e-02   0.567   0.5708    \nBIO6_Min_Temp_Coldest_Month      -1.028e+00  1.908e-01  -5.386 7.21e-08 ***\nI(BIO6_Min_Temp_Coldest_Month^2)  1.392e-01  1.287e-02  10.816  &lt; 2e-16 ***\nBIO12_Annual_Precipitation        1.044e-03  1.938e-03   0.539   0.5901    \nI(BIO12_Annual_Precipitation^2)  -1.393e-06  6.913e-07  -2.016   0.0438 *  \nBIO15_Precip_Seasonality          1.885e+00  2.375e-01   7.939 2.04e-15 ***\nI(BIO15_Precip_Seasonality^2)    -8.166e-03  1.268e-03  -6.439 1.20e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 8758.5  on 11463  degrees of freedom\nResidual deviance: 5526.5  on 11455  degrees of freedom\nAIC: 5544.5\n\nNumber of Fisher Scoring iterations: 6\n\n\nCode\n# These response curves don't look very helpful\ndismo::response(glm_model_2)"
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#model-effect-evaluation",
    "href": "Session 3/ICCB_Modelling_and_validation.html#model-effect-evaluation",
    "title": "ICCB Species distribution modelling and validation",
    "section": "Model effect evaluation",
    "text": "Model effect evaluation\nHere we use a function presented in an EcoCommons Australia notebook to evaluate the model performance. The notebook can be found on their GitHub: https://github.com/EcoCommonsAustralia/notebooks/tree/main/notebooks.\n\n\nCode\n# Function to plot effect size graph\nplot_effect_size &lt;- function(glm_model) {\n  # Check if required libraries are installed\n  if (!requireNamespace(\"ggplot2\", quietly = TRUE)) {\n    stop(\"Please install the 'ggplot2' package to use this function.\")\n  }\n  library(ggplot2)\n\n  # Extract effect sizes (coefficients) from the model\n  coefs &lt;- summary(glm_model)$coefficients\n  effect_sizes &lt;- data.frame(\n    Variable = rownames(coefs)[-1],  # Exclude the intercept\n    Effect_Size = coefs[-1, \"Estimate\"],\n    Std_Error = coefs[-1, \"Std. Error\"]\n  )\n\n  # Sort by effect size\n  effect_sizes &lt;- effect_sizes[order(-abs(effect_sizes$Effect_Size)), ]\n\n  # Plot the effect sizes with error bars\n  ggplot(effect_sizes, aes(x = reorder(Variable, Effect_Size), y = Effect_Size)) +\n    geom_bar(stat = \"identity\", fill = \"#11aa96\") +\n    geom_errorbar(aes(ymin = Effect_Size - Std_Error, ymax = Effect_Size + Std_Error), width = 0.2) +\n    coord_flip() +\n    labs(\n      title = \"Effect Sizes of Variables\",\n      x = \"Variable\",\n      y = \"Effect Size (Coefficient Estimate)\"\n    ) +\n    theme_minimal()\n}"
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#use-the-function-to-check-the-effect-sizes",
    "href": "Session 3/ICCB_Modelling_and_validation.html#use-the-function-to-check-the-effect-sizes",
    "title": "ICCB Species distribution modelling and validation",
    "section": "Use the function to check the effect sizes",
    "text": "Use the function to check the effect sizes\nWe need to be careful when interpreting the effect sizes of models with quadratic terms however, as the response curve depends on the linear and the quadratic term.\n\n\nCode\n# Example usage of effect size plot\nplot_effect_size(glm_model_1)\n\n\n\n\n\n\n\n\n\nCode\nplot_effect_size(glm_model_2)"
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#response-curves",
    "href": "Session 3/ICCB_Modelling_and_validation.html#response-curves",
    "title": "ICCB Species distribution modelling and validation",
    "section": "Response curves",
    "text": "Response curves\nAgain, we can use a function from the EcoCommons notebook to plot the response curves from the model, although for quadratics we need to adjust the function or use something else.\n\n\nCode\nplot_species_response &lt;- function(glm_model, predictors, data) {\n  # Check if required libraries are installed\n  if (!requireNamespace(\"ggplot2\", quietly = TRUE) || !requireNamespace(\"gridExtra\", quietly = TRUE)) {\n    stop(\"Please install the 'ggplot2' and 'gridExtra' packages to use this function.\")\n  }\n  library(ggplot2)\n  library(gridExtra)\n\n  # Create empty list to store response plots\n  response_plots &lt;- list()\n\n  # Loop through each predictor variable\n  for (predictor in predictors) {\n    # Create new data frame to vary predictor while keeping others constant\n    pred_range &lt;- seq(\n      min(data[[predictor]], na.rm = TRUE),\n      max(data[[predictor]], na.rm = TRUE),\n      length.out = 100\n    )\n    const_data &lt;- data[1, , drop = FALSE]  # Use first row to keep other predictors constant\n    response_data &lt;- const_data[rep(1, 100), ]  # Duplicate the row\n    response_data[[predictor]] &lt;- pred_range\n\n    # Predict probabilities\n    predicted_response &lt;- predict(glm_model, newdata = response_data, type = \"response\")\n\n    # Create data frame for plotting\n    plot_data &lt;- data.frame(\n      Predictor_Value = pred_range,\n      Predicted_Probability = predicted_response\n    )\n\n    # Add presence and absence data\n    presence_absence_data &lt;- data.frame(\n      Predictor_Value = data[[predictor]],\n      Presence_Absence = data$Presence\n    )\n\n    # Generate the response plot\n    p &lt;- ggplot() +\n      \n      geom_line(data = plot_data, \n                aes(x = Predictor_Value, y = Predicted_Probability), \n                color = \"#61c6fa\", linewidth = 1) +\n      \n      geom_point(data = presence_absence_data[presence_absence_data$Presence_Absence == 1, ], \n                 aes(x = Predictor_Value, y = Presence_Absence), \n                 color = \"#11aa96\", alpha = 0.6) +\n      \n      geom_point(data = presence_absence_data[presence_absence_data$Presence_Absence == 0, ], \n                 aes(x = Predictor_Value, y = Presence_Absence), \n                 color = \"#f6aa70\", alpha = 0.6) +\n      \n      labs(x = predictor, y = NULL) +\n      theme_minimal() +\n      theme(axis.title.y = element_blank())\n\n    # Store the plot in the list\n    response_plots[[predictor]] &lt;- p\n  }\n\n  # Arrange all plots in one combined plot with a single shared y-axis label\n  grid.arrange(\n    grobs = response_plots,\n    ncol = 3,\n    left = \"Predicted Probability / Presence-Absence\"\n  )\n}"
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#use-the-response-curve-function",
    "href": "Session 3/ICCB_Modelling_and_validation.html#use-the-response-curve-function",
    "title": "ICCB Species distribution modelling and validation",
    "section": "Use the response curve function",
    "text": "Use the response curve function\n\n\nCode\npredictors &lt;- c(\"BIO5_Max_Temp_Warmest_Month\", \n                \"BIO6_Min_Temp_Coldest_Month\", \n                \"BIO12_Annual_Precipitation\", \n                \"BIO15_Precip_Seasonality\")\n\nplot_species_response(glm_model_1, predictors, train_PB_covs_thinned)\n\n\n\nAttaching package: 'gridExtra'\n\n\nThe following object is masked from 'package:randomForest':\n\n    combine\n\n\nThe following object is masked from 'package:dplyr':\n\n    combine\n\n\n\n\n\n\n\n\n\n\nModel 1 partial responses\n\n\nCode\n# Plot the partial responses\npartial_response(glm_model_1, predictors = train_PB_covs_thinned[,predictors], main='GLM')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Plot inflated response curves:\ninflated_response(glm_model_1, predictors = train_PB_covs_thinned[,predictors], method = \"stat3\", lwd = 3, main='GLM') \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel 2 partial responses\n\n\nCode\n# Plot the partial responses\npartial_response(glm_model_2, predictors = train_PB_covs_thinned[,predictors], main='GLM')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Plot inflated response curves:\ninflated_response(glm_model_2, predictors = train_PB_covs_thinned[,predictors], method = \"stat3\", lwd = 3, main='GLM')"
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#glm-predictions-to-current-environment",
    "href": "Session 3/ICCB_Modelling_and_validation.html#glm-predictions-to-current-environment",
    "title": "ICCB Species distribution modelling and validation",
    "section": "GLM predictions to current environment",
    "text": "GLM predictions to current environment\n\nModel 1\n\n\nCode\n# Predict the presence probability across the entire raster extent\npredicted_raster_model_1 &lt;- predicts::predict(covs_current_expert, glm_model_1, type = \"response\")\n\n# Plot the species distribution raster\nplot(\n  predicted_raster_model_1,\n  range = c(0, 1),  # Set min and max values for the color scale\n  main = \"Relative Probability of Occurrence of Koalas in SEQ - GLM 1\"\n)\n\n\n\n\n\n\n\n\n\n\n\nModel 2\n\n\nCode\n# Predict the presence probability across the entire raster extent\npredicted_raster_model_2 &lt;- predicts::predict(covs_current_expert, glm_model_2, type = \"response\")\n\n# Plot the species distribution raster\nplot(\n  predicted_raster_model_2,\n  range = c(0, 1),  # Set min and max values for the color scale\n  main = \"Relative Probability of Occurrence of Koalas in SEQ - GLM 2\"\n)"
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#data-preparation",
    "href": "Session 3/ICCB_Modelling_and_validation.html#data-preparation",
    "title": "ICCB Species distribution modelling and validation",
    "section": "Data preparation",
    "text": "Data preparation\n\n\n\n\n\n\n\n\n\n\nCalculate the case weights (down/up-weighting)\nBecause we have a ‘class imbalance’ (uneven number of presences and background points), we are making their ‘weight’ in the model equal.\n\n\nCode\npresNum &lt;- as.numeric(table(train_PB_covs_thinned$Presence)[\"1\"]) # number of presences\nbgNum &lt;- as.numeric(table(train_PB_covs_thinned$Presence)[\"0\"]) # number of backgrounds\nweight &lt;- ifelse(train_PB_covs_thinned$Presence == 1, 1, presNum / bgNum) # down-weighting\n\n\n\n\nPrepare for fitting the RF model(s)\n\n\nCode\n# If wanting to fit a classification model\n# Convert the response to factor for producing class relative likelihood\ntrain_PB_covs_thinned$Presence_Factor &lt;- as.factor(train_PB_covs_thinned$Presence)\n\n# For down-sampling, the number of background (0s) in each bootstrap sample should the same as presences\n# (1s). For this, we use sampsize argument to do this.\n# We need to choose the SMALLER number out of the two classes\nsample_size &lt;- c(\"0\" = bgNum, \"1\" = bgNum)\nsample_size &lt;- c(bgNum)"
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#random-forest-model---expert-covariates",
    "href": "Session 3/ICCB_Modelling_and_validation.html#random-forest-model---expert-covariates",
    "title": "ICCB Species distribution modelling and validation",
    "section": "Random Forest Model - expert covariates",
    "text": "Random Forest Model - expert covariates\n\nClassification or regression model?\n\n\nCode\n# # Specify the model formula - classification\n# model_formula &lt;- as.formula(Presence_Factor ~ \n#                               BIO5_Max_Temp_Warmest_Month + \n#                               BIO6_Min_Temp_Coldest_Month + \n#                               BIO12_Annual_Precipitation + \n#                               BIO15_Precip_Seasonality)\n\n# Specify the model formula - regression\nmodel_formula &lt;- as.formula(Presence ~ \n                              BIO5_Max_Temp_Warmest_Month + \n                              BIO6_Min_Temp_Coldest_Month + \n                              BIO12_Annual_Precipitation + \n                              BIO15_Precip_Seasonality)\n\n\n\n\nFit the random forest model\nThis will throw a warning as we only have two unique values (0s and 1s), but in our case that is fine, and you can ignore the warning.\n\n\nCode\nrf_1 &lt;- randomForest::randomForest(formula = model_formula,\n                                   data = train_PB_covs_thinned,\n                                   weights = weight,\n                                   ntree = 1000,\n                                   sampsize = sample_size,\n                                   replace = T, \n                                   importance=TRUE)\n\n\nWarning in randomForest.default(m, y, ...): The response has five or fewer\nunique values.  Are you sure you want to do regression?\n\n\n\n\nCheck the model results\n\n\nCode\n# Model summary\nrf_1\n\n\n\nCall:\n randomForest(formula = model_formula, data = train_PB_covs_thinned,      weights = weight, ntree = 1000, sampsize = sample_size, replace = T,      importance = TRUE) \n               Type of random forest: regression\n                     Number of trees: 1000\nNo. of variables tried at each split: 1\n\n          Mean of squared residuals: 0.08394254\n                    % Var explained: 24.64\n\n\nCode\n# Variable importance:\nimportance(rf_1)\n\n\n                              %IncMSE IncNodePurity\nBIO5_Max_Temp_Warmest_Month  97.30508      70.28901\nBIO6_Min_Temp_Coldest_Month 113.83596     103.48376\nBIO12_Annual_Precipitation   78.26095      82.27573\nBIO15_Precip_Seasonality     79.29062      47.90045\n\n\nCode\n# Plot variable importance\nvarImpPlot(rf_1, type = 1)\n\n\n\n\n\n\n\n\n\nCode\n# Look at single trees:\nhead(getTree(rf_1,1,T))\n\n\n\n  \n\n\n\n\n\nPartial dependence plots\n\n\nCode\n# Now, we plot response curves in the same way as we did for GLMs above:\npartial_response(rf_1, predictors = train_PB_covs_thinned[,predictors], main='Random Forest')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Plot inflated response curves:\ninflated_response(rf_1, predictors = train_PB_covs_thinned[,predictors], method = \"stat3\", lwd = 3, main='Random Forest') \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRandom Forest predictions\n\n\nCode\n# Predict the presence probability across the entire raster extent\npredicted_raster_RF_1 &lt;- predicts::predict(covs_current_expert, rf_1, type = \"response\")\n\n# Plot the species distribution raster\nplot(\n  predicted_raster_RF_1,\n  range = c(0, 1),  # Set min and max values for the color scale\n  main = \"Relative Probability of Occurrence of Koalas in SEQ - RF 1\"\n)\n\n\n\n\n\n\n\n\n\nCode\nwriteRaster(predicted_raster_RF_1, \n            filename = \"outputs/current_distribution_RF_1.tif\", \n            overwrite = TRUE)"
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#run-the-model-for-every-fold-and-evaluate",
    "href": "Session 3/ICCB_Modelling_and_validation.html#run-the-model-for-every-fold-and-evaluate",
    "title": "ICCB Species distribution modelling and validation",
    "section": "Run the model for every fold and evaluate",
    "text": "Run the model for every fold and evaluate\n\nModel evaluation - metrics\nTypically, it helps to evaluate your model with several metrics that describe different features of model performance and prediction. Here, we define a function to feed in a model prediction and calculate several evaluation metrics.\nThe metrics are:\n-Area under the receiver operating characteristic curve (AUC ROC)\nHigher values of this (closer to 1) suggest a model is good at distinguishing presence points from the background.\n-Continuous boyce index\nHigher values of this (closer to 1) suggest a model is good at predicting higher suitability at spots where there were presences.\n\n\nCode\n# Start a dataframe to save results\neval_df &lt;- data.frame(fold = numeric(),\n                      ROC = numeric(),\n                      boyce = numeric())\n\nfor(f in seq_along(spfolds)) {\n  \n  # Subset the training and testing data (spatial cross validation) (for the fth fold)\n  \n  train_PB_covs_scv &lt;- train_PB_covs_thinned[spfolds[[f]][[1]], ]\n  test_PB_covs_scv &lt;- train_PB_covs_thinned[spfolds[[f]][[2]], ]\n  \n  glm_model_1 &lt;- glm(Presence ~ \n                     BIO5_Max_Temp_Warmest_Month + \n                     BIO6_Min_Temp_Coldest_Month + \n                     BIO12_Annual_Precipitation + \n                     BIO15_Precip_Seasonality,\n                   data=train_PB_covs_scv,\n                   family = binomial(link = \"logit\"))\n  \n    # Predict to the testing data of fold f\n  test_PB_covs_scv$pred &lt;- predict(glm_model_1, newdata = test_PB_covs_scv, type = \"response\")\n\n  # Evaluate prediction on test set\n  ROC = precrec::auc(precrec::evalmod(scores = test_PB_covs_scv$pred, labels = test_PB_covs_scv$Presence))[1,4]\n \n  boyce = ecospat::ecospat.boyce(fit = test_PB_covs_scv$pred, \n                                 obs = test_PB_covs_scv$pred[which(test_PB_covs_scv$Presence==1)], \n                                 nclass = 0, # Calculate continuous index\n                                 method = \"pearson\",\n                                 PEplot = F)[[\"cor\"]]\n  \n  # Add results to dataframe\n  eval_df &lt;- eval_df %&gt;% add_row(fold = f, ROC = ROC, boyce = boyce)\n\n  \n}\n\n\n\n\nSummarise the evaluation metrics\n\n\nCode\n# Mean AUC & boyce\neval_df %&gt;% \n  summarise(mean_AUC = mean(ROC),\n            mean_boyce = mean(boyce),\n            sd_AUC = sd(ROC),\n            sd_boyce = sd(boyce))"
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#run-the-rf-model-for-every-fold-and-evaluate",
    "href": "Session 3/ICCB_Modelling_and_validation.html#run-the-rf-model-for-every-fold-and-evaluate",
    "title": "ICCB Species distribution modelling and validation",
    "section": "Run the RF model for every fold and evaluate",
    "text": "Run the RF model for every fold and evaluate\n\n\nCode\n# Start a dataframe to save results\neval_df.RF &lt;- data.frame(fold = numeric(),\n                      ROC = numeric(),\n                      boyce = numeric())\n\nfor(f in seq_along(spfolds)) {\n  \n  # Subset the training and testing data (spatial cross validation) (for the fth fold)\n  \n  train_PB_covs_scv &lt;- train_PB_covs_thinned[spfolds[[f]][[1]], ]\n  test_PB_covs_scv &lt;- train_PB_covs_thinned[spfolds[[f]][[2]], ]\n  \n  presNum &lt;- as.numeric(table(train_PB_covs_scv$Presence)[\"1\"]) # number of presences\n  bgNum &lt;- as.numeric(table(train_PB_covs_scv$Presence)[\"0\"]) # number of backgrounds\n  weight &lt;- ifelse(train_PB_covs_scv$Presence == 1, 1, presNum / bgNum) # down-weighting\n  \n  sample_size &lt;- c(\"0\" = bgNum, \"1\" = bgNum)\n  sample_size &lt;- c(bgNum)\n\n  \n  rf_1 &lt;- randomForest::randomForest(formula = model_formula,\n                                   data = train_PB_covs_scv,\n                                   weights = weight,\n                                   ntree = 1000,\n                                   sampsize = sample_size,\n                                   replace = T, \n                                   importance=TRUE)\n  \n  \n    # Predict to the testing data of fold f\n  test_PB_covs_scv$pred &lt;- predict(rf_1, newdata = test_PB_covs_scv, type = \"response\")\n\n  # Evaluate prediction on test set\n  ROC = precrec::auc(precrec::evalmod(scores = test_PB_covs_scv$pred, labels = test_PB_covs_scv$Presence))[1,4]\n \n  boyce = ecospat::ecospat.boyce(fit = test_PB_covs_scv$pred, \n                                 obs = test_PB_covs_scv$pred[which(test_PB_covs_scv$Presence==1)], \n                                 nclass = 0, # Calculate continuous index\n                                 method = \"pearson\",\n                                 PEplot = F)[[\"cor\"]]\n  \n  # Add results to dataframe\n  eval_df.RF &lt;- eval_df.RF %&gt;% add_row(fold = f, ROC = ROC, boyce = boyce)\n\n  \n}\n\n\nWarning in randomForest.default(m, y, ...): The response has five or fewer\nunique values.  Are you sure you want to do regression?\nWarning in randomForest.default(m, y, ...): The response has five or fewer\nunique values.  Are you sure you want to do regression?\nWarning in randomForest.default(m, y, ...): The response has five or fewer\nunique values.  Are you sure you want to do regression?\nWarning in randomForest.default(m, y, ...): The response has five or fewer\nunique values.  Are you sure you want to do regression?\nWarning in randomForest.default(m, y, ...): The response has five or fewer\nunique values.  Are you sure you want to do regression?"
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#summarise-the-evaluation-metrics-1",
    "href": "Session 3/ICCB_Modelling_and_validation.html#summarise-the-evaluation-metrics-1",
    "title": "ICCB Species distribution modelling and validation",
    "section": "Summarise the evaluation metrics",
    "text": "Summarise the evaluation metrics\n\n\nCode\n# Mean AUC & boyce\neval_df.RF %&gt;% \n  summarise(mean_AUC = mean(ROC),\n            mean_boyce = mean(boyce),\n            sd_AUC = sd(ROC),\n            sd_boyce = sd(boyce))"
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#load-future-environmental-data",
    "href": "Session 3/ICCB_Modelling_and_validation.html#load-future-environmental-data",
    "title": "ICCB Species distribution modelling and validation",
    "section": "Load future environmental data",
    "text": "Load future environmental data\n\n\nCode\ncovs_future &lt;- rast(\"Data/Environmental_variables/future_bioclim.2090.SSP370.tif\")\nnames(covs_future) &lt;- layer_names\ncovs_future\n\n\nclass       : SpatRaster \ndimensions  : 47, 55, 19  (nrow, ncol, nlyr)\nresolution  : 5123.954, 5123.954  (x, y)\nextent      : 1621552, 1903370, -3349594, -3108768  (xmin, xmax, ymin, ymax)\ncoord. ref. : GDA94 / Geoscience Australia Lambert (EPSG:3112) \nsource      : future_bioclim.2090.SSP370.tif \nnames       : BIO1_~_Temp, BIO2_~Range, BIO3_~ality, BIO4_~ality, BIO5_~Month, BIO6_~Month, ... \nmin values  :   0.8177757,   0.3121004,    1.564732,    12.43535,    1.130271,   0.4521889, ... \nmax values  :  24.5521488,  14.5486765,   50.989292,   528.63293,   37.389927,  15.7586107, ... \n\n\nCode\ncovs_future &lt;- terra::mask(covs_future, covs_current) # Crop to SEQ extent\n\ncovs_future_expert &lt;- subset(covs_future, names(covs_future) %in% c(\"BIO5_Max_Temp_Warmest_Month\", \n                                                                    \"BIO6_Min_Temp_Coldest_Month\", \n                                                                    \"BIO12_Annual_Precipitation\", \n                                                                    \"BIO15_Precip_Seasonality\"))"
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#plot-the-future-rasters",
    "href": "Session 3/ICCB_Modelling_and_validation.html#plot-the-future-rasters",
    "title": "ICCB Species distribution modelling and validation",
    "section": "Plot the future rasters",
    "text": "Plot the future rasters\n\n\nCode\nfor(i in 1:nlyr(covs_future)) {\n  terra::plot(covs_future[[i]], main = names(covs_future)[[i]])\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Plot to compare the difference between the current and future rasters\n\nplot(covs_future_expert - covs_current_expert)"
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#test-the-environmental-distance-between-current-data-and-future-conditions",
    "href": "Session 3/ICCB_Modelling_and_validation.html#test-the-environmental-distance-between-current-data-and-future-conditions",
    "title": "ICCB Species distribution modelling and validation",
    "section": "Test the environmental distance between current data and future conditions",
    "text": "Test the environmental distance between current data and future conditions\n\n\nCode\nmess &lt;- predicts::mess(covs_future_expert, \n                       train_PB_covs_thinned[, c(\"BIO5_Max_Temp_Warmest_Month\", \n                                            \"BIO6_Min_Temp_Coldest_Month\", \n                                            \"BIO12_Annual_Precipitation\", \n                                            \"BIO15_Precip_Seasonality\")])\n\nplot(mess, axes = F)\n\n\n\n\n\n\n\n\n\nCode\nr_mess_mask &lt;- mess &lt; 0\nplot(r_mess_mask, axes=F)\n\n\n\n\n\n\n\n\n\nTest which areas you might mask out because they are ‘novel’ in environmental space and therefore require model extrapolation.\n\n\nCode\nanalog_fut &lt;- predicted_raster_model_1\n\nvalues(analog_fut)[values(mess)&lt;0] &lt;- NA\n\nplot(analog_fut, \n     range = c(0, 1),  # Set min and max values for the color scale\n     main = \"Koala relative occurrence in regions with analogue conditions\")\n\n\n\n\n\n\n\n\n\nCode\nnovel_fut &lt;- predicted_raster_model_1\n\nvalues(novel_fut)[values(mess)&gt;0] &lt;- NA\n\nplot(novel_fut, \n     range = c(0, 1),  # Set min and max values for the color scale\n     main = \"Koala relative occurrence in regions with novel conditions\")"
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#model-1-1",
    "href": "Session 3/ICCB_Modelling_and_validation.html#model-1-1",
    "title": "ICCB Species distribution modelling and validation",
    "section": "Model 1",
    "text": "Model 1\n\n\nCode\n# Predict the presence probability across the entire raster extent\npredicted_raster_model_1 &lt;- predict(covs_future_expert, glm_model_1, type = \"response\")\n\n# Plot the species distribution raster\nplot(\n  predicted_raster_model_1,\n  range = c(0, 1),  # Set min and max values for the color scale\n  main = \"Relative Probability of Occurrence of Koalas in SEQ - GLM1\"\n)"
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#model-2-1",
    "href": "Session 3/ICCB_Modelling_and_validation.html#model-2-1",
    "title": "ICCB Species distribution modelling and validation",
    "section": "Model 2",
    "text": "Model 2\n\n\nCode\n# Predict the presence probability across the entire raster extent\npredicted_raster_model_2 &lt;- predict(covs_future_expert, glm_model_2, type = \"response\")\n\n# Plot the species distribution raster\nplot(\n  predicted_raster_model_2,\n  range = c(0, 1),  # Set min and max values for the color scale\n  main = \"Relative Probability of Occurrence of Koalas in SEQ - GLM2\"\n)"
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#random-forest-future-predictions",
    "href": "Session 3/ICCB_Modelling_and_validation.html#random-forest-future-predictions",
    "title": "ICCB Species distribution modelling and validation",
    "section": "Random Forest future predictions",
    "text": "Random Forest future predictions\n\nModel 1\n\n\nCode\n# Predict the presence probability across the entire raster extent\npredicted_raster_RF_1 &lt;- predicts::predict(covs_future_expert, rf_1, type = \"response\", na.rm=TRUE)\n\n# Plot the species distribution raster\nplot(\n  predicted_raster_RF_1,\n  range = c(0, 1),  # Set min and max values for the color scale\n  main = \"Relative Probability of Occurrence of Koalas in SEQ - RF\"\n)"
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#presenting-predictions-with-uncertainty",
    "href": "Session 3/ICCB_Modelling_and_validation.html#presenting-predictions-with-uncertainty",
    "title": "ICCB Species distribution modelling and validation",
    "section": "Presenting predictions with uncertainty",
    "text": "Presenting predictions with uncertainty\nThere are many sources of model uncertainty that should be explored and ideally, presented alongside model predictions.\nOne that we’ll focus on here is climate scenario uncertainty. We do so by fitting a second model to future climate data from a lower emission shared socioeconomic path scenario (SSP 1.26)."
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#load-future-environmental-data-ssp-1.26",
    "href": "Session 3/ICCB_Modelling_and_validation.html#load-future-environmental-data-ssp-1.26",
    "title": "ICCB Species distribution modelling and validation",
    "section": "Load future environmental data (SSP 1.26)",
    "text": "Load future environmental data (SSP 1.26)\n\n\nCode\ncovs_future_SSP126 &lt;- rast(\"Data/Environmental_variables/future_bioclim.2090.SSP126.tif\")\nnames(covs_future_SSP126) &lt;- layer_names\ncovs_future_SSP126\n\n\nclass       : SpatRaster \ndimensions  : 47, 55, 19  (nrow, ncol, nlyr)\nresolution  : 5123.954, 5123.954  (x, y)\nextent      : 1621552, 1903370, -3349594, -3108768  (xmin, xmax, ymin, ymax)\ncoord. ref. : GDA94 / Geoscience Australia Lambert (EPSG:3112) \nsource      : future_bioclim.2090.SSP126.tif \nnames       : BIO1_~_Temp, BIO2_~Range, BIO3_~ality, BIO4_~ality, BIO5_~Month, BIO6_~Month, ... \nmin values  :   0.7471204,   0.3128485,    1.585051,    12.19436,    1.046093,   0.3754203, ... \nmax values  :  22.4384842,  14.8543510,   51.254021,   544.83429,   35.546104,  13.5217409, ... \n\n\nCode\ncovs_future_SSP126_expert &lt;- subset(covs_future_SSP126, names(covs_future_SSP126) %in% c(\"BIO5_Max_Temp_Warmest_Month\", \n                                                                                          \"BIO6_Min_Temp_Coldest_Month\", \n                                                                                          \"BIO12_Annual_Precipitation\", \n                                                                                          \"BIO15_Precip_Seasonality\"))\n\n\nPlot to compare the variables across the two scenarios\n\n\nCode\nplot(covs_future_expert)\n\n\n\n\n\n\n\n\n\nCode\nplot(covs_future_SSP126_expert)"
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#glm-future-predictions-ssp-1.26",
    "href": "Session 3/ICCB_Modelling_and_validation.html#glm-future-predictions-ssp-1.26",
    "title": "ICCB Species distribution modelling and validation",
    "section": "GLM future predictions (SSP 1.26)",
    "text": "GLM future predictions (SSP 1.26)\n\nModel 1\n\n\nCode\n# Predict the presence probability across the entire raster extent\npredicted_raster_model_1_SSP126 &lt;- predict(covs_future_SSP126_expert, glm_model_1, type = \"response\")\n\n# Plot the species distribution raster\nplot(\n  predicted_raster_model_1,\n  range = c(0,1),\n  main = \"SSP 3.70\"\n)\n\n\n\n\n\n\n\n\n\nCode\nplot(\n  predicted_raster_model_1_SSP126,\n  range = c(0,1),\n  main = \"SSP 1.26\"\n)"
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#model-uncertainty",
    "href": "Session 3/ICCB_Modelling_and_validation.html#model-uncertainty",
    "title": "ICCB Species distribution modelling and validation",
    "section": "Model uncertainty",
    "text": "Model uncertainty\nAnother element of uncertainty that can be represented is model uncertainty, or the standard error around the coefficient estimates.\n\n\nCode\n# Extract standard errors of coefficients\n\ncoef_se &lt;- summary(glm_model_1)$coefficients[, \"Std. Error\"]\n\nprint(coef_se)\n\n\n                (Intercept) BIO5_Max_Temp_Warmest_Month \n               1.6960955169                0.0612124929 \nBIO6_Min_Temp_Coldest_Month  BIO12_Annual_Precipitation \n               0.0324663917                0.0003209716 \n   BIO15_Precip_Seasonality \n               0.0133672918 \n\n\n\n\nCode\ncovs_df &lt;- as.data.frame(covs_future_expert, na.rm = FALSE)\n\npred_link &lt;- predict(glm_model_1, newdata = covs_df, type = \"link\", se.fit = TRUE)\n\n# Linear predictor (eta)\neta &lt;- pred_link$fit\nse_eta &lt;- pred_link$se.fit\n\n# Confidence intervals (95%)\nz &lt;- 1.96\neta_lower &lt;- eta - z * se_eta\neta_upper &lt;- eta + z * se_eta\n\n# Transform back to response scale\nlinkinv &lt;- glm_model_1$family$linkinv\npredicted &lt;- linkinv(eta)\nlower_ci &lt;- linkinv(eta_lower)\nupper_ci &lt;- linkinv(eta_upper)\n\n\n# Add to covs_df\ncovs_df$predicted &lt;- predicted\ncovs_df$lower_ci &lt;- lower_ci\ncovs_df$upper_ci &lt;- upper_ci\n\n\npredicted_r &lt;- setValues(rast(covs_future_expert, nlyr = 1), predicted)\nlower_ci_r &lt;- setValues(rast(covs_future_expert, nlyr = 1), lower_ci)\nupper_ci_r &lt;- setValues(rast(covs_future_expert, nlyr = 1), upper_ci)\n\n# Step 2: Name the layers\nnames(predicted_r) &lt;- \"predicted\"\nnames(lower_ci_r) &lt;- \"lower_CI\"\nnames(upper_ci_r) &lt;- \"upper_CI\"\n\nprediction_w_uncertainty &lt;- c(predicted_r, lower_ci_r, upper_ci_r)\n\nplot(prediction_w_uncertainty, range = c(0, 1))"
  },
  {
    "objectID": "Session 3/ICCB_Species_data.html",
    "href": "Session 3/ICCB_Species_data.html",
    "title": "ICCB Species data download",
    "section": "",
    "text": "Code\n# install.packages(\"galah\")"
  },
  {
    "objectID": "Session 3/ICCB_Species_data.html#install-packages",
    "href": "Session 3/ICCB_Species_data.html#install-packages",
    "title": "ICCB Species data download",
    "section": "",
    "text": "Code\n# install.packages(\"galah\")"
  },
  {
    "objectID": "Session 3/ICCB_Species_data.html#import-packages",
    "href": "Session 3/ICCB_Species_data.html#import-packages",
    "title": "ICCB Species data download",
    "section": "Import packages",
    "text": "Import packages\n\n\nCode\nlibrary(dplyr)\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCode\nlibrary(purrr)\nlibrary(ggplot2)\nlibrary(galah)\n\n\ngalah: version 2.1.1\nℹ Default node set to ALA (ala.org.au).\nℹ See all supported GBIF nodes with `show_all(atlases)`.\nℹ To change nodes, use e.g. `galah_config(atlas = \"GBIF\")`.\n\n\n\nAttaching package: 'galah'\n\n\nThe following object is masked from 'package:dplyr':\n\n    desc\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\nCode\nlibrary(terra)\n\n\nterra 1.8.50\n\n\nCode\nlibrary(sf)\n\n\nLinking to GEOS 3.13.0, GDAL 3.8.5, PROJ 9.5.1; sf_use_s2() is TRUE\n\n\nCode\nlibrary(predicts)\nlibrary(tidyterra)\n\n\n\nAttaching package: 'tidyterra'\n\nThe following object is masked from 'package:stats':\n\n    filter"
  },
  {
    "objectID": "Session 3/ICCB_Species_data.html#to-cite-the-galah-package",
    "href": "Session 3/ICCB_Species_data.html#to-cite-the-galah-package",
    "title": "ICCB Species data download",
    "section": "To cite the galah package",
    "text": "To cite the galah package\n\n\nCode\n# Package citation\ncitation(package = \"galah\")\n\n\nTo cite galah in publications use:\n\n  Westgate M, Kellie D, Stevenson M, Newman P (2025). _galah:\n  Biodiversity Data from the GBIF Node Network_. R package version\n  2.1.1, &lt;https://CRAN.R-project.org/package=galah&gt;.\n\nA BibTeX entry for LaTeX users is\n\n  @Manual{,\n    title = {galah: Biodiversity Data from the GBIF Node Network},\n    author = {Martin Westgate and Dax Kellie and Matilda Stevenson and Peggy Newman},\n    year = {2025},\n    note = {R package version 2.1.1},\n    url = {https://CRAN.R-project.org/package=galah},\n  }"
  },
  {
    "objectID": "Session 3/ICCB_Species_data.html#load-south-east-queensland-seq-boundary",
    "href": "Session 3/ICCB_Species_data.html#load-south-east-queensland-seq-boundary",
    "title": "ICCB Species data download",
    "section": "Load South East Queensland (SEQ) boundary",
    "text": "Load South East Queensland (SEQ) boundary\nWe made this boundary in the ‘ICCB_Environmental_data.qmd’ script. Also load local government area polygons (LGAs) just for plotting.\n\n\nCode\nSEQ_extent.vect &lt;- vect(\"Data/Environmental_variables/SEQ_extent.shp\")\n\n# Define an sf object as well\nSEQ_extent &lt;- st_as_sf(SEQ_extent.vect, \n                        coords = c(\"x\", \"y\"), \n                        crs = 3112)\n                        \n\n\n# Load the study area shapefile\nLGA &lt;- st_read(\"Data/Environmental_variables/Local_Government_Areas.shp\")\n\n\nReading layer `Local_Government_Areas' from data source \n  `/Users/scottforrest/Library/CloudStorage/OneDrive-QueenslandUniversityofTechnology/PhD - Scott Forrest/GIT/ICCB_geospatial_tools_conservation/Session 3/Data/Environmental_variables/Local_Government_Areas.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 78 features and 8 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 137.9946 ymin: -29.17927 xmax: 153.5519 ymax: -9.087991\nGeodetic CRS:  GDA94\n\n\nCode\n# Check the coordinate reference system (CRS)\nst_crs(LGA)\n\n\nCoordinate Reference System:\n  User input: GDA94 \n  wkt:\nGEOGCRS[\"GDA94\",\n    DATUM[\"Geocentric Datum of Australia 1994\",\n        ELLIPSOID[\"GRS 1980\",6378137,298.257222101,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    USAGE[\n        SCOPE[\"Horizontal component of 3D system.\"],\n        AREA[\"Australia including Lord Howe Island, Macquarie Island, Ashmore and Cartier Islands, Christmas Island, Cocos (Keeling) Islands, Norfolk Island. All onshore and offshore.\"],\n        BBOX[-60.55,93.41,-8.47,173.34]],\n    ID[\"EPSG\",4283]]\n\n\nCode\n# Convert to WGS84\nLGA &lt;- LGA %&gt;% st_transform(3112)\n\n# Select local govt. areas for South East Queensland\nLGA_SEQ &lt;- LGA %&gt;% \n  filter(lga %in% c(\"Brisbane City\", \n                    \"Moreton Bay City\", \n                    \"Logan City\", \n                    \"Ipswich City\", \n                    \"Redland City\", \n                    \"Scenic Rim Regional\", \n                    \"Somerset Regional\", \n                    \"Lockyer Valley Regional\", \n                    \"Gold Coast City\", \n                    \"Sunshine Coast Regional\", \n                    \"Toowoomba Regional\", \n                    \"Noosa Shire\"))"
  },
  {
    "objectID": "Session 3/ICCB_Species_data.html#atlas-of-living-australia-using-galah-package",
    "href": "Session 3/ICCB_Species_data.html#atlas-of-living-australia-using-galah-package",
    "title": "ICCB Species data download",
    "section": "Atlas of Living Australia using “galah” package",
    "text": "Atlas of Living Australia using “galah” package\nTo access records from the ALA, you will need to be registered.\nThere are two registration options:\n\nIf you are affiliated with an Australian institution, you should be able to register for ALA through your institution. Find your institution in the list of institutions when you select ‘Login’ on the ALA website. Follow the prompts to enter your institution email and password. If your institution is not listed, you will need to register for an ALA account.\nIf you are not affiliated with an Australian institution, you will need to register for an ALA account. You can do this by selecting ‘Register’ on the ALA website. Follow the prompts to enter your email and password.\n\n\n\nCode\ngalah_config(atlas = \"ALA\",\n             # username = \"scott.forrest@hdr.qut.edu.au\",\n             email = \"scott.forrest@hdr.qut.edu.au\"\n             # password = \"Password\"\n             )"
  },
  {
    "objectID": "Session 3/ICCB_Species_data.html#download-koala-data-from-ala",
    "href": "Session 3/ICCB_Species_data.html#download-koala-data-from-ala",
    "title": "ICCB Species data download",
    "section": "Download koala data from ALA",
    "text": "Download koala data from ALA\nUsually you would check that the CRS for the occurrences is the same as the shapefile. However, we know that the `galah’ package operates in WGS84.\n\n\nCode\nkoala_occurrences &lt;- galah_call() %&gt;% \n  galah_identify(\"Phascolarctos cinereus\") %&gt;% \n  galah_filter(\n    stateProvince == \"Queensland\",\n    occurrenceStatus == \"PRESENT\"\n  ) %&gt;% \n  atlas_occurrences()\n\n\nRequest for 93456 occurrences placed in queue\nCurrent queue length: 1\n\n\n-----\n\n\nDownloading"
  },
  {
    "objectID": "Session 3/ICCB_Species_data.html#clean-koala-data",
    "href": "Session 3/ICCB_Species_data.html#clean-koala-data",
    "title": "ICCB Species data download",
    "section": "Clean koala data",
    "text": "Clean koala data\n\n\nCode\n# Create a map using ggplot2\nggplot() +\n  geom_sf(data = LGA, color = \"black\") +\n  geom_point(data = koala_occurrences,\n             aes(x = decimalLongitude,\n                 y = decimalLatitude),\n             color = \"blue\", size = 0.5) + # Add points for occurrences\n  ggtitle(\"Koala occurrences across Queensland\") +             # Add title\n  theme_bw()\n\n\nWarning: Removed 215 rows containing missing values or values outside the scale range\n(`geom_point()`)."
  },
  {
    "objectID": "Session 3/ICCB_Species_data.html#filter-by-seq-region",
    "href": "Session 3/ICCB_Species_data.html#filter-by-seq-region",
    "title": "ICCB Species data download",
    "section": "Filter by SEQ region",
    "text": "Filter by SEQ region\n\n\nCode\n# Check for missing values in decimalLongitude and decimalLatitude\npaste0(\"Number of NAs in 'longitude' \", sum(is.na(koala_occurrences$decimalLongitude)))\n\n\n[1] \"Number of NAs in 'longitude' 215\"\n\n\nCode\npaste0(\"Number of NAs in 'latitude' \", sum(is.na(koala_occurrences$decimalLatitude)))\n\n\n[1] \"Number of NAs in 'latitude' 215\"\n\n\nCode\nkoala_occ_sf &lt;- koala_occurrences %&gt;% \n  drop_na(decimalLongitude, decimalLatitude) %&gt;% # remove NA values\n  st_as_sf(coords = c(\"decimalLongitude\", \"decimalLatitude\"), \n           crs = 4326) %&gt;%\n  st_transform(3112) %&gt;% # Transform to the same CRS as SEQ_extent\n  st_intersection(SEQ_extent) %&gt;% # Mask to extent\n  distinct() # drop any duplicated records\n\n\nWarning: attribute variables are assumed to be spatially constant throughout\nall geometries"
  },
  {
    "objectID": "Session 3/ICCB_Species_data.html#plot-the-filtered-data",
    "href": "Session 3/ICCB_Species_data.html#plot-the-filtered-data",
    "title": "ICCB Species data download",
    "section": "Plot the filtered data",
    "text": "Plot the filtered data\n\n\nCode\n# Create a map using ggplot2\nggplot() +\n  geom_sf(data = SEQ_extent.vect, fill = \"purple3\", alpha = 0.5, color = \"black\", size = 0.2) +\n  geom_sf(data = koala_occ_sf,                           # Add koala presence locations\n          aes(geometry = geometry),\n             color = \"blue\", size = 0.5) +               # Add points for occurrences\n  ggtitle(\"Koala occurrences in South East Queensland\") +      # Add title\n  theme_bw()"
  },
  {
    "objectID": "Session 3/ICCB_Species_data.html#save-koala-presences-and-background-points",
    "href": "Session 3/ICCB_Species_data.html#save-koala-presences-and-background-points",
    "title": "ICCB Species data download",
    "section": "Save koala presences and background points",
    "text": "Save koala presences and background points\nThis ensures quick upload in the future and that these records can be used among models.\n\n\nCode\nwriteVector(koala_occ.vect, \"Data/Biological_records/SEQ_koala_occurrences.shp\", overwrite = T)\n\nwriteVector(background, \"Data/Biological_records/background_points_2.5k_random.shp\", overwrite = T)"
  },
  {
    "objectID": "Session 4/session_4_home.html",
    "href": "Session 4/session_4_home.html",
    "title": "Session 4",
    "section": "",
    "text": "Landing page for Session 4.\n\n\n\n Back to top"
  },
  {
    "objectID": "workshop_overview.html",
    "href": "workshop_overview.html",
    "title": "Workshop overview",
    "section": "",
    "text": "Overview of the workshop\n\nHow it will run\nAccessing the repo\netc…\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Session 3/ICCB_Environmental_data.html",
    "href": "Session 3/ICCB_Environmental_data.html",
    "title": "ICCB Environmental data download",
    "section": "",
    "text": "Code\nlibrary(terra)\n\n\nterra 1.8.50\n\n\nCode\nlibrary(dplyr)\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:terra':\n\n    intersect, union\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCode\nlibrary(sf)\n\n\nLinking to GEOS 3.13.0, GDAL 3.8.5, PROJ 9.5.1; sf_use_s2() is TRUE\n\n\nCode\nlibrary(ggplot2)"
  },
  {
    "objectID": "Session 3/ICCB_Environmental_data.html#import-packages",
    "href": "Session 3/ICCB_Environmental_data.html#import-packages",
    "title": "ICCB Environmental data download",
    "section": "",
    "text": "Code\nlibrary(terra)\n\n\nterra 1.8.50\n\n\nCode\nlibrary(dplyr)\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:terra':\n\n    intersect, union\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCode\nlibrary(sf)\n\n\nLinking to GEOS 3.13.0, GDAL 3.8.5, PROJ 9.5.1; sf_use_s2() is TRUE\n\n\nCode\nlibrary(ggplot2)"
  },
  {
    "objectID": "Session 3/ICCB_Environmental_data.html#load-south-east-queensland-seq-boundary",
    "href": "Session 3/ICCB_Environmental_data.html#load-south-east-queensland-seq-boundary",
    "title": "ICCB Environmental data download",
    "section": "Load South East Queensland (SEQ) boundary",
    "text": "Load South East Queensland (SEQ) boundary\nWe start by defining our study area, which is the South East Queensland (SEQ) region. We will use the Local Government Areas (LGA) shapefile to define the extent of SEQ.\nhttps://qldspatial.information.qld.gov.au/catalogue/custom/detail.page?fid={3F3DBD69-647B-4833-B0A5-CC43D5E70699}\n\n\nCode\n# Load the study area shapefile\nLGA &lt;- st_read(\"Data/Environmental_variables/Local_Government_Areas.shp\")\n\n\nReading layer `Local_Government_Areas' from data source \n  `/Users/scottforrest/Library/CloudStorage/OneDrive-QueenslandUniversityofTechnology/PhD - Scott Forrest/GIT/ICCB_geospatial_tools_conservation/Session 3/Data/Environmental_variables/Local_Government_Areas.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 78 features and 8 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 137.9946 ymin: -29.17927 xmax: 153.5519 ymax: -9.087991\nGeodetic CRS:  GDA94\n\n\nCode\n# Check the coordinate reference system (CRS)\nst_crs(LGA)\n\n\nCoordinate Reference System:\n  User input: GDA94 \n  wkt:\nGEOGCRS[\"GDA94\",\n    DATUM[\"Geocentric Datum of Australia 1994\",\n        ELLIPSOID[\"GRS 1980\",6378137,298.257222101,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    USAGE[\n        SCOPE[\"Horizontal component of 3D system.\"],\n        AREA[\"Australia including Lord Howe Island, Macquarie Island, Ashmore and Cartier Islands, Christmas Island, Cocos (Keeling) Islands, Norfolk Island. All onshore and offshore.\"],\n        BBOX[-60.55,93.41,-8.47,173.34]],\n    ID[\"EPSG\",4283]]\n\n\nCode\n# Convert to WGS84\nLGA &lt;- LGA %&gt;% st_transform(3112)\n\n# Select local govt. areas for South East Queensland\nLGA_SEQ &lt;- LGA %&gt;% \n  filter(lga %in% c(\"Brisbane City\", \n                    \"Moreton Bay City\", \n                    \"Logan City\", \n                    \"Ipswich City\", \n                    \"Redland City\", \n                    \"Scenic Rim Regional\", \n                    \"Somerset Regional\", \n                    \"Lockyer Valley Regional\", \n                    \"Gold Coast City\", \n                    \"Sunshine Coast Regional\", \n                    \"Toowoomba Regional\", \n                    \"Noosa Shire\"))\n\nggplot() +\n  geom_sf(data = LGA, color = \"black\") +\n  geom_sf(data = LGA_SEQ, fill = \"purple3\", alpha = 0.5, color = \"black\", size = 0.2) +\n  theme_minimal() +\n  theme(legend.position = \"none\") +\n  labs(title = \"Local Government Areas Queensland (SEQ in purple)\")\n\n\n\n\n\n\n\n\n\nCode\nggplot() +\n  geom_sf(data = LGA_SEQ, fill = \"purple3\", alpha = 0.5, color = \"black\", size = 0.2) +\n  theme_minimal() +\n  theme(legend.position = \"none\") +\n  labs(title = \"Local Government Areas South East Queensland (SEQ)\")"
  },
  {
    "objectID": "Session 3/ICCB_Environmental_data.html#merge-into-a-single-polygon",
    "href": "Session 3/ICCB_Environmental_data.html#merge-into-a-single-polygon",
    "title": "ICCB Environmental data download",
    "section": "Merge into a single polygon",
    "text": "Merge into a single polygon\n\n\nCode\n# Merge the SEQ LGAs into one polygon\nSEQ_extent &lt;- st_union(LGA_SEQ)\n\nggplot() +\n  geom_sf(data = SEQ_extent, fill = \"purple3\", alpha = 0.5, color = \"black\", size = 0.2) +\n  theme_minimal() +\n  theme(legend.position = \"none\") +\n  ggtitle(\"South-East Queensland Spatial Extent\") + \n  theme_bw()"
  },
  {
    "objectID": "Session 3/ICCB_Environmental_data.html#save-seq-extent-for-other-scripts",
    "href": "Session 3/ICCB_Environmental_data.html#save-seq-extent-for-other-scripts",
    "title": "ICCB Environmental data download",
    "section": "Save SEQ extent for other scripts",
    "text": "Save SEQ extent for other scripts\n\n\nCode\n# Convert our SEQ extent to a SpatExtent object by converting to a SpatVector\nSEQ_extent.vect &lt;- terra::vect(SEQ_extent)\n\nwriteVector(SEQ_extent.vect, \"Data/Environmental_variables/SEQ_extent.shp\", overwrite = T)"
  },
  {
    "objectID": "Session 3/ICCB_Environmental_data.html#load-current-environmental-data",
    "href": "Session 3/ICCB_Environmental_data.html#load-current-environmental-data",
    "title": "ICCB Environmental data download",
    "section": "Load current environmental data",
    "text": "Load current environmental data\nLayers were made available to us by the EcoCommons team and were created by Toombs and Ma (2025):\nToombs, N., and Ma S., 2025, A High-Resolution Dataset of 19 Bioclimatic Indices over Australia, Climate Projections and Services – Queensland Treasury, Brisbane, Queensland. [https://longpaddock.qld.gov.au/qld-future-climate/data-info/tern/]\n\n\nCode\nfiles &lt;- list.files(\"Data/Environmental_variables/Current_climate_QLD\", \n             pattern = \".tif$\", \n             full.names = TRUE)\n\n# Load all bioclim rasters\ncurrent_bioclim &lt;- lapply(files, terra::rast) \n\n# Make into one raster stack\ncurrent_bioclim &lt;- rast(current_bioclim)\n\nplot(current_bioclim)\n\n\n\n\n\n\n\n\n\nCode\n# Examine the resolution\ncurrent_bioclim\n\n\nclass       : SpatRaster \ndimensions  : 681, 841, 19  (nrow, ncol, nlyr)\nresolution  : 0.05, 0.05  (x, y)\nextent      : 111.975, 154.025, -44.025, -9.975  (xmin, xmax, ymin, ymax)\ncoord. ref. : lon/lat WGS 84 (EPSG:4326) \nsources     : bioclim_01.tif  \n              bioclim_02.tif  \n              bioclim_03.tif  \n              ... and 16 more sources\nnames       : bioclim_01, bioclim_02, bioclim_03, bioclim_04, bioclim_05, bioclim_06, ... \n\n\nCode\n# Check the CRS\ncrs(current_bioclim)\n\n\n[1] \"GEOGCRS[\\\"WGS 84\\\",\\n    ENSEMBLE[\\\"World Geodetic System 1984 ensemble\\\",\\n        MEMBER[\\\"World Geodetic System 1984 (Transit)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G730)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G873)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G1150)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G1674)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G1762)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G2139)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G2296)\\\"],\\n        ELLIPSOID[\\\"WGS 84\\\",6378137,298.257223563,\\n            LENGTHUNIT[\\\"metre\\\",1]],\\n        ENSEMBLEACCURACY[2.0]],\\n    PRIMEM[\\\"Greenwich\\\",0,\\n        ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n    CS[ellipsoidal,2],\\n        AXIS[\\\"geodetic latitude (Lat)\\\",north,\\n            ORDER[1],\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n        AXIS[\\\"geodetic longitude (Lon)\\\",east,\\n            ORDER[2],\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n    USAGE[\\n        SCOPE[\\\"Horizontal component of 3D system.\\\"],\\n        AREA[\\\"World.\\\"],\\n        BBOX[-90,-180,90,180]],\\n    ID[\\\"EPSG\\\",4326]]\"\n\n\nCode\n# Update CRS \ncurrent_bioclim &lt;- terra::project(current_bioclim, \"EPSG:3112\")\n\n# Our resolution is now ~5km by 5km\ncurrent_bioclim\n\n\nclass       : SpatRaster \ndimensions  : 770, 924, 19  (nrow, ncol, nlyr)\nresolution  : 5123.954, 5123.954  (x, y)\nextent      : -2477612, 2256922, -5117358, -1171913  (xmin, xmax, ymin, ymax)\ncoord. ref. : GDA94 / Geoscience Australia Lambert (EPSG:3112) \nsource(s)   : memory\nnames       : bioclim_01, bioclim_02, bioclim_03, bioclim_04, bioclim_05, bioclim_06, ... \nmin values  :   5.030256,   5.511227,   34.70108,   105.4365,   16.72381,  -4.999238, ... \nmax values  :  29.429586,  16.877110,   61.76879,   680.1939,   42.44056,  23.001247, ..."
  },
  {
    "objectID": "Session 3/ICCB_Environmental_data.html#mask-to-seq-extent",
    "href": "Session 3/ICCB_Environmental_data.html#mask-to-seq-extent",
    "title": "ICCB Environmental data download",
    "section": "Mask to SEQ extent",
    "text": "Mask to SEQ extent\n\n\nCode\ncurrent_bioclim &lt;- terra::mask(current_bioclim, SEQ_extent.vect)\n\n# You can see that this has masked the area but the extent is still the same\nplot(current_bioclim[[1]])\n\n\n\n\n\n\n\n\n\nCode\ncurrent_bioclim &lt;- terra::crop(current_bioclim, SEQ_extent.vect)\n\nplot(current_bioclim)\n\n\n\n\n\n\n\n\n\nCode\n# Save the current environmental covariates\nwriteRaster(current_bioclim, \n            filename = \"Data/Environmental_variables/current_bioclim.tif\",\n            overwrite = T)"
  },
  {
    "objectID": "Session 3/ICCB_Environmental_data.html#load-future-environmental-data",
    "href": "Session 3/ICCB_Environmental_data.html#load-future-environmental-data",
    "title": "ICCB Environmental data download",
    "section": "Load future environmental data",
    "text": "Load future environmental data\nHere we load outputs from a moderate-high emissions shared socio-economic path scenario (SSP 3.70) for the year 2090 (2080 - 2099).\n\n\nCode\nfiles &lt;- list.files(\"Data/Environmental_variables/Future_climate_SSP370_2090\", \n             pattern = \".tif$\", \n             full.names = TRUE)\n\n# Load all bioclim rasters\nfuture_bioclim &lt;- lapply(files, terra::rast) \n\n# Make into one raster stack\nfuture_bioclim &lt;- rast(future_bioclim)\n\nplot(future_bioclim)\n\n\n\n\n\n\n\n\n\nCode\n# Examine the resolution\nfuture_bioclim\n\n\nclass       : SpatRaster \ndimensions  : 681, 841, 19  (nrow, ncol, nlyr)\nresolution  : 0.05, 0.05  (x, y)\nextent      : 111.975, 154.025, -44.025, -9.975  (xmin, xmax, ymin, ymax)\ncoord. ref. : lon/lat WGS 84 (EPSG:4326) \nsources     : bioclim_01.tif  \n              bioclim_02.tif  \n              bioclim_03.tif  \n              ... and 16 more sources\nnames       : bioclim_01, bioclim_02, bioclim_03, bioclim_04, bioclim_05, bioclim_06, ... \n\n\nCode\n# Check the CRS\ncrs(future_bioclim)\n\n\n[1] \"GEOGCRS[\\\"WGS 84\\\",\\n    ENSEMBLE[\\\"World Geodetic System 1984 ensemble\\\",\\n        MEMBER[\\\"World Geodetic System 1984 (Transit)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G730)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G873)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G1150)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G1674)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G1762)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G2139)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G2296)\\\"],\\n        ELLIPSOID[\\\"WGS 84\\\",6378137,298.257223563,\\n            LENGTHUNIT[\\\"metre\\\",1]],\\n        ENSEMBLEACCURACY[2.0]],\\n    PRIMEM[\\\"Greenwich\\\",0,\\n        ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n    CS[ellipsoidal,2],\\n        AXIS[\\\"geodetic latitude (Lat)\\\",north,\\n            ORDER[1],\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n        AXIS[\\\"geodetic longitude (Lon)\\\",east,\\n            ORDER[2],\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n    USAGE[\\n        SCOPE[\\\"Horizontal component of 3D system.\\\"],\\n        AREA[\\\"World.\\\"],\\n        BBOX[-90,-180,90,180]],\\n    ID[\\\"EPSG\\\",4326]]\"\n\n\nCode\n# Update CRS \nfuture_bioclim &lt;- terra::project(future_bioclim, \"EPSG:3112\")\n\n# Our resolution is now ~5km by 5km\nfuture_bioclim\n\n\nclass       : SpatRaster \ndimensions  : 770, 924, 19  (nrow, ncol, nlyr)\nresolution  : 5123.954, 5123.954  (x, y)\nextent      : -2477612, 2256922, -5117358, -1171913  (xmin, xmax, ymin, ymax)\ncoord. ref. : GDA94 / Geoscience Australia Lambert (EPSG:3112) \nsource(s)   : memory\nnames       : bioclim_01, bioclim_02, bioclim_03, bioclim_04, bioclim_05, bioclim_06, ... \nmin values  :    0.00000,     0.0000,    0.00000,     0.0000,    0.00000,  -2.320518, ... \nmax values  :   32.99174,    16.1037,   66.06882,   706.0898,   46.24387,  25.877970, ..."
  },
  {
    "objectID": "Session 3/ICCB_Environmental_data.html#mask-to-seq-extent-1",
    "href": "Session 3/ICCB_Environmental_data.html#mask-to-seq-extent-1",
    "title": "ICCB Environmental data download",
    "section": "Mask to SEQ extent",
    "text": "Mask to SEQ extent\n\n\nCode\nfuture_bioclim &lt;- terra::subst(from = 0, to = NA, future_bioclim) # Set all values of 0 to NA\n\nfuture_bioclim &lt;- terra::mask(future_bioclim, SEQ_extent.vect)\n\n# You can see that this has masked the area but the extent is still the same\nplot(future_bioclim[[1]])\n\n\n\n\n\n\n\n\n\nCode\nfuture_bioclim &lt;- terra::crop(future_bioclim, SEQ_extent.vect)\n\nplot(future_bioclim[[1]])\n\n\n\n\n\n\n\n\n\nCode\n# Save the future environmental covariates\nwriteRaster(future_bioclim, \n            filename = \"Data/Environmental_variables/future_bioclim.2090.SSP370.tif\",\n            overwrite = T)"
  },
  {
    "objectID": "Session 3/ICCB_Environmental_data.html#load-future-environmental-data-2",
    "href": "Session 3/ICCB_Environmental_data.html#load-future-environmental-data-2",
    "title": "ICCB Environmental data download",
    "section": "Load future environmental data 2",
    "text": "Load future environmental data 2\nHere we load outputs from a low emissions shared socio-economic path scenario (SSP 1.26) for the year 2090 (2080 - 2099).\n\n\nCode\nfiles &lt;- list.files(\"Data/Environmental_variables/Future_climate_SSP126_2090\", \n             pattern = \".tif$\", \n             full.names = TRUE)\n\n# Load all bioclim rasters\nfuture_bioclim &lt;- lapply(files, terra::rast) \n\n# Make into one raster stack\nfuture_bioclim &lt;- rast(future_bioclim)\n\nplot(future_bioclim)\n\n\n\n\n\n\n\n\n\nCode\n# Examine the resolution\nfuture_bioclim\n\n\nclass       : SpatRaster \ndimensions  : 681, 841, 19  (nrow, ncol, nlyr)\nresolution  : 0.05, 0.05  (x, y)\nextent      : 111.975, 154.025, -44.025, -9.975  (xmin, xmax, ymin, ymax)\ncoord. ref. : lon/lat WGS 84 (EPSG:4326) \nsources     : bioclim_01.tif  \n              bioclim_02.tif  \n              bioclim_03.tif  \n              ... and 16 more sources\nnames       : bioclim_01, bioclim_02, bioclim_03, bioclim_04, bioclim_05, bioclim_06, ... \nmin values  :    0.00000,    0.00000,     0.0000,         ? ,         ? ,         ? , ... \nmax values  :   30.47033,   16.75114,    63.2751,         ? ,         ? ,         ? , ... \n\n\nCode\n# Check the CRS\ncrs(future_bioclim)\n\n\n[1] \"GEOGCRS[\\\"WGS 84\\\",\\n    ENSEMBLE[\\\"World Geodetic System 1984 ensemble\\\",\\n        MEMBER[\\\"World Geodetic System 1984 (Transit)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G730)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G873)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G1150)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G1674)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G1762)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G2139)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G2296)\\\"],\\n        ELLIPSOID[\\\"WGS 84\\\",6378137,298.257223563,\\n            LENGTHUNIT[\\\"metre\\\",1]],\\n        ENSEMBLEACCURACY[2.0]],\\n    PRIMEM[\\\"Greenwich\\\",0,\\n        ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n    CS[ellipsoidal,2],\\n        AXIS[\\\"geodetic latitude (Lat)\\\",north,\\n            ORDER[1],\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n        AXIS[\\\"geodetic longitude (Lon)\\\",east,\\n            ORDER[2],\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n    USAGE[\\n        SCOPE[\\\"Horizontal component of 3D system.\\\"],\\n        AREA[\\\"World.\\\"],\\n        BBOX[-90,-180,90,180]],\\n    ID[\\\"EPSG\\\",4326]]\"\n\n\nCode\n# Update CRS \nfuture_bioclim &lt;- terra::project(future_bioclim, \"EPSG:3112\")\n\n# Our resolution is now ~5km by 5km\nfuture_bioclim\n\n\nclass       : SpatRaster \ndimensions  : 770, 924, 19  (nrow, ncol, nlyr)\nresolution  : 5123.954, 5123.954  (x, y)\nextent      : -2477612, 2256922, -5117358, -1171913  (xmin, xmax, ymin, ymax)\ncoord. ref. : GDA94 / Geoscience Australia Lambert (EPSG:3112) \nsource(s)   : memory\nnames       : bioclim_01, bioclim_02, bioclim_03, bioclim_04, bioclim_05, bioclim_06, ... \nmin values  :    0.00000,    0.00000,    0.00000,     0.0000,    0.00000,  -4.138016, ... \nmax values  :   30.75635,   16.89703,   63.40196,   687.5078,   43.83433,  24.002493, ..."
  },
  {
    "objectID": "Session 3/ICCB_Environmental_data.html#mask-to-seq-extent-2",
    "href": "Session 3/ICCB_Environmental_data.html#mask-to-seq-extent-2",
    "title": "ICCB Environmental data download",
    "section": "Mask to SEQ extent",
    "text": "Mask to SEQ extent\n\n\nCode\nfuture_bioclim &lt;- terra::subst(from = 0, to = NA, future_bioclim) # Set all values of 0 to NA\n\nfuture_bioclim &lt;- terra::mask(future_bioclim, SEQ_extent.vect)\n\n# You can see that this has masked the area but the extent is still the same\nplot(future_bioclim[[1]])\n\n\n\n\n\n\n\n\n\nCode\nfuture_bioclim &lt;- terra::crop(future_bioclim, SEQ_extent.vect)\n\nplot(future_bioclim)\n\n\n\n\n\n\n\n\n\nCode\n# Save the future environmental covariates\nwriteRaster(future_bioclim, \n            filename = \"Data/Environmental_variables/future_bioclim.2090.SSP126.tif\",\n            overwrite = T)"
  },
  {
    "objectID": "Session 3/session_3_home.html",
    "href": "Session 3/session_3_home.html",
    "title": "Session 3",
    "section": "",
    "text": "Landing page for Session 3."
  },
  {
    "objectID": "Session 3/session_3_home.html#slides",
    "href": "Session 3/session_3_home.html#slides",
    "title": "Session 3",
    "section": "Slides",
    "text": "Slides\nDownload a PDF of the slides"
  },
  {
    "objectID": "Session 2/session_2_home.html",
    "href": "Session 2/session_2_home.html",
    "title": "Session 2",
    "section": "",
    "text": "Landing page for Session 2.\n\n\n\n Back to top"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ICCB - Open Source Geospatial Tools for Conservation under Climate Change",
    "section": "",
    "text": "This repo contains the materials for the ICCB workshop titled “Open Source Geospatial Tools for Conservation under Climate Change”, and can be viewed as the Quarto/GitHub pages site at https://geospatial-community.github.io/ICCB_geospatial_tools_conservation/."
  },
  {
    "objectID": "index.html#sessions",
    "href": "index.html#sessions",
    "title": "ICCB - Open Source Geospatial Tools for Conservation under Climate Change",
    "section": "Sessions",
    "text": "Sessions\n\nIntro to to geospatial data and tools\nDownscaled climate projections\nKoala species distribution modeling\nSpatial conservation planning\nMaking maps with QGIS\n\n\n\n\nWorkshop session outline"
  },
  {
    "objectID": "Session 1/session_1_home.html",
    "href": "Session 1/session_1_home.html",
    "title": "Session 1",
    "section": "",
    "text": "Landing page for Session 1.\n\n\n\n Back to top"
  }
]