[
  {
    "objectID": "Session 1/session_1_code.html",
    "href": "Session 1/session_1_code.html",
    "title": "Getting started with geospatial coding in R using the terra and sf packages",
    "section": "",
    "text": "No prior experience of spatial data is assumed, but this introduction will not have time to delve deeply into some important aspects of spatial data such as projections. We will use the two most commonly used R packages for geospatial data manipulation: sf for manipulating vector data, and terra for manipulating raster and vector data. If you are still using the raster package, you should move to terra; it is simpler, faster and can do more!\nResources:",
    "crumbs": [
      "Session 1",
      "Getting started with geospatial coding in R using the terra and sf packages"
    ]
  },
  {
    "objectID": "Session 1/session_1_code.html#prerequisites",
    "href": "Session 1/session_1_code.html#prerequisites",
    "title": "Getting started with geospatial coding in R using the terra and sf packages",
    "section": "Prerequisites",
    "text": "Prerequisites\nYou will need the terra and sf packages installed. We will also make an interactive map with terra, which requires the leaflet package to be installed, and we will need the dplyr package for data manipulation.\n\ninstall.packages(c(\"sf\", \"terra\", \"leaflet\", \"dplyr\", \"tmap\"))\n\nIf you have problems, there are more details about installing terra here and sf here.\nWe can now load the packages:\n\nlibrary(dplyr)\nlibrary(terra)\nlibrary(sf)\nlibrary(tmap)",
    "crumbs": [
      "Session 1",
      "Getting started with geospatial coding in R using the terra and sf packages"
    ]
  },
  {
    "objectID": "Session 1/session_1_code.html#vector-data",
    "href": "Session 1/session_1_code.html#vector-data",
    "title": "Getting started with geospatial coding in R using the terra and sf packages",
    "section": "Vector data",
    "text": "Vector data\nCan be points, lines or polygons. Vectors are useful for representing things like survey locations, rivers, and boundaries.\n\n\nCode\npts &lt;- rbind(c(3.2,4), c(3,4.6), c(3.8,4.4), c(3.5,3.8), c(3.4,3.6), c(3.9,4.5)) |&gt;\n  vect()\n\nlnes &lt;- as.lines(vect(rbind(c(3,4.6), c(3.2,4), c(3.5,3.8)))) |&gt;\n  rbind(as.lines(vect(rbind(c(3.9, 4.5), c(3.8, 4.4), c(3.5,3.8), c(3.4,3.6)))))\n\nlux &lt;- vect(system.file(\"ex/lux.shp\", package = \"terra\"))\n\npar(mfrow = c(1,3))\npar(mar = rep(0.1,4))\n\nplot(pts, axes = F, main = \"Points\")\nplot(lnes, col = \"blue\", axes = F, main = \"Lines\")\nplot(lux, \"NAME_2\", col = terrain.colors(12), las = 1, axes = F, main = \"Polygons\")",
    "crumbs": [
      "Session 1",
      "Getting started with geospatial coding in R using the terra and sf packages"
    ]
  },
  {
    "objectID": "Session 1/session_1_code.html#raster-data",
    "href": "Session 1/session_1_code.html#raster-data",
    "title": "Getting started with geospatial coding in R using the terra and sf packages",
    "section": "Raster data",
    "text": "Raster data\nRaster data is a grid of rectangles, normally called cells. Each cell has a value, making rasters useful for storing continuous data, such as temperature and elevation.\nHere is an example of raster data, where each cell in the raster represents elevation.\n\n\nCode\npar(mfrow = c(1,1)) #return to defaults\npar(mar = c(5, 4, 4, 2) + 0.1)\n\nelev &lt;- system.file(\"ex/elev.tif\", package = \"terra\") |&gt;\n  rast() |&gt;\n  aggregate(fact = 2)\n\nplot(elev, las = 1, main = \"Elevation map\", col = terrain.colors(100))\n\nelev |&gt;\n  as.polygons(aggregate = FALSE, na.rm = FALSE) |&gt;\n  lines(col = \"grey40\", lwd = 0.2)",
    "crumbs": [
      "Session 1",
      "Getting started with geospatial coding in R using the terra and sf packages"
    ]
  },
  {
    "objectID": "Session 1/session_1_code.html#making-and-inspecting-a-raster",
    "href": "Session 1/session_1_code.html#making-and-inspecting-a-raster",
    "title": "Getting started with geospatial coding in R using the terra and sf packages",
    "section": "Making and inspecting a raster",
    "text": "Making and inspecting a raster\nLets start by creating our own raster. We will be doing all manipulation of rasters with the terra package. To create rasters from scratch or load them from a file we use the function rast(). We can create a simple raster by specifying the x and y limits for the raster and the resolution (how big each cell is).\n\n#create raster\nras &lt;- rast(xmin = 0, xmax = 10, ymin = 0, ymax = 10, resolution = 2)\n\n#see what we've created\nras\n\nclass       : SpatRaster \ndimensions  : 5, 5, 1  (nrow, ncol, nlyr)\nresolution  : 2, 2  (x, y)\nextent      : 0, 10, 0, 10  (xmin, xmax, ymin, ymax)\ncoord. ref. : lon/lat WGS 84 (CRS84) (OGC:CRS84) \n\n\nThe figure below shows what most of the terms above refer to. As you can see, you don’t need to use all the terms to define a raster. Some other important points to note:\n\nEvery object in R has a class, such as data.frame and as you can see, rasters in terra are of class SpatRaster.\nWe did not tell rast() which coordinate reference system to use, so it defaults to using longitude latitude coordinates, also known as EPSG 4326. We will come back to coordinate reference systems later.\n\n\n\n\n\n\n\n\n\n\nBut what does the raster we created actually look like when plotted. Lets see. All we need is plot()\n\nplot(ras)\n\n\n\n\n\n\n\n\nWhy is there no plot? Because the raster we created is empty; there are no values associated with the the cells. Lets assign some values to each cell in the raster and try again. First we will find out how many cells are in our raster using `ncell()\n\nncell(ras)\n\n[1] 25\n\n\nOk, now we know this lets give our raster cells values from 1 to 25:\n\nvalues(ras) &lt;- 1:25\n\nplot(ras)\n\n\n\n\n\n\n\n\nNow our raster has values, we get a plot! Each cell has an integer value between 1 and 25, with cell values increasing from left to right and top to bottom. So the values start being “filled up” in the top left, and finish in the bottom right.\nLets have another look at our raster properties\n\nras\n\nclass       : SpatRaster \ndimensions  : 5, 5, 1  (nrow, ncol, nlyr)\nresolution  : 2, 2  (x, y)\nextent      : 0, 10, 0, 10  (xmin, xmax, ymin, ymax)\ncoord. ref. : lon/lat WGS 84 (CRS84) (OGC:CRS84) \nsource(s)   : memory\nname        : lyr.1 \nmin value   :     1 \nmax value   :    25 \n\n\nWe can now see a few extra pieces of information compared to last time:\n\nsources(s): where is the data held on your computer? It says memory for this raster, indicating that the raster is in the computer memory. Rasters can also be held on your hard disk, in which case this will be the file name of the raster. We won’t go into details here, but terra is smart about loading data into memory, only doing so when it needs to and it thinks it will have enough space.\nname: what is the raster called?\nmin value & max value: the minimum and maximum values in the raster\n\nOk, now we understand the basic structure of a raster, lets look at vector data using the sf package.",
    "crumbs": [
      "Session 1",
      "Getting started with geospatial coding in R using the terra and sf packages"
    ]
  },
  {
    "objectID": "Session 1/session_1_code.html#making-and-inspecting-a-vector",
    "href": "Session 1/session_1_code.html#making-and-inspecting-a-vector",
    "title": "Getting started with geospatial coding in R using the terra and sf packages",
    "section": "Making and inspecting a vector",
    "text": "Making and inspecting a vector\nAs mentioned earlier, vector data can be points, lines or polygons. Let’s start by making a single spatial point and plot it:\n\npt &lt;- st_point(c(1,3))\n\nplot(pt, axes = TRUE)\n\n\n\n\n\n\n\n\nSimple! But this is just a point. What if we want our point to have some information attached to it? For example, what the temperature is at that point. Well first we need to convert it into a simple feature collection:\n\npt_sf &lt;- pt |&gt; \n  st_sfc() |&gt; \n  st_as_sf()\n\npt_sf\n\n\n  \n\n\n\nInspecting the simple feature collection, pt_sf, that we created, we see that there is only 1 feature; our point. There is also a bounding box, which is the same concept as the x and y limits we had for our raster. Like the raster, we also have coordinate reference system (CRS), that is currently not defined.\nNow our point is a simple feature collection, we can add some information to it. We will add a column called “temperature” and give our point a value of 25.\n\npt_sf$temperature &lt;- 25\n\npt_sf\n\n\n  \n\n\n\nNow our point has a “field” attached to it with temperature data. The fields are simply columns that have information for each geometry; in our case a point.",
    "crumbs": [
      "Session 1",
      "Getting started with geospatial coding in R using the terra and sf packages"
    ]
  },
  {
    "objectID": "Session 1/session_1_code.html#vectors",
    "href": "Session 1/session_1_code.html#vectors",
    "title": "Getting started with geospatial coding in R using the terra and sf packages",
    "section": "Vectors",
    "text": "Vectors\n\nLoading and plotting\nMost of the time, we won’t be making our own data from scratch, but reading in data that we have downloaded or been provided with. In this workshop, you are going to be doing a case study of Koalas in south-east Queensland (SEQ). One of the first pieces of spatial data we normally need are the boundaries of the area we are working in. We will use spatial data of the local government areas (LGAs) in Queensland downloaded from the Queensland government website to define our SEQ boundary.\nWe use st_read() to read the data which is in the data folder you should have downloaded with the code from Github. The file is a Geopackage, which is widely used for storing geospatial data, and is similar (but better!) than shapefile. The st_read() command can read data in many different spatial formats: run st_drivers() to see a complete list of formats.\n\nlgas &lt;- st_read(\"data/Local_Government_Areas.gpkg\") \n\nReading layer `Local_Government_Areas' from data source \n  `/Users/scottforrest/Library/CloudStorage/OneDrive-QueenslandUniversityofTechnology/PhD - Scott Forrest/GIT/ICCB_geospatial_tools_conservation/Session 1/data/Local_Government_Areas.gpkg' \n  using driver `GPKG'\nSimple feature collection with 78 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 137.9947 ymin: -29.17925 xmax: 153.5519 ymax: -9.087977\nGeodetic CRS:  WGS 84\n\n\nsf gives us some information about the data we have read: we can see it is MULTIPOLYGON and has 78 features and 6 fields, i.e. 78 rows of geometry and 6 columns of data, and its CRS is WGS 84. We will come back to the coordinate reference system (CRS) later, so for now, lets have a look at the first few rows (features):\n\nhead(lgas)\n\n\n  \n\n\n\nNow we can see that the 6 fields contain information about each LGA, including various name formats and the areas. The final column called “Shape” contains the spatial information: the coordinates for each point that makes up the polygons. This column is most commonly labelled “geometry”.\nThe fields in our sf data are just like columns in a data frame. So if we want all the values in one column, we can just select that column in the same way as a data frame:\n\nlgas$lga\n\n [1] \"Aurukun Shire\"                    \"Balonne Shire\"                   \n [3] \"Banana Shire\"                     \"Barcaldine Regional\"             \n [5] \"Barcoo Shire\"                     \"Blackall Tambo Regional\"         \n [7] \"Boulia Shire\"                     \"Brisbane City\"                   \n [9] \"Burdekin Shire\"                   \"Burke Shire\"                     \n[11] \"Cairns Regional\"                  \"Carpentaria Shire\"               \n[13] \"Cassowary Coast Regional\"         \"Central Highlands Regional\"      \n[15] \"Charters Towers Regional\"         \"Maranoa Regional\"                \n[17] \"Mareeba Shire\"                    \"Mckinlay Shire\"                  \n[19] \"Moreton Bay City\"                 \"Mornington Shire\"                \n[21] \"Mount Isa City\"                   \"Murweh Shire\"                    \n[23] \"Napranum Aboriginal Shire\"        \"Noosa Shire\"                     \n[25] \"North Burnett Regional\"           \"Northern Peninsula Area Regional\"\n[27] \"Palm Island Aboriginal Shire\"     \"Paroo Shire\"                     \n[29] \"Pormpuraaw Aboriginal Shire\"      \"Quilpie Shire\"                   \n[31] \"Redland City\"                     \"Richmond Shire\"                  \n[33] \"Rockhampton Regional\"             \"Scenic Rim Regional\"             \n[35] \"Somerset Regional\"                \"South Burnett Regional\"          \n[37] \"Southern Downs Regional\"          \"Sunshine Coast Regional\"         \n[39] \"Tablelands Regional\"              \"Toowoomba Regional\"              \n[41] \"Torres Shire\"                     \"Torres Strait Island Regional\"   \n[43] \"Townsville City\"                  \"Bulloo Shire\"                    \n[45] \"Bundaberg Regional\"               \"Cherbourg Aboriginal Shire\"      \n[47] \"Cloncurry Shire\"                  \"Cook Shire\"                      \n[49] \"Croydon Shire\"                    \"Diamantina Shire\"                \n[51] \"Isaac Regional\"                   \"Kowanyama Aboriginal Shire\"      \n[53] \"Livingstone Shire\"                \"Lockhart River Aboriginal Shire\" \n[55] \"Lockyer Valley Regional\"          \"Logan City\"                      \n[57] \"Longreach Regional\"               \"Mackay Regional\"                 \n[59] \"Mapoon Aboriginal Shire\"          \"Doomadgee Aboriginal Shire\"      \n[61] \"Douglas Shire\"                    \"Etheridge Shire\"                 \n[63] \"Flinders Shire\"                   \"Fraser Coast Regional\"           \n[65] \"Gladstone Regional\"               \"Gold Coast City\"                 \n[67] \"Goondiwindi Regional\"             \"Gympie Regional\"                 \n[69] \"Hinchinbrook Shire\"               \"Hope Vale Aboriginal Shire\"      \n[71] \"Ipswich City\"                     \"Weipa Town\"                      \n[73] \"Western Downs Regional\"           \"Whitsunday Regional\"             \n[75] \"Winton Shire\"                     \"Woorabinda Aboriginal Shire\"     \n[77] \"Wujal Wujal Aboriginal Shire\"     \"Yarrabah Aboriginal Shire\"       \n\n\nLet’s plot the data to see what we have:\n\nplot(lgas)\n\n\n\n\n\n\n\n\nLooks like Queensland! We got one map for each field (column). If we want a map of just one field we can select only the field we want:\n\nplot(lgas[, \"lga\"], axes = TRUE)\n\n\n\n\n\n\n\n\nWe added axes using the axes = TRUE argument.\n\n\nSubsetting and merging\nOur data has local government areas (LGAs) for the whole of Queensland, but we just want a polygon of south-east Queensland (SEQ). How do we get that?\nFirst, we make a vector containing the names of all the LGAs in SEQ:\n\nseq_lga_names &lt;- c(\n  \"Brisbane City\",\n  \"Moreton Bay City\",\n  \"Logan City\",\n  \"Ipswich City\",\n  \"Redland City\",\n  \"Scenic Rim Regional\",\n  \"Somerset Regional\",\n  \"Lockyer Valley Regional\",\n  \"Gold Coast City\",\n  \"Sunshine Coast Regional\",\n  \"Toowoomba Regional\",\n  \"Noosa Shire\"\n)\n\nNow we can subset our LGAs spatial data for just these LGAs:\n\nlgas_seq &lt;- lgas |&gt; \n  filter(lga %in% seq_lga_names) #select only the rows of data with LGA names that we have listed\n\nplot(lgas_seq[, \"lga\"])\n\n\n\n\n\n\n\n\nGreat! We’ve got only the LGAs in SEQ. But at the moment we have many polygons that make up SEQ:\n\nhead(lgas_seq)\n\n\n  \n\n\n\nHow do we get just one polygon that is the boundary of the area? We use st_union():\n\nseq_boundary &lt;- st_union(lgas_seq)\n\nplot(seq_boundary)\n\n\n\n\n\n\n\n\nThis merges all our polygons into one polygon. Note that we lose all the fields when we do this:\n\nhead(seq_boundary)\n\nGeometry set for 1 feature \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 150.7027 ymin: -28.36387 xmax: 153.5519 ymax: -26.13711\nGeodetic CRS:  WGS 84\n\n\nMULTIPOLYGON (((153.2366 -27.43647, 153.2385 -2...",
    "crumbs": [
      "Session 1",
      "Getting started with geospatial coding in R using the terra and sf packages"
    ]
  },
  {
    "objectID": "Session 1/session_1_code.html#rasters",
    "href": "Session 1/session_1_code.html#rasters",
    "title": "Getting started with geospatial coding in R using the terra and sf packages",
    "section": "Rasters",
    "text": "Rasters\n\nLoading and plotting\nWe now want to get some climate data for our south-east Queensland study area that we will use in a later session to do species modelling. Climate data is normally stored in raster format, so we will be using the terra package to manipulate the data. Example climate data is already in the data folder, and you will learn about how to create these data in the following session. For now, let’s load one of the climate rasters and have a look at it:\n\nclimate1 &lt;- rast(\"data/Current_climate_QLD/bioclim_01.tif\")\n\nclimate1\n\nclass       : SpatRaster \ndimensions  : 681, 841, 1  (nrow, ncol, nlyr)\nresolution  : 0.05, 0.05  (x, y)\nextent      : 111.975, 154.025, -44.025, -9.975  (xmin, xmax, ymin, ymax)\ncoord. ref. : lon/lat WGS 84 (EPSG:4326) \nsource      : bioclim_01.tif \nname        : bioclim_01 \n\n\nIt is a raster with 0.05 degree resolution: we know it is in degrees because it is unprojected, in the EPSG 4326 coordinate reference system. Let’s plot the data:\n\nplot(climate1)\n\n\n\n\n\n\n\n\nWe can see that the data covers the whole of Australia. What type of data do you think this is?\n\n\nCropping and masking\nThe raster data we have at the moment is for a much larger area than just SEQ. Let’s plot our raster and SEQ polygon together to see:\n\nseq_vect &lt;- vect(seq_boundary) #we need to convert our sf polygon into a SpatVector, which is the vector format that the terra package uses\n\nplot(climate1) \nlines(seq_vect) #adds the SEQ polygon as lines on top of the raster\n\n\n\n\n\n\n\n\nTo get only SEQ data, we need to crop and mask the raster data using our SEQ polygon.\nCropping means that we keep only the data inside the extent of the vector we are using. Mask means that all the data outside the vector is set to NA or some other value we specify. Lets have a look how this works.\nFirst lets have a look at the extent of the SEQ polygon. We can get the extent of a raster or vector using ext(). We need to convert this into a SpatVector object for plotting using vect(). We only need to do this for plotting; when we crop, we can just use the SEQ polygon as the input.\n\nseq_vect_extent &lt;- ext(seq_vect) |&gt; \n  vect()\n\nplot(climate1)\nlines(seq_vect)\nlines(seq_vect_extent, col = \"blue\")\n\n\n\n\nCropping means we remove everything outside the extent (blue box) of our polygon. Masking sets all values outside our polygon to NA.\n\n\n\n\nSo when we crop, we get only the area within the blue box.\nWe crop using the crop() function, using the raster we want to crop as the first argument and the vector we are cropping as the second.\n\n#crop\nclimate1_cropped &lt;- crop(climate1, seq_vect)\n\n#plot\nplot(climate1_cropped)\nlines(seq_vect)\n\n\n\n\n\n\n\n\nNow we have cropped our raster, we can mask it so that we only have values for the area within the SEQ boundary. We do this using mask:\n\n#mask\nclimate_seq &lt;- mask(climate1_cropped, seq_vect)\n\n#plot\nplot(climate_seq)\nlines(seq_vect)\n\n\n\n\n\n\n\n\nNow we only see raster values for cells that are within the SEQ boundary. But remember that the areas that are white, still have values, they are just NA values. We can confirm this by plotting the NA cells in grey (or any other colour):\n\nplot(climate_seq, colNA = \"grey\")\nlines(seq_vect)\n\n\n\n\n\n\n\n\nOften we want to crop and mask one after the other, and you can do this in one command using crop(climate1_projected, seq_vect, mask = TRUE).\nFor reference, here is a figure comparing what crop, mask and crop(mask = TRUE) do:\n\n\nCode\npar(mfrow = c(2,2))\n\nplot(climate1, main = \"Original raster\")\nlines(seq_vect)\n\nplot(climate1_cropped, main = \"Cropped\")\nlines(seq_vect)\n\nclimate1 |&gt;\n  mask(seq_vect) |&gt;\n  plot(main = \"Masked\")\nlines(seq_vect)\n\nplot(crop(climate1, seq_vect, mask = TRUE), main = \"Cropped and masked\")\nlines(seq_vect)\n\n\n\n\n\n\n\n\n\nWhy not just mask rather than crop and mask? As we see in the figure above, this would mean we have a lot of area we are not interested in and even though most of those cells would be NA they take up space in our raster, so it is not efficient.\n\n\nRaster values\nRemember that each cell in our raster has a value. We might want to examine some summaries of these raster values. We can get a histogram of all the values in a raster using the hist() function:\n\nhist(climate_seq)\n\n\n\n\n\n\n\n\nThere is a tail of low values, which are mostly from the south-east of Australia (Tasmania is chilly!). What is the mean value for the whole of Australia?\n\nglobal(climate_seq, \"mean\", na.rm = TRUE)\n\n\n  \n\n\n\nWe can also get a statistical summary of the raster values just by using the summary() function:\n\nsummary(climate_seq)\n\n   bioclim_01   \n Min.   :15.36  \n 1st Qu.:18.72  \n Median :19.39  \n Mean   :19.43  \n 3rd Qu.:20.32  \n Max.   :21.49  \n NA's   :1118   \n\n\n\n\nRaster math\nThe great thing about rasters are you can do maths with them! For example, doing climate1 + 1 just adds one to each raster value, and doing climate1*2 multiplies each raster value by two.\nAs an example, lets convert our temperature data into Fahrenheit for our confused colleagues from the U.S. The conversion from Celsius to Fahrenheit is: Fahrenheit = (Celsius * 1.8) + 32.\n\n#do the conversion\nclimate_seq_fahrenheit &lt;- (climate_seq*1.8) + 32\n\n#plot our new raster\nplot(climate_seq_fahrenheit)\n\n\n\n\n\n\n\n\n\n\nCoordinate reference systems and projection\nRemember that the CRS of our data is WGS 84. What does this mean? We can get some more information using st_crs():\n\ncrs(climate_seq)\n\n[1] \"GEOGCRS[\\\"WGS 84\\\",\\n    ENSEMBLE[\\\"World Geodetic System 1984 ensemble\\\",\\n        MEMBER[\\\"World Geodetic System 1984 (Transit)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G730)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G873)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G1150)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G1674)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G1762)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G2139)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G2296)\\\"],\\n        ELLIPSOID[\\\"WGS 84\\\",6378137,298.257223563,\\n            LENGTHUNIT[\\\"metre\\\",1]],\\n        ENSEMBLEACCURACY[2.0]],\\n    PRIMEM[\\\"Greenwich\\\",0,\\n        ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n    CS[ellipsoidal,2],\\n        AXIS[\\\"geodetic latitude (Lat)\\\",north,\\n            ORDER[1],\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n        AXIS[\\\"geodetic longitude (Lon)\\\",east,\\n            ORDER[2],\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n    USAGE[\\n        SCOPE[\\\"Horizontal component of 3D system.\\\"],\\n        AREA[\\\"World.\\\"],\\n        BBOX[-90,-180,90,180]],\\n    ID[\\\"EPSG\\\",4326]]\"\n\n\nThis is the well-known text (wkt) description of the CRS, which gives a lot of detail. Let’s get a simpler version:\n\ncrs(climate_seq, describe = TRUE)\n\n\n  \n\n\n\nWe often have to deal with spatial data that have different CRS’s, which involves transforming the data from one CRS to another. But first, what is a CRS?\n\nCoordinate reference systems\n\n\nClick here to expand this section\n\nIf we want to know where things are in space, we need to use some kind of spatial reference. We can use our own arbitrary system, e.g. a sampling grid like the one shown in the photo below where we could define the location of each square relative to one of the corners. But normally we want to know where something is on Earth.\n\n\n\n\n\n\n\n\n\nThere are two types of coordinate systems we can use to represent locations on Earth:\n\nGeographic coordinate systems (GCS): uses a 3-D surface (e.g. globe) to define locations on the Earth using longitude and latitude. The 3-D surface is normally an ellipsoid which approximates the Earth but cannot be exact since the Earth is not a smooth surface. This approximation of the Earth is called a datum and can be aligned with the true Earth (the geoid) in different ways depending on whether we are trying to get a good approximation at some particular location (local datum), e.g. Brisbane, or best approximation across the whole Earth (geocentric datum). The figure below (sourced from here) shows examples of these datums.\n\n\n\n\n\n\n\n\n\n\nA commonly used geocentric datum is World Geodetic Survey for 1984 (WGS84). This is almost synonymous with the commonly used coordinate reference system EPSG 4326, but EPSG 4326 defines the latitude and longitude coordinates used on the WGS84 ellipsoid (Ref)\n\nProjected coordinate system (projection): Unfortunately, we can’t carry around globes all the time when we want to look at a map, and doing calculations, such as distance and area, in 3-D is much more difficult than 2-D. So we need a way of getting from our 3-D globe to a piece of paper (or for younger people, a screen). To do this we need to ‘project’ from a GCS to a projected coordinate system, which is called projection because we can think of this as putting a light in the centre of a globe and the light shines through the globe projecting features onto a flat piece of paper. The figure below (from QGIS docs) illustrates this, showing the 3 projection families:\n\n\n\n\n\n\na) Cylindrical; b) conical, and; c) planar projecions\n\n\n\n\nAll projections are a compromise because they will always distort the shape, area, distances, and directions of the original GCS. A map that preserves shape is called conformal; one that preserves area is called equal-area; one that preserves distance is called equidistant; and one that preserves direction is called azimuthal. There are a huge number of projections available and choosing the correct one can be challenging. Often your choice will be to use the a local projection that is used by goverment or other authorities in the location you are working, e.g. for this workshop we will use EPSG 7856, GDA2020 / MGA zone 56, which is suitable for our study area of south-east Queensland. For global work where equal area is important, the Mollweide projection is commonly used.\nWe have only covered the basics of coordinate reference systems because it is a big topic to cover. The following resources are useful for understanding in more depth:\n\nThe QGIS software documentation\nThe Geocomputation with R book section\nR for Spatial Data Science book section\nStackexchange question about WGS84\n\n\nComing back to our Queensland data, you will remember that it is in the WGS 84 CRS, which is a geographic CRS. We want to transform it into a suitable projected CRS. We will be using GDA2020 / MGA zone 56, which is identified by the EPSG code 7843. Let’s check if this is a suitable projection:\n\ncrs(\"EPSG:7856\", describe = TRUE)\n\n\n  \n\n\n\nIt says it’s suitable for Australia between 150°E and 156°E. Is our data between those bounds? We can check by finding the extent of the unprojected data, which is in degrees longitude and latitude:\n\next(climate_seq)\n\nSpatExtent : 150.725, 153.575, -28.375, -26.125 (xmin, xmax, ymin, ymax)\n\n\nYep, we’re good!\nSo now we can go ahead and project the data:\n\nclimate_seq_projected &lt;- project(climate_seq, \"EPSG:7856\")\n\nplot(climate_seq_projected)\n\n\n\n\n\n\n\n\nThe data looks the same, but our axes are no longer in degrees latitude and longitude. What are our units of measurement in our projected CRS? Normally they would be metres (unless you’re in some weird American projection and you’re using feet), but lets check. We need to use sf’s crs function for this:\n\nst_crs(climate_seq_projected)$units_gdal\n\n[1] \"metre\"\n\n\nYep, we’re in metres. Compare this to the units for the unprojected data:\n\nst_crs(climate_seq)$units_gdal\n\n[1] \"degree\"\n\n\nIt is really important to understand that when we project a raster, we are changing the raster, because we have to create a new raster in the new CRS.\nLets compare our original raster and the projected version:\n\nclimate_seq\n\nclass       : SpatRaster \ndimensions  : 45, 57, 1  (nrow, ncol, nlyr)\nresolution  : 0.05, 0.05  (x, y)\nextent      : 150.725, 153.575, -28.375, -26.125  (xmin, xmax, ymin, ymax)\ncoord. ref. : lon/lat WGS 84 (EPSG:4326) \nsource(s)   : memory\nvarname     : bioclim_01 \nname        : bioclim_01 \nmin value   :   15.35748 \nmax value   :   21.49342 \n\n\n\nclimate_seq_projected\n\nclass       : SpatRaster \ndimensions  : 48, 55, 1  (nrow, ncol, nlyr)\nresolution  : 5184.076, 5184.076  (x, y)\nextent      : 272527.9, 557652.1, 6861637, 7110473  (xmin, xmax, ymin, ymax)\ncoord. ref. : GDA2020 / MGA zone 56 (EPSG:7856) \nsource(s)   : memory\nname        : bioclim_01 \nmin value   :   15.44909 \nmax value   :   21.47693 \n\n\nThe extent, resolution, and dimensions of the projected raster are all different from the unprojected one. This projected CRS has units of meters, which means the size of each raster cell is 5184.08m x 5184.08m.\nLet’s compare the statistics for the two rasters:\n\nsummary(climate_seq)\n\n   bioclim_01   \n Min.   :15.36  \n 1st Qu.:18.72  \n Median :19.39  \n Mean   :19.43  \n 3rd Qu.:20.32  \n Max.   :21.49  \n NA's   :1118   \n\nsummary(climate_seq_projected)\n\n   bioclim_01   \n Min.   :15.45  \n 1st Qu.:18.67  \n Median :19.38  \n Mean   :19.42  \n 3rd Qu.:20.27  \n Max.   :21.48  \n NA's   :1172   \n\n\nThe statistics are similar, but not exactly the same. There are more NA values in the projected raster, largely because there are more cells: 2565 in the original and 2640 in the projected raster.\nThese changes in the raster are really important to think about when making decisions about projecting rasters. In general avoid projecting rasters if you can. You can find more information about the methods you can use when project in the project() help file (?project).\nWe can also project vector data. For this we use the sf function st_transform(). Let’s project our SEQ boundary polygon into the local projection:\n\nseq_boundary_projected &lt;- st_transform(seq_boundary, 7856)\n\nseq_boundary_projected\n\nGeometry set for 1 feature \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 273950.9 ymin: 6862464 xmax: 554186.6 ymax: 7109132\nProjected CRS: GDA2020 / MGA zone 56\n\n\nMULTIPOLYGON (((523385.9 6965198, 523570.3 6965...\n\n\nNote that we don’t need to use the “EPSG:” part like we did when using project().\nThe nice thing about projecting vector data is that the values stay the same. So if you can, project your vector data into the CRS of your raster data.\n\n\n\nMany raster layers\nWe’ve been working with just one raster, but what if we want to do the same thing to many rasters at the same time?\nIn the data/Current_climate_QLD folder, there are 19 raster files. It would be painful to have to load, crop, mask and project each file individually. A very useful feature of rasters is that they can have many layers. These layers often represent different time periods, such as days or months, or different variables, such as temperature maximum, minimum and mean.\nFirst we need to load all 19 rasters. We can do this by getting the file names and then reading those file into a list.\n\nbioclim_list &lt;- list.files(\"data/Current_climate_QLD\", full.names = TRUE) |&gt; \n  lapply(FUN = rast)\n\nThe lapply() applies the rast() function to each file name, i.e. loads each raster, and places them into a list. If you haven’t encountered lists before, they can be a little confusing, but they are very helpful for holding any type of data. In our case, each element in the list is a raster. We can access each list element using the index. For example, to get the first object (in our case, raster), we do:\n\nbioclim_list[[1]]\n\nclass       : SpatRaster \ndimensions  : 681, 841, 1  (nrow, ncol, nlyr)\nresolution  : 0.05, 0.05  (x, y)\nextent      : 111.975, 154.025, -44.025, -9.975  (xmin, xmax, ymin, ymax)\ncoord. ref. : lon/lat WGS 84 (EPSG:4326) \nsource      : bioclim_01.tif \nname        : bioclim_01 \n\n\nWe can find out how long our list is using length():\n\nlength(bioclim_list)\n\n[1] 19\n\n\nThis is the same number of files that we read in: each raster is 1 element in the list.\nWe can manipulate the rasters in the list, but it is a little easier if we can just create a single raster object to work with. Happily we can create a multi-layer raster, with each of our rasters as one layer.\n\nbioclim_ras &lt;- rast(bioclim_list)\nbioclim_ras\n\nclass       : SpatRaster \ndimensions  : 681, 841, 19  (nrow, ncol, nlyr)\nresolution  : 0.05, 0.05  (x, y)\nextent      : 111.975, 154.025, -44.025, -9.975  (xmin, xmax, ymin, ymax)\ncoord. ref. : lon/lat WGS 84 (EPSG:4326) \nsources     : bioclim_01.tif  \n              bioclim_02.tif  \n              bioclim_03.tif  \n              ... and 16 more sources\nnames       : bioclim_01, bioclim_02, bioclim_03, bioclim_04, bioclim_05, bioclim_06, ... \n\n\nWe can see that we have many raster names, and the nlyr (number of layers) variable is now 19.\nWe can think of a multi-layer raster as a data sandwich (as my colleague likes to say!):\n\n\nCode\n#This is to create a stack of maps \n#The code is modified from: https://www.urbandemographics.org/post/figures-map-layers-r/\n\n#functions\nrotate_data &lt;- function(data, y_add) {\n  x_add = 0\n  \n  shear_matrix &lt;- function(){ matrix(c(2, 1.2, 0, 1), 2, 2) }\n  \n  rotate_matrix &lt;- function(x){ \n    matrix(c(cos(x), sin(x), -sin(x), cos(x)), 2, 2) \n  }\n  data %&gt;% \n    dplyr::mutate(\n      geometry = .$geometry * shear_matrix() * rotate_matrix(pi/20) + c(x_add, y_add)\n    )\n}\n\n#aggregate and polygonize data\ntemp_poly &lt;- aggregate(bioclim_ras, fact = 4) |&gt; \n  as.polygons(aggregate = FALSE) |&gt; \n  st_as_sf()\n  \n#make tilted plot\nggplot2::ggplot() +\n  ggplot2::geom_sf(data = rotate_data(temp_poly[,1], y_add = 0), ggplot2::aes(fill = .data[[names(temp_poly)[1]]]), color=NA, show.legend = FALSE) +\n  ggplot2::scale_fill_viridis_c() +\n  ggplot2::geom_sf(data = rotate_data(temp_poly[,7], y_add = 20), ggplot2::aes(fill = .data[[names(temp_poly)[7]]]), color=NA, show.legend = FALSE) +\n  ggplot2::scale_fill_viridis_c() +\n  ggplot2::geom_sf(data = rotate_data(temp_poly[,8], y_add = 40), ggplot2::aes(fill = .data[[names(temp_poly)[8]]]), color=NA, show.legend = FALSE) +\n  ggplot2::scale_fill_viridis_c() +\n  ggplot2::geom_sf(data = rotate_data(temp_poly[,5], y_add = 60), ggplot2::aes(fill = .data[[names(temp_poly)[5]]]), color=NA, show.legend = FALSE) +\n  ggplot2::scale_fill_viridis_c() +\n  ggplot2::theme_void()\n\n\n\n\n\n\n\n\n\nWe can use functions on our new multi-layer raster in the same way as we did for just one raster layer. We can map the rasters using the plot() function as normal:\n\nplot(bioclim_ras)\n\n\n\n\n\n\n\n\nNot all the rasters fit in the window, so only the first 16 are show.\nIt’s important to remember that if you want to put rasters into a multi-layer raster like we have done here, they must be the same extent, resolution, and crs.\nNow, we want to crop, mask and project our raster, same as we did with our single raster before. We can use exactly the same commands:\n\nbioclim_seq &lt;- bioclim_ras |&gt; \n  crop(seq_vect, mask = TRUE) |&gt; \n  project(crs(climate_seq_projected))\n\nJust three lines of codes and we’ve got our 19 rasters cropped, masked and projected! Let’s check everything looks right:\n\nplot(bioclim_seq)",
    "crumbs": [
      "Session 1",
      "Getting started with geospatial coding in R using the terra and sf packages"
    ]
  },
  {
    "objectID": "Session 1/session_1_code.html#nice-maps",
    "href": "Session 1/session_1_code.html#nice-maps",
    "title": "Getting started with geospatial coding in R using the terra and sf packages",
    "section": "Nice maps",
    "text": "Nice maps\nSo far we have been using the plot() functions from the terra and sf packages. If you want to make detailed, publication quality maps, there are many great plotting packages such as tmap and ggplot. The final session of this workshop goes into detail about making nice maps, and there is an excellent section on map making in the Geocomputation with R book. For now, we will use the tmap package to make a nice map of our rasters with the SEQ polygon boundary.\nTo make maps using tmap, you build up layers. You add data layers to the map using tm_shape() and that is followed by another tm_ function that tells tmap what kind of data you are visualizing (e.g. raster, polygons, points) and how to show it (what colours, scales, etc.). First let’s plot some of the raster data. We will use just the first two rasters from our multi-layer raster:\n\ntm_shape(bioclim_seq[[1:2]]) +\n  tm_raster()\n\n\n\n\n\n\n\n\nWe will change colours and scales in a moment, but first let’s add our SEQ boundary polygon. We use tm_shape() to tell it what data we want to map, and then tm_borders() to show it as a border, not a filled polygon.\n\ntm_shape(bioclim_seq[[1:2]]) +\n  tm_raster() +\n  tm_shape(seq_boundary_projected) +\n  tm_borders()\n\n\n\n\n\n\n\n\nWe can add a scale bar and north arrow with two simple functions:\n\ntm_shape(bioclim_seq[[1:2]]) +\n  tm_raster() +\n  tm_shape(seq_boundary_projected) +\n  tm_borders() +\n  tm_scalebar() +\n  tm_compass()\n\n\n\n\n\n\n\n\nLet’s move the north arrow to the top left of the frame where there is some space, and set the scale bar to have marks at 0, 50 and 100 km. We will also change our raster scale colour palette:\n\ntm_shape(bioclim_seq[[1:2]]) +\n  tm_raster(col.scale = tm_scale_continuous(values = \"brewer.yl_or_rd\")) +\n  tm_shape(seq_boundary_projected) +\n  tm_borders() +\n  tm_scalebar(breaks = c(0, 50, 100)) +\n  tm_compass(position = c(\"left\", \"top\"))\n\n[plot mode] fit legend/component: Some legend items or map compoments do not\nfit well, and are therefore rescaled.\nℹ Set the tmap option `component.autoscale = FALSE` to disable rescaling.\n\n\n\n\n\n\n\n\n\nThere are a HUGE variety of colour scales available. A good way to see some options is to use the cols4all package that is installed when you install the tmap package:\n\ncols4all::c4a_gui()\n\nThis brings up a window where you can view many colour palettes and lots of information about them, such as if the palette is colour blind friendly.\nWe can make a few more tweaks to our maps to make them a bit neater:\n\ntm_shape(bioclim_seq[[1:2]]) +\n  tm_raster(col.scale = tm_scale_continuous(values = \"brewer.yl_or_rd\"),\n            col.legend = tm_legend(title = \"Temperature\", #Title for legends\n                                   orientation = \"landscape\")) + #change legends to landscape (horizontal) orientation\n  tm_shape(seq_boundary_projected) +\n  tm_borders() +\n  tm_scalebar(breaks = c(0, 50, 100)) +\n  tm_compass(position = c(\"left\", \"top\")) +\n  tm_layout(panel.labels = c(\"Climate layer 1\", \"Climate layer 2\")) #labels above each map\n\n[plot mode] fit legend/component: Some legend items or map compoments do not\nfit well, and are therefore rescaled.\nℹ Set the tmap option `component.autoscale = FALSE` to disable rescaling.\n\n\n\n\n\n\n\n\n\n\nInteractive maps\nIt’s often useful to see your data on a maps that you can move around on, with basemaps, such as satellite data, already loaded. There are two quick ways to do this. One is to use the plet() function from terra, which is just like plot(), but makes an interactive map, using the leaflet package behind the scenes:\n\nplet(bioclim_seq[[1]]) #show only the first layer of the multi-layer raster\n\n\n\n\n\nWe can choose a different basemap using the tiles = argument:\n\nplet(bioclim_seq[[1]], tiles = \"Esri.WorldImagery\")\n\n\n\n\n\nAnother way of making an interactive map is using tmap and the tmap_mode() function:\n\ntmap_mode(\"view\") #all tmap plots from now on will be interactive\n\nℹ tmap mode set to \"view\".\n\n#now we copy our tmap code from above\ntm_shape(bioclim_seq[[1:2]]) +\n  tm_raster(col.scale = tm_scale_continuous(values = \"brewer.yl_or_rd\"),\n            col.legend = tm_legend(title = \"Temperature\", #Title for legends\n                                   orientation = \"landscape\")) + #change legends to landscape (horizontal) orientation\n  tm_shape(seq_boundary_projected) +\n  tm_borders()\n\n[landscape legend in view mode] doesn't support labels yet\nThis message is displayed once per session.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntmap_mode(\"plot\") #reset the plotting to non-interactive\n\nℹ tmap mode set to \"plot\".",
    "crumbs": [
      "Session 1",
      "Getting started with geospatial coding in R using the terra and sf packages"
    ]
  },
  {
    "objectID": "Session 1/session_1_code.html#saving",
    "href": "Session 1/session_1_code.html#saving",
    "title": "Getting started with geospatial coding in R using the terra and sf packages",
    "section": "Saving",
    "text": "Saving\nWe will need the SEQ polygon later, so lets save it using st_write():\n\nst_write(seq_boundary_projected, \"data/seq_boundary.gpkg\", append = FALSE)\n\nDeleting layer `seq_boundary' using driver `GPKG'\nWriting layer `seq_boundary' to data source \n  `data/seq_boundary.gpkg' using driver `GPKG'\nWriting 1 features with 0 fields and geometry type Multi Polygon.\n\n\nYou can save in many different formats (see st_drivers()). You can change the file format just by changing the file extension, e.g. use “seq_polygon.shp” if you want a shapefile.\nWe use the append = FALSE argument to overwrite a file with the same name. This is useful if you are making changes to code and want to make sure that the most up-to-date version of your data gets saved.\nWe will also need the cropped, masked and projected climate data. We can save rasters using the writeRaster() function from the terra package:\n\nwriteRaster(bioclim_seq, \"data/bioclim_seq.tif\", overwrite = TRUE)\n\nWe don’t need to save each raster as a separate file, instead we save a single multi-band Geotiff. Geotiff is a widely used raster file format and can be loaded by pretty much any GIS software.\nWe can check that this file will load as a multi-layer raster:\n\nrast(\"data/bioclim_seq.tif\")\n\nclass       : SpatRaster \ndimensions  : 48, 55, 19  (nrow, ncol, nlyr)\nresolution  : 5184.076, 5184.076  (x, y)\nextent      : 272527.9, 557652.1, 6861637, 7110473  (xmin, xmax, ymin, ymax)\ncoord. ref. : GDA2020 / MGA zone 56 (EPSG:7856) \nsource      : bioclim_seq.tif \nnames       : bioclim_01, bioclim_02, bioclim_03, bioclim_04, bioclim_05, bioclim_06, ... \nmin values  :   15.44909,    6.61918,   41.13598,   325.6700,   25.56623,   2.795907, ... \nmax values  :   21.47693,   14.57873,   50.49781,   548.4877,   34.20971,  12.623736, ...",
    "crumbs": [
      "Session 1",
      "Getting started with geospatial coding in R using the terra and sf packages"
    ]
  },
  {
    "objectID": "Session 1/session_1_code.html#wrapping-up",
    "href": "Session 1/session_1_code.html#wrapping-up",
    "title": "Getting started with geospatial coding in R using the terra and sf packages",
    "section": "Wrapping-up",
    "text": "Wrapping-up\nWe’ve covered the basics of vector and raster manipulation in R using the sf and terra packages, and the tmap package for making maps. This is a relatively short introduction to a lot of geospatial concepts, but should provide the background you need for the following sessions which focus on data retrieval, manipulation and modelling.",
    "crumbs": [
      "Session 1",
      "Getting started with geospatial coding in R using the terra and sf packages"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This training course was organized by the Geospatial Share Community of Practice based in Australia.\nOur mission is to build a supportive and inclusive community where students, researchers, and professionals can grow their geospatial skills together. See the Geospatial Share website to see the other workshops and tutorials we have organized throughout the years."
  },
  {
    "objectID": "about.html#organizers",
    "href": "about.html#organizers",
    "title": "About",
    "section": "Organizers",
    "text": "Organizers\n\nMitch Rudge\n\nMitch created the GeoSpatial Share Community, completed his PhD at UQ, and now works as a Natural Capital Data Scientist at Bush Heritage Australia.\n\n\n\nCatherine Kim\n\nCatherine is a marine scientist at the Queensland University of Technology and passionate about upskilling students, researchers, and professionals with data science skills."
  },
  {
    "objectID": "about.html#session-leads",
    "href": "about.html#session-leads",
    "title": "About",
    "section": "Session Leads",
    "text": "Session Leads\n\nJason Flower\n\nProject Researcher at the Environmental Market Solutions Lab (emLab) at the University of California, Santa Barbara working on marine spatial planning and coastal and fisheries management on islands in the Caribbean, Pacific, and Western Indian Ocean. His work has helped guide marine spatial planning in Montserrat and Bermuda, and inform fisheries management in Barbuda, Curacao, the Maldives, and Montserrat.\n\n\n\nRalph Trancoso\n\nRalph Trancoso is a senior research scientist and adjunct associate professor with a strong track record of leading multidisciplinary projects that deliver impactful outcomes for science, policy, and natural resource management across Australia and Brazil. With deep expertise in climate change, natural hazards, risk assessment, hydrology, and spatial sciences, he excels at translating complex science into actionable knowledge and public-facing services using cutting-edge web technologies. Ralph is also a skilled scientific programmer, communicator, and writer, known for his leadership, mentoring, and creative problem-solving.\n\n\n\nSarah Chapman\n\nSarah Chapman is a Principal Climate Data Scientist in the Climate Projections & Services team at Queensland Treasury and an Honorary Research Fellow at the University of Queensland. She brings extensive experience in climate change research, having previously worked at the University of Leeds on the impacts of climate change on heat stress and agriculture in Africa. Her PhD at the University of Queensland focused on urban heat island effects and heat stress driven by climate change and urban growth. Sarah holds a Master of Environmental Management from UQ and a Bachelor of Science in Environment and Economics from McGill University in Canada.\n\n\n\nRohan Eccles\n\n\n\n\n\nCharlotte Patterson\n\nCharlotte Patterson is a quantitative spatial ecologist and PhD candidate at Queensland University of Technology, specialising in conservation science and ecological modelling. Her current research explores how terrestrial ecosystems in Antarctica may respond to climate change, using spatial modelling approaches to address challenges in data-poor environments. With a strong foundation in fieldwork, statistical modelling, and conservation management, Charlotte has also contributed to invasive species research and large-scale restoration and predator control programs in Aotearoa New Zealand. She is passionate about applying ecological insight and clear communication to support effective conservation outcomes.\n\n\n\nScott Forrest\n\nScott Forrest is a PhD researcher in animal movement ecology at Queensland University of Technology, with a background in both engineering and ecology. His research focuses on predicting the seasonal distribution of Asian water buffalo and feral cattle across Northern Australia’s monsoonal ecosystems to support effective management strategies. Scott is particularly interested in data-driven, stochastic simulations of individual animal movements to inform population-level inference and prediction.\n\n\n\nBrooke Williams\n\nBrooke Williams is a lecturer in environmental management at the University of Newcastle and an applied ecologist and conservation scientist. Her work focuses on designing decision support frameworks and developing datasets that help guide conservation and forest restoration actions while accounting for human needs. By integrating considerations of ecosystem services and economic factors, her tools empower policymakers and land managers to make informed decisions in complex, real-world scenarios.\n\n\n\nCaite Kuemple\n\nCaitie Kuempel is a conservation scientist and Lecturer in ecosystem modelling at Griffith University, working at the interface of science and policy. Her research focuses on integrated land-sea planning, sustainable food production, and conservation strategies that balance human needs with environmental protection, especially in marine ecosystems. She has previously worked with the University of Queensland and WWF on climate-resilient reef management, and held a postdoctoral position at NCEAS UC Santa Barbara examining the environmental impacts of global food systems. Caitie holds advanced degrees in marine biology, environmental science, and French.\n\n\n\nEmma Hain\n\nEmma Hain is a GeoSpatial Product Manager and Cartographer with over 30 years of experience spanning geospatial systems, engineering, environment, heritage, sports management, and military sectors. At North Road, she supports the global QGIS community and delivers tailored open-source geospatial solutions to a wide range of organizations. Emma also coordinates the QGIS AU community and contributes to FOSS4G Oceania, promoting collaboration across the sector. Known for her creative, ethical approach and commitment to inclusivity, she blends a deep appreciation for art with technical expertise to solve complex spatial challenges."
  },
  {
    "objectID": "about.html#about-the-organisers-and-supporters",
    "href": "about.html#about-the-organisers-and-supporters",
    "title": "About",
    "section": "About the organisers and supporters",
    "text": "About the organisers and supporters\nThis workshop was organised by Geospatial Share, a grassroots group of spatial enthusiasts whose mission is to build a supportive and inclusive community where students, researchers, and professionals can grow their geospatial skills together. See https://brisbane-geocommunity.netlify.app/ for more.\nThis workshop was made possible by generous contributions by members of the following organisations."
  },
  {
    "objectID": "Session 5/docs/get-ready.html",
    "href": "Session 5/docs/get-ready.html",
    "title": "Get Ready",
    "section": "",
    "text": "Download QGIS 3.40.7 (current Long Term Release) using the OSGeo4W installer\n\n\n📁 Download ZIP: Course materials\n\n\n\nPrior to the conference, you can undertake the freely available Introduction to QGIS from Spatial Thoughts.\nWe will be using the following facets of QGIS, so familiarise yourself with them:\n- Load layers\n- Navigating around the map\n- Status bar information\n- Panels: Layers, Browser, Layer Styling, Identify Results, Processsing\n- Working with project files\n- Attributes toolbar\n- Print layout\n- Atlas",
    "crumbs": [
      "Session 5",
      "Get Ready"
    ]
  },
  {
    "objectID": "Session 5/docs/get-ready.html#download-data",
    "href": "Session 5/docs/get-ready.html#download-data",
    "title": "Get Ready",
    "section": "",
    "text": "📁 Download ZIP: Course materials",
    "crumbs": [
      "Session 5",
      "Get Ready"
    ]
  },
  {
    "objectID": "Session 5/docs/get-ready.html#for-those-new-to-qgis",
    "href": "Session 5/docs/get-ready.html#for-those-new-to-qgis",
    "title": "Get Ready",
    "section": "",
    "text": "Prior to the conference, you can undertake the freely available Introduction to QGIS from Spatial Thoughts.\nWe will be using the following facets of QGIS, so familiarise yourself with them:\n- Load layers\n- Navigating around the map\n- Status bar information\n- Panels: Layers, Browser, Layer Styling, Identify Results, Processsing\n- Working with project files\n- Attributes toolbar\n- Print layout\n- Atlas",
    "crumbs": [
      "Session 5",
      "Get Ready"
    ]
  },
  {
    "objectID": "Session 5/docs/get-ready.html#create-a-project-file-structure",
    "href": "Session 5/docs/get-ready.html#create-a-project-file-structure",
    "title": "Get Ready",
    "section": "Create a project file structure",
    "text": "Create a project file structure\nCreate this somewhere logical:",
    "crumbs": [
      "Session 5",
      "Get Ready"
    ]
  },
  {
    "objectID": "Session 5/docs/get-ready.html#open-qgis",
    "href": "Session 5/docs/get-ready.html#open-qgis",
    "title": "Get Ready",
    "section": "Open QGIS",
    "text": "Open QGIS\nSave the project file to Products and name it ICCB_Koala.qgz",
    "crumbs": [
      "Session 5",
      "Get Ready"
    ]
  },
  {
    "objectID": "Session 5/docs/get-ready.html#install-data-services",
    "href": "Session 5/docs/get-ready.html#install-data-services",
    "title": "Get Ready",
    "section": "Install Data Services",
    "text": "Install Data Services\nLoad the following XYZ Tiles:\nQLD Imagery\nhttps://spatial-img.information.qld.gov.au/arcgis/rest/services/Basemaps/LatestStateProgram_AllUsers/ImageServer/tile/%7Bz%7D/%7By%7D/%7Bx%7D\nLoad the following ArcGIS REST Server:\nQLD\nhttps://spatial-gis.information.qld.gov.au/arcgis/rest/services\n\nHow to load a connection\nThis works for both the XYZ Tile and the ArcGIS REST Server.\n1. In the Browser panel, right mouse click and select New Connection\n\n2. Give the Connection a name\n3. Enter in links from the website into the URL\n4. Click OK",
    "crumbs": [
      "Session 5",
      "Get Ready"
    ]
  },
  {
    "objectID": "Session 5/docs/map-brief.html",
    "href": "Session 5/docs/map-brief.html",
    "title": "Map Brief",
    "section": "",
    "text": "Create a poster showing:\n1. Title: “Open Source Geospatial Tools for Conservation under Climate Change - a Koala Case Study” or another one?\n2. Description\n3. Area of Interest (AOI) - South EAst Queensland (SEQ)\n4. Picture of a Koala\n5. Koala distribution impacts\n6. Climate change in SEQ - past, present and future\n7. Where efforts should be focused\n\n\n\n\n Back to top",
    "crumbs": [
      "Session 5",
      "Map Brief"
    ]
  },
  {
    "objectID": "Session 5/docs/resources.html",
    "href": "Session 5/docs/resources.html",
    "title": "Resources",
    "section": "",
    "text": "Style resources\n\nSpatial Thoughts\n\nQgis expressions\n\nUsing R as a GIS by Nick Bearman\n\nQGIS Map design - 2nd Edition by Anita Graser and Gretchen N. Peterson\n\nTo learn more about Open Source Geospatial How to Succeed as a GIS Rebel, A Journey to Open Source GIS by Mark Seibel\n\nDiscover QGIS 3.x - Second Edition, A Workbook for Classroom or Independent Study by Kurt Menke\n\nhttps://docs.qgis.org/3.40/en/docs/training_manual/forestry/forest_maps.html\n\n\n\n\n Back to top",
    "crumbs": [
      "Session 5",
      "Resources"
    ]
  },
  {
    "objectID": "Session 2/session_2_code.html",
    "href": "Session 2/session_2_code.html",
    "title": "Climate downscaling",
    "section": "",
    "text": "Code\n#install.packages(\"terra\")\n#install.packages(\"dplyr\")\n#install.packages(\"sf\")\n#install.packages(\"ggplot2\")\n#install.packages(\"dismo\")\n#install.packages(\"rasterVis\")\n#install.packages(\"reshape\")\n\n## Import packages\nlibrary(terra)\nlibrary(dplyr)\nlibrary(sf)\nlibrary(ggplot2)\nlibrary(dismo)\nlibrary(rasterVis)\nlibrary(reshape)\nlibrary(RColorBrewer)",
    "crumbs": [
      "Session 2",
      "Climate downscaling"
    ]
  },
  {
    "objectID": "Session 2/session_2_code.html#q-can-you-cut-the-historical-data-and-future-based-on-the-dates",
    "href": "Session 2/session_2_code.html#q-can-you-cut-the-historical-data-and-future-based-on-the-dates",
    "title": "Climate downscaling",
    "section": "Q: Can you cut the historical data and future based on the dates?",
    "text": "Q: Can you cut the historical data and future based on the dates?\n\n\nCode\n# Add your code here!\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n\n\n\n\nCode\nplot(tas_base)\n\n\n\n\n\n\n\n\n\nCode\nplot(tas_fut)\n\n\n\n\n\n\n\n\n\nChange in future temperature (future - base)\n\n\nCode\ntas_dif = tas_fut - tas_base\nplot(tas_dif)",
    "crumbs": [
      "Session 2",
      "Climate downscaling"
    ]
  },
  {
    "objectID": "Session 2/session_2_code.html#q.-can-you-make-this-plot-nicer-add-a-title-and-change-the-colours",
    "href": "Session 2/session_2_code.html#q.-can-you-make-this-plot-nicer-add-a-title-and-change-the-colours",
    "title": "Climate downscaling",
    "section": "Q. Can you make this plot nicer? Add a title and change the colours",
    "text": "Q. Can you make this plot nicer? Add a title and change the colours\nHint: You can set plot titles using ‘main’\nControl the colours using col = brewer.pal(11, ‘PaletteName’) (see https://colorbrewer2.org/ for colour options)\nYou can plot multiple figures in one plot using par (mfrow = c(nrows, ncols))\nAlso check the instructions from Session 1!\n\n\nCode\n# Add your code here!\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n\n\nExtracting out point data (timeseries)\n\n\nCode\ntas[50,50]                  # extracts data from the 50th lat and 50th lon position\n\n\n\n  \n\n\n\nCode\ncells &lt;- cellFromRowCol(tas[[1]], 50, 50)\nxyFromCell(tas,cells)\n\n\n         x     y\n[1,] 142.4 -13.9\n\n\nCode\ndf = melt(tas[50,50])\n\n\nUsing  as id variables\n\n\nBasic plot\n\n\nCode\nplot(df, xlab = \"Year\", ylab = \"Temperature (degC)\")\n\n\n\n\n\n\n\n\n\nCalculating spatial average of all data\n\n\nCode\nspat_ave = global(tas, fun=mean, na.rm=TRUE)\nspat_ave$date = dates\n\n\nggplot\n\n\nCode\nggplot(data = spat_ave, aes(y=mean, x=date))+ \n  ylab('Temperature (degC)') + xlab('Year') +\n  geom_point() +\n  geom_line() +\n  geom_smooth(method = \"lm\") +\n  theme_bw()\n\n\n`geom_smooth()` using formula = 'y ~ x'",
    "crumbs": [
      "Session 2",
      "Climate downscaling"
    ]
  },
  {
    "objectID": "Session 2/session_2_code.html#q.-can-you-add-another-model-to-this-plot-and-compare-the-two",
    "href": "Session 2/session_2_code.html#q.-can-you-add-another-model-to-this-plot-and-compare-the-two",
    "title": "Climate downscaling",
    "section": "Q. Can you add another model to this plot and compare the two?",
    "text": "Q. Can you add another model to this plot and compare the two?\nHint: You’ll need to prepare a dataframe with data for all models in it. One of the columns will need to be the values, and the other the model name.\n\n\nCode\n# Add your code here!\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#",
    "crumbs": [
      "Session 2",
      "Climate downscaling"
    ]
  },
  {
    "objectID": "Session 2/session_2_code.html#working-with-multiple-models",
    "href": "Session 2/session_2_code.html#working-with-multiple-models",
    "title": "Climate downscaling",
    "section": "Working with multiple Models",
    "text": "Working with multiple Models\n\n\nCode\npr_files &lt;- list.files(path = \"data/annual/\", pattern = \"pr\", full.names = TRUE)            # Lists all files, including all scenarios\npr_files &lt;- list.files(path = \"data/annual/\", pattern = \"pr.*ssp370\", full.names = TRUE)    # Lists files with only ssp370\n\n\n\n\nCode\npr_data = rast(pr_files)*365  # daily mean to annual total. CCAM has a 365 day calendar.\npr_data\n\n\nclass       : SpatRaster \ndimensions  : 205, 176, 360  (nrow, ncol, nlyr)\nresolution  : 0.1, 0.1  (x, y)\nextent      : 137.45, 155.05, -29.45, -8.95  (xmin, xmax, ymin, ymax)\ncoord. ref. : lon/lat WGS 84 (CRS84) (OGC:CRS84) \nsource(s)   : memory\nvarname     : pr_annual (Seasonal average of Precipitation (Annual)) \nnames       : pr_annual_1, pr_annual_2, pr_annual_3, pr_annual_4, pr_annual_5, pr_annual_6, ... \nmin values  :      52.196,    48.72456,    85.55378,    54.58001,    150.5908,    117.2378, ... \nmax values  :    6151.675,  7233.45194,  5595.35947,  6152.59279,   5482.5640,   5449.5375, ... \ntime (days) : 1981-01-01 to 2100-01-01 (2 steps) \n\n\nRepeating the year names multiple times to correspond with multiple models\n\n\nCode\nyears = seq(1981,2100)\nyears_rep = rep(years, times =3)\nnames(pr_data) = years_rep\n\n\nCalculating the model average\n\n\nCode\npr_modavg = tapp(pr_data, years, fun = mean)\n\n# Calculating climatology for baseline (1981-2010)\npr_base = mean(pr_modavg[[1:30]])  # Converting from daily mean to annual mean\n\n# Calculating climatology for future (2071-2100)\npr_fut = mean(pr_modavg[[91:120]])  # Converting from daily mean to annual mean",
    "crumbs": [
      "Session 2",
      "Climate downscaling"
    ]
  },
  {
    "objectID": "Session 2/session_2_code.html#q-can-you-select-the-data-based-on-the-years-instead",
    "href": "Session 2/session_2_code.html#q-can-you-select-the-data-based-on-the-years-instead",
    "title": "Climate downscaling",
    "section": "Q: Can you select the data based on the years instead?",
    "text": "Q: Can you select the data based on the years instead?\n\n\nCode\n# Add your code here!\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#\n\n\nPlot historic and future rainfall\n\n\nCode\nlevelplot(pr_base)\n\n\n\n\n\n\n\n\n\nCode\nlevelplot(pr_fut)\n\n\n\n\n\n\n\n\n\nCutting data to Queensland\n\n\nCode\nqld_shp = vect('data/shp/QLD_State_Mask.shp')\npr_dif = pr_fut - pr_base\npr_dif_masked &lt;- crop(pr_dif, qld_shp, mask = TRUE)\nlevelplot(pr_dif_masked, margin = FALSE)\n\n\n\n\n\n\n\n\n\nPlotting the percent change\n\n\nCode\npr_pdif = (pr_fut - pr_base ) / pr_base *100  #Percent difference\npr_pdif_masked &lt;- crop(pr_pdif, qld_shp, mask = TRUE)\nlevelplot(pr_pdif_masked, margin = FALSE)\n\n\n\n\n\n\n\n\n\nSpecifying plotting bins and colours\n\n\nCode\nmy.at &lt;- seq(-20, 20, length.out = 10)\nmy.at = c(-Inf, my.at, Inf)\nlevelplot(pr_pdif_masked, margin = FALSE, at = my.at, cuts=11, pretty=T,\n                col.regions=((brewer.pal(11,\"RdBu\"))))",
    "crumbs": [
      "Session 2",
      "Climate downscaling"
    ]
  },
  {
    "objectID": "Session 2/session_2_code.html#q.-can-you-modify-this-plot-to-show-more-infomation-can-you-add-a-title-and-change-the-colours",
    "href": "Session 2/session_2_code.html#q.-can-you-modify-this-plot-to-show-more-infomation-can-you-add-a-title-and-change-the-colours",
    "title": "Climate downscaling",
    "section": "Q. Can you modify this plot to show more infomation? Can you add a title and change the colours?",
    "text": "Q. Can you modify this plot to show more infomation? Can you add a title and change the colours?\nWould showing multiple models on this plot help?\n\n\nCode\n# Add your code here!\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#",
    "crumbs": [
      "Session 2",
      "Climate downscaling"
    ]
  },
  {
    "objectID": "Session 2/session_2_code.html#q.-can-we-compare-the-results-from-ssp370-to-another-scenario",
    "href": "Session 2/session_2_code.html#q.-can-we-compare-the-results-from-ssp370-to-another-scenario",
    "title": "Climate downscaling",
    "section": "Q. Can we compare the results from SSP370 to another Scenario?",
    "text": "Q. Can we compare the results from SSP370 to another Scenario?\n\n\nCode\n# Add your code here!\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#",
    "crumbs": [
      "Session 2",
      "Climate downscaling"
    ]
  },
  {
    "objectID": "Session 2/session_2_code.html#q-can-you-plot-the-bioclimatic-indices-in-the-past-and-present-and-compare-the-changes",
    "href": "Session 2/session_2_code.html#q-can-you-plot-the-bioclimatic-indices-in-the-past-and-present-and-compare-the-changes",
    "title": "Climate downscaling",
    "section": "Q: Can you plot the bioclimatic indices in the past and present and compare the changes?",
    "text": "Q: Can you plot the bioclimatic indices in the past and present and compare the changes?\n\n\nCode\n# Add your code here!\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#",
    "crumbs": [
      "Session 2",
      "Climate downscaling"
    ]
  },
  {
    "objectID": "Session 2/session_2_code.html#q-what-does-the-bioclimatic-indicators-look-like-for-a-lower-emissions-scenario",
    "href": "Session 2/session_2_code.html#q-what-does-the-bioclimatic-indicators-look-like-for-a-lower-emissions-scenario",
    "title": "Climate downscaling",
    "section": "Q: What does the bioclimatic indicators look like for a lower emissions scenario?",
    "text": "Q: What does the bioclimatic indicators look like for a lower emissions scenario?\n\n\nCode\n# Add your code here!\n#\n#\n#\n#\n#\n#\n#\n#\n#\n#",
    "crumbs": [
      "Session 2",
      "Climate downscaling"
    ]
  },
  {
    "objectID": "Session 3/Data/Environmental_variables/QLD_State_Mask.html",
    "href": "Session 3/Data/Environmental_variables/QLD_State_Mask.html",
    "title": "ICCB - Open Geospatial Tools",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;  Mainland  ENG dataset\n\nMainlands - Queensland\n\nThis dataset depicts the land extent of continental Queensland. The boundary of the area shown coincides with theFrameworkBoundaries dataset.\nUSER NOTICE This feature class will be no longer updated after April 26th, 2024. New feature classes have been created to replace it. This feature class will be removed after June 1st without notification. To provide digital data depicting the land extent of continental Queensland for use in land administration, topographic mapping and in the production of navigational and web based mapping applications.  Queensland coastline mean high water state border mainland BOUNDARIES coastline mean high water state border mainland   BOUNDARIES    \n\n\n  &lt;city&gt;&lt;/city&gt;\n  &lt;administrativearea&gt;&lt;/administrativearea&gt;\n  &lt;postalcode&gt;&lt;/postalcode&gt;\n  &lt;country&gt;&lt;/country&gt;\n&lt;/contactAddress&gt;\n&lt;name&gt;Resources, Georesources, SI, SD, SDM, Senior Spatial Information Officer&lt;/name&gt;\n&lt;organization&gt;Department of Resources&lt;/organization&gt;\n&lt;position&gt;Senior Spatial Information Officer, Spatial Data Management, Spatial Data, Spatial Information&lt;/position&gt;\n&lt;voice&gt;(07) 3330 4738&lt;/voice&gt;\n&lt;fax&gt;&lt;/fax&gt;\n&lt;email&gt;SIIMTopoDataManagement@resources.qld.gov.au&lt;/email&gt;\n&lt;role&gt;Point of contact&lt;/role&gt;\n    This dataset is GDA2020 compatible. The source data, and therefore the captured features, are georeferenced as GDA94 (horizontal only). The horizontal accuracy of the geo-referencing and/or data collection method for this example is greater than the datum offset between GDA94 and GDA2020 (1.8 meters). The resulting dataset has been nominated as a low-accuracy GDA2020 dataset. As this data has not been directly captured in GDA2020, nor transformed to GDA2020, the resulting data is ‘GDA2020 Compatible’ not ‘GDA2020 Compliant’. This dataset was derived from and is coincident with the FrameworkBoundaries_Queensland dataset. Within the FrameworkBoundaries_Queensland dataset., the coastline was digitized from the most current imagery by defining mean high water from sand coloration and debris lines. Where available, the highest astronomical tide line generated from LiDAR was used to help define the line. Were the line is obscured by vegetation, in particular mangroves; the seaward edge of the vegetation is adopted. The coastline feature does not cross the entrances to large inland waterbodies. In these instances, a feature type Junction is used to seamlessly connect the coastline. The state border was captured and coincides with the position as shown by the Queensland Digital Cadastral Database, Feature Types: Mainland - The area of continental Queensland. Data source: Queensland Digital Cadastral Database  Features have been captured or updated from the best available imagery or data sources, with an attribute within the data describing the source and reliability. Unrestricted to all levels of government and community. Data is available to all government agencies, community groups and individuals. Dataset is available through physical supply and may be made available via web delivery tools, for example, through DNRME’s internet sites. The State of Queensland (Department of Resources) � State of Queensland (Department of Resources) 2023 This material is licensed under a Creative Commons - Attribution 4.0 International licence. ? The Department of Resources requests attribution in the following manner: � State of Queensland (Department of Resources) 2021. Updated data available at http://qldspatial.information.qld.gov.au/catalogue/ .    GEOGCRS[“GDA94”,DATUM[“Geocentric Datum of Australia 1994”,ELLIPSOID[“GRS 1980”,6378137,298.257222101,LENGTHUNIT[“metre”,1]]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“Australia including Lord Howe Island, Macquarie Island, Ashmore and Cartier Islands, Christmas Island, Cocos (Keeling) Islands, Norfolk Island. All onshore and offshore.”],BBOX[-60.55,93.41,-8.47,173.34]],ID[“EPSG”,4283]] +proj=longlat +ellps=GRS80 +no_defs 3415 4283 EPSG:4283 GDA94 longlat EPSG:7019 true       2018-05-21T14:00:00Z           \n\n\n\n Back to top"
  },
  {
    "objectID": "Session 3/session_3_home.html",
    "href": "Session 3/session_3_home.html",
    "title": "Session 3",
    "section": "",
    "text": "In this session we are fitting species distribution models to the data of koalas (Phascolarctos cinereus) in the South-East Queensland (SEQ) region under current climatic conditions, which we will predict into future climatic conditions.",
    "crumbs": [
      "Session 3"
    ]
  },
  {
    "objectID": "Session 3/session_3_home.html#slides",
    "href": "Session 3/session_3_home.html#slides",
    "title": "Session 3",
    "section": "Slides",
    "text": "Slides\nDownload a PDF of the slides",
    "crumbs": [
      "Session 3"
    ]
  },
  {
    "objectID": "Session 4/session_4_home.html",
    "href": "Session 4/session_4_home.html",
    "title": "Session 4",
    "section": "",
    "text": "Step-by-step walkthrough can be found here https://docs.google.com/document/d/15le0kx3n-C6hevoJ7zWs-kxWQd1YlW6joY3pRtJU4Ds/edit?tab=t.0#heading=h.9tqqmwld3mgr.\nDownload a PDF of the walkthrough",
    "crumbs": [
      "Session 4"
    ]
  },
  {
    "objectID": "Session 4/session_4_home.html#resources",
    "href": "Session 4/session_4_home.html#resources",
    "title": "Session 4",
    "section": "",
    "text": "Step-by-step walkthrough can be found here https://docs.google.com/document/d/15le0kx3n-C6hevoJ7zWs-kxWQd1YlW6joY3pRtJU4Ds/edit?tab=t.0#heading=h.9tqqmwld3mgr.\nDownload a PDF of the walkthrough",
    "crumbs": [
      "Session 4"
    ]
  },
  {
    "objectID": "Session 4/session_4_home.html#optimiser-installation",
    "href": "Session 4/session_4_home.html#optimiser-installation",
    "title": "Session 4",
    "section": "Optimiser installation",
    "text": "Optimiser installation\nThe prioritizr package requires that you download and install an optimiser - a commonly used one is Gurobi. You can obtain a free academic license for Gurobi here: https://www.gurobi.com/features/academic-named-user-license/.\nHere is a guide to install Gurobi for R: https://docs.gurobi.com/projects/optimizer/en/current/reference/r/setup.html.\nAlternatively, if you cannot obtain an academic licence there are other solvers available https://prioritizr.net/reference/solvers.html. We recommend installing the CBC solver: https://github.com/dirkschumacher/rcbc.\nIf you have issues with installing a solver, please let us know.",
    "crumbs": [
      "Session 4"
    ]
  },
  {
    "objectID": "workshop_overview.html",
    "href": "workshop_overview.html",
    "title": "Open Source Geospatial Tools for Conservation under Climate Change",
    "section": "",
    "text": "This repo contains the materials for the ICCB workshop titled “Open Source Geospatial Tools for Conservation under Climate Change”."
  },
  {
    "objectID": "workshop_overview.html#aim-of-the-workshop",
    "href": "workshop_overview.html#aim-of-the-workshop",
    "title": "Open Source Geospatial Tools for Conservation under Climate Change",
    "section": "Aim of the workshop",
    "text": "Aim of the workshop\nOver two days, this training workshop aims to equip participants with the core skills of conservation planning and management with open source geospatial tools - from the basics of R spatial, to climate modelling, species distribution modelling, spatial conservation planning, all the way to making beautiful maps with QGIS."
  },
  {
    "objectID": "workshop_overview.html#key-case-study-question",
    "href": "workshop_overview.html#key-case-study-question",
    "title": "Open Source Geospatial Tools for Conservation under Climate Change",
    "section": "Key case study question",
    "text": "Key case study question\nKoalas (Phascolarctos cinereus) in South East Queensland (SEQ) inhabit fragmented eucalypt woodlands and rely heavily on Eucalyptus species for food and shelter. The population is already under pressure from habitat loss, disease (notably chlamydia), and vehicle collisions. Climate change poses additional threats through increased frequency of heatwaves, droughts, and bushfires, which reduce food quality, water availability, and suitable habitat. With this in mind, this workshop will seek to address the question: “How can we best conserve the koalas of south east Queensland under climate change?”."
  },
  {
    "objectID": "workshop_overview.html#schedule",
    "href": "workshop_overview.html#schedule",
    "title": "Open Source Geospatial Tools for Conservation under Climate Change",
    "section": "Schedule",
    "text": "Schedule\nThe content will be delivered on the weekend prior to ICCB - the 14th and 15th of June 2025.\n\n\n\nSession\nLed by\nSupported by\nStart time\nEnd time\n\n\nIntroduction\nMitch Rudge and Catherine Kim\n\n9:00\n9:30\n\n\nGetting started with geospatial tools in R\nJason Flower (University of California, Santa Barbara)\nMitch Rudge and Catherine Kim\nSaturday 9:30\nSaturday 11:00\n\n\nMorning tea\n\n\n11:00\n11:15\n\n\nWorking with climate projection models part 1\nRalph Trancoso, Sarah Chapman, Rohan Eccles (Queensland Future Climate Science Program)\nMitch Rudge and Catherine Kim\nSaturday 11:15\nSaturday 12:30\n\n\nLunch day 1\n\n\nSaturday 12:30\nSaturday 13:30\n\n\nWorking with climate projection models part 2\n\n\n13:30\n14:00\n\n\nAfternoon tea\n\n\n14:00\n14:15\n\n\nModelling the future distribution of koalas\nScott Forrest and Charlotte Patterson (QUT)\nMitch Rudge and Catherine Kim\nSaturday 14:15\nSaturday 16:30\n\n\nKoala dinner\n\n\nTBC\nTBC\n\n\nPutting it all together with conservation spatial planning\nCaitie Kuempel (Griffith University) and Brooke Williams (The University of Newcastle)\nMitch Rudge and Catherine Kim\nSunday 10:00\nSunday 11:30\n\n\nLunch Day 2\n\n\nSunday 11:30\nSunday 12:30\n\n\nCreating beautiful maps with QGIS\nEmma Hain (North Road and QGIS Australia)\nMitch Rudge and Catherine Kim\nSunday 12:30\nSunday 14:30"
  },
  {
    "objectID": "workshop_overview.html#before-the-workshop",
    "href": "workshop_overview.html#before-the-workshop",
    "title": "Open Source Geospatial Tools for Conservation under Climate Change",
    "section": "Before the workshop",
    "text": "Before the workshop\nPlease download and install R, R studio, and QGIS before the workshop. If you are not able to do this, that’s fine but please arrive early so we can get you started."
  },
  {
    "objectID": "workshop_overview.html#location",
    "href": "workshop_overview.html#location",
    "title": "Open Source Geospatial Tools for Conservation under Climate Change",
    "section": "Location",
    "text": "Location\nThe University of Queensland St Lucia campus, Forgan Smith Building 01-E107."
  },
  {
    "objectID": "workshop_overview.html#about-the-organisers-and-supporters",
    "href": "workshop_overview.html#about-the-organisers-and-supporters",
    "title": "Open Source Geospatial Tools for Conservation under Climate Change",
    "section": "About the organisers and supporters",
    "text": "About the organisers and supporters\n\n\n\n\n\nThis workshop was organised by Geospatial Share, a grassroots group of spatial enthusiasts whose mission is to build a supportive and inclusive community where students, researchers, and professionals can grow their geospatial skills together. See https://brisbane-geocommunity.netlify.app/ for more.\nThis workshop was made possible by generous contributions by members of the following organisations."
  },
  {
    "objectID": "Session 4/session_4_code.html",
    "href": "Session 4/session_4_code.html",
    "title": "Conservation planning",
    "section": "",
    "text": "The prioritizr package requires that you download and install an optimiser - a commonly used one is Gurobi. You can obtain a free academic license for Gurobi here: https://www.gurobi.com/features/academic-named-user-license/.\nHere is a guide to install Gurobi for R: https://docs.gurobi.com/projects/optimizer/en/current/reference/r/setup.html.\nAlternatively, if you cannot obtain an academic licence there are other solvers available https://prioritizr.net/reference/solvers.html. We recommend installing the CBC solver: https://github.com/dirkschumacher/rcbc.\nIf you have issues with installing a solver, please let us know.",
    "crumbs": [
      "Session 4",
      "Conservation planning"
    ]
  },
  {
    "objectID": "Session 4/session_4_code.html#optimiser-installation",
    "href": "Session 4/session_4_code.html#optimiser-installation",
    "title": "Conservation planning",
    "section": "",
    "text": "The prioritizr package requires that you download and install an optimiser - a commonly used one is Gurobi. You can obtain a free academic license for Gurobi here: https://www.gurobi.com/features/academic-named-user-license/.\nHere is a guide to install Gurobi for R: https://docs.gurobi.com/projects/optimizer/en/current/reference/r/setup.html.\nAlternatively, if you cannot obtain an academic licence there are other solvers available https://prioritizr.net/reference/solvers.html. We recommend installing the CBC solver: https://github.com/dirkschumacher/rcbc.\nIf you have issues with installing a solver, please let us know.",
    "crumbs": [
      "Session 4",
      "Conservation planning"
    ]
  },
  {
    "objectID": "Session 4/session_4_code.html#install-packages",
    "href": "Session 4/session_4_code.html#install-packages",
    "title": "Conservation planning",
    "section": "Install packages",
    "text": "Install packages\n\n\nCode\n# Load required packages\nlibrary(terra)\nlibrary(viridisLite)\nlibrary(prioritizr)\nlibrary(raster)",
    "crumbs": [
      "Session 4",
      "Conservation planning"
    ]
  },
  {
    "objectID": "Session 4/session_4_code.html#load-spatial-data",
    "href": "Session 4/session_4_code.html#load-spatial-data",
    "title": "Conservation planning",
    "section": "Load Spatial Data",
    "text": "Load Spatial Data\n\n\nCode\n# Load the Planning unit\nPU &lt;- terra::rast(\"data/otherdata/PlanningUnits.tif\")\nplot(PU, col = viridisLite::mako(n = 1))\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Get the file names of the testing data\nspp.list &lt;- list.files(path = \"data/SpeciesDistributions/\", full.names = TRUE, recursive = TRUE, pattern = \".tif$\")\n\n\n\nLoad current species distribution\n\n\nCode\n# Load all files and rename them\nspp &lt;- rast(spp.list[grep(\"current\", spp.list)])\n# Get just the filenames (without full paths and extensions)\nnew_names &lt;- tools::file_path_sans_ext(basename(spp.list[grep(\"current\", spp.list)]))\n# Load and assign names\nspp &lt;- rast(spp.list[grep(\"current\", spp.list)])\nnames(spp) &lt;- new_names\n# Plot species distributions\nplot(spp, axes = F,col = viridisLite::mako(n = 100, direction = -1), main = c(names(spp)))\n\n\n\n\n\n\n\n\n\n\n\nLoad future species distribution\n\n\nCode\n# Do the same for \"future\" rasters\nspp &lt;- rast(spp.list[grep(\"future\", spp.list)])\n# Get just the filenames (without full paths and extensions)\nnew_names &lt;- tools::file_path_sans_ext(basename(spp.list[grep(\"future\", spp.list)]))\n# Load and assign names\nspp &lt;- rast(spp.list[grep(\"future\", spp.list)])\nnames(spp) &lt;- new_names\n# Plot first four species distributions\nplot(spp, axes = F,col = viridisLite::mako(n = 100, direction = -1), main = c(names(spp)))\n\n\n\n\n\n\n\n\n\n\n\nLoad protected areas, urban centers, and cost layer\n\n\nCode\nPA &lt;- rast(\"data/otherdata/protected_areas.tif\")\nplot(PA, axes = FALSE, col = viridisLite::mako(n = 100, direction = -1), main = \"Protected Areas (I & II)\")\n\n\n\n\n\n\n\n\n\nCode\nurban &lt;- rast(\"data/otherdata/urban_centers.tif\")\nplot(urban, axes = FALSE, col = viridisLite::mako(n = 100, direction = -1), main = \"Urban Centers\")\n\n\n\n\n\n\n\n\n\nCode\nhfp &lt;- rast(\"data/otherdata/cost_hfp2013.tif\")\nplot(hfp, axes = FALSE, col = viridisLite::mako(n = 10, direction = -1), main = \"Global human footprint\")",
    "crumbs": [
      "Session 4",
      "Conservation planning"
    ]
  },
  {
    "objectID": "Session 4/session_4_code.html#define-budget",
    "href": "Session 4/session_4_code.html#define-budget",
    "title": "Conservation planning",
    "section": "Define Budget",
    "text": "Define Budget\n\n\nCode\nbudget.area &lt;- round(0.3 * length(cells(PU)))",
    "crumbs": [
      "Session 4",
      "Conservation planning"
    ]
  },
  {
    "objectID": "Session 4/session_4_code.html#scenario-1-basic-shortfall-objective",
    "href": "Session 4/session_4_code.html#scenario-1-basic-shortfall-objective",
    "title": "Conservation planning",
    "section": "Scenario 1: Basic Shortfall Objective",
    "text": "Scenario 1: Basic Shortfall Objective\n\n\nCode\np &lt;- problem(PU, spp) %&gt;% \n  add_min_shortfall_objective(budget = budget.area) %&gt;%\n  add_relative_targets(targets = 1) %&gt;% \n  add_default_solver() %&gt;%\n  add_proportion_decisions()\n\ns1 &lt;- solve(p)\nplot(s1, main = \"Scenario 1\")",
    "crumbs": [
      "Session 4",
      "Conservation planning"
    ]
  },
  {
    "objectID": "Session 4/session_4_code.html#scenario-2-lock-out-urban-areas",
    "href": "Session 4/session_4_code.html#scenario-2-lock-out-urban-areas",
    "title": "Conservation planning",
    "section": "Scenario 2: Lock Out Urban Areas",
    "text": "Scenario 2: Lock Out Urban Areas\n\n\nCode\np &lt;- problem(PU, spp) %&gt;% \n  add_min_shortfall_objective(budget = budget.area) %&gt;%\n  add_relative_targets(targets = 1) %&gt;%\n  add_proportion_decisions() %&gt;%\n  add_locked_out_constraints(urban) %&gt;%\n  add_default_solver()\n\ns2 &lt;- solve(p)\nplot(s2, main = \"Scenario 2 - lock out\")",
    "crumbs": [
      "Session 4",
      "Conservation planning"
    ]
  },
  {
    "objectID": "Session 4/session_4_code.html#scenario-3-lock-in-protected-areas",
    "href": "Session 4/session_4_code.html#scenario-3-lock-in-protected-areas",
    "title": "Conservation planning",
    "section": "Scenario 3: Lock In Protected Areas",
    "text": "Scenario 3: Lock In Protected Areas\n\n\nCode\np &lt;- problem(PU, spp) %&gt;% \n  add_min_shortfall_objective(budget = budget.area) %&gt;%\n  add_relative_targets(targets = 1) %&gt;%\n  add_proportion_decisions() %&gt;%\n  add_locked_in_constraints(PA) %&gt;%\n  add_locked_out_constraints(urban) %&gt;%\n  add_default_solver()\n\ns3 &lt;- solve(p)\nplot(s3, main = \"Scenario 3 - lock in\")",
    "crumbs": [
      "Session 4",
      "Conservation planning"
    ]
  },
  {
    "objectID": "Session 4/session_4_code.html#scenario-4-penalize-human-footprint",
    "href": "Session 4/session_4_code.html#scenario-4-penalize-human-footprint",
    "title": "Conservation planning",
    "section": "Scenario 4: Penalize Human Footprint",
    "text": "Scenario 4: Penalize Human Footprint\n\n\nCode\np &lt;- problem(PU, spp) %&gt;% \n  add_min_shortfall_objective(budget = budget.area) %&gt;%\n  add_relative_targets(targets = 1) %&gt;%\n  add_linear_penalties(penalty = 1, data = hfp) %&gt;%\n  add_proportion_decisions() %&gt;%\n  add_locked_in_constraints(PA) %&gt;%\n  add_locked_out_constraints(urban) %&gt;%\n  add_default_solver()\n\ns4 &lt;- solve(p)\nplot(s4, main = \"Scenario 4 - apply penalty\")\n\n\n\n\n\n\n\n\n\nCode\n# Export to GeoTIFF\nwriteRaster(s4, \"scenario_4.tif\", overwrite = TRUE)",
    "crumbs": [
      "Session 4",
      "Conservation planning"
    ]
  },
  {
    "objectID": "Session 4/session_4_code.html#plot-all-scenarios-side-by-side",
    "href": "Session 4/session_4_code.html#plot-all-scenarios-side-by-side",
    "title": "Conservation planning",
    "section": "Plot All Scenarios Side by Side",
    "text": "Plot All Scenarios Side by Side\n\n\nCode\n# Set plotting area to 1 row, 4 columns\npar(mfrow = c(2, 2), mar = c(3, 3, 3, 1))\n\nplot(s1, main = \"Scenario 1\")\nplot(s2, main = \"Scenario 2 - lock out\")\nplot(s3, main = \"Scenario 3 - lock in\")\nplot(s4, main = \"Scenario 4 - apply penalty\")\n\n\n\n\n\n\n\n\n\nCode\n# Reset plotting layout to default (optional)\npar(mfrow = c(1, 1))",
    "crumbs": [
      "Session 4",
      "Conservation planning"
    ]
  },
  {
    "objectID": "Session 4/session_4_code.html#calculate-metrics",
    "href": "Session 4/session_4_code.html#calculate-metrics",
    "title": "Conservation planning",
    "section": "Calculate metrics",
    "text": "Calculate metrics\n\n\nCode\n#Scenario 1\nrpz_target_spp_s1 &lt;- eval_target_coverage_summary(p, s1) \nmean(rpz_target_spp_s1$relative_held)\n\n\n[1] 0.3863076\n\n\nCode\nmean(rpz_target_spp_s1$relative_shortfall) \n\n\n[1] 0.6136924\n\n\nCode\n#Scenario 2\nrpz_target_spp_s2 &lt;- eval_target_coverage_summary(p, s2) \nmean(rpz_target_spp_s2$relative_held)\n\n\n[1] 0.3801815\n\n\nCode\nmean(rpz_target_spp_s2$relative_shortfall) \n\n\n[1] 0.6198185\n\n\nCode\n#Scenario 3\nrpz_target_spp_s3 &lt;- eval_target_coverage_summary(p, s3) \nmean(rpz_target_spp_s3$relative_held)\n\n\n[1] 0.3350504\n\n\nCode\nmean(rpz_target_spp_s3$relative_shortfall)\n\n\n[1] 0.6649496\n\n\nCode\n#Scenario 4\nrpz_target_spp_s4 &lt;- eval_target_coverage_summary(p, s4) \nmean(rpz_target_spp_s4$relative_held)\n\n\n[1] 0.06277898\n\n\nCode\nmean(rpz_target_spp_s4$relative_shortfall)  \n\n\n[1] 0.937221",
    "crumbs": [
      "Session 4",
      "Conservation planning"
    ]
  },
  {
    "objectID": "Session 3/ICCB_Environmental_data.html",
    "href": "Session 3/ICCB_Environmental_data.html",
    "title": "ICCB Environmental data download",
    "section": "",
    "text": "Code\nlibrary(terra)\nlibrary(dplyr)\nlibrary(sf)\nlibrary(ggplot2)"
  },
  {
    "objectID": "Session 3/ICCB_Environmental_data.html#import-packages",
    "href": "Session 3/ICCB_Environmental_data.html#import-packages",
    "title": "ICCB Environmental data download",
    "section": "",
    "text": "Code\nlibrary(terra)\nlibrary(dplyr)\nlibrary(sf)\nlibrary(ggplot2)"
  },
  {
    "objectID": "Session 3/ICCB_Environmental_data.html#load-south-east-queensland-seq-boundary",
    "href": "Session 3/ICCB_Environmental_data.html#load-south-east-queensland-seq-boundary",
    "title": "ICCB Environmental data download",
    "section": "Load South East Queensland (SEQ) boundary",
    "text": "Load South East Queensland (SEQ) boundary\nWe start by defining our study area, which is the South East Queensland (SEQ) region. We will use the Local Government Areas (LGA) shapefile to define the extent of SEQ.\nhttps://qldspatial.information.qld.gov.au/catalogue/custom/detail.page?fid={3F3DBD69-647B-4833-B0A5-CC43D5E70699}\n\n\nCode\n# Load the study area shapefile\nLGA &lt;- st_read(\"Data/Environmental_variables/Local_Government_Areas.shp\")\n\n\nReading layer `Local_Government_Areas' from data source \n  `/Users/scottforrest/Library/CloudStorage/OneDrive-QueenslandUniversityofTechnology/PhD - Scott Forrest/GIT/ICCB_geospatial_tools_conservation/Session 3/Data/Environmental_variables/Local_Government_Areas.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 78 features and 8 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 137.9946 ymin: -29.17927 xmax: 153.5519 ymax: -9.087991\nGeodetic CRS:  GDA94\n\n\nCode\n# Check the coordinate reference system (CRS)\nst_crs(LGA)\n\n\nCoordinate Reference System:\n  User input: GDA94 \n  wkt:\nGEOGCRS[\"GDA94\",\n    DATUM[\"Geocentric Datum of Australia 1994\",\n        ELLIPSOID[\"GRS 1980\",6378137,298.257222101,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    USAGE[\n        SCOPE[\"Horizontal component of 3D system.\"],\n        AREA[\"Australia including Lord Howe Island, Macquarie Island, Ashmore and Cartier Islands, Christmas Island, Cocos (Keeling) Islands, Norfolk Island. All onshore and offshore.\"],\n        BBOX[-60.55,93.41,-8.47,173.34]],\n    ID[\"EPSG\",4283]]\n\n\nCode\n# Convert to WGS84\nLGA &lt;- LGA %&gt;% st_transform(7856)\n\n# Select local govt. areas for South East Queensland\nLGA_SEQ &lt;- LGA %&gt;% \n  filter(lga %in% c(\"Brisbane City\", \n                    \"Moreton Bay City\", \n                    \"Logan City\", \n                    \"Ipswich City\", \n                    \"Redland City\", \n                    \"Scenic Rim Regional\", \n                    \"Somerset Regional\", \n                    \"Lockyer Valley Regional\", \n                    \"Gold Coast City\", \n                    \"Sunshine Coast Regional\", \n                    \"Toowoomba Regional\", \n                    \"Noosa Shire\"))\n\nggplot() +\n  geom_sf(data = LGA, color = \"black\") +\n  geom_sf(data = LGA_SEQ, fill = \"purple3\", alpha = 0.5, color = \"black\", size = 0.2) +\n  theme_minimal() +\n  theme(legend.position = \"none\") +\n  labs(title = \"Local Government Areas Queensland (SEQ in purple)\")\n\n\n\n\n\n\n\n\n\nCode\nggplot() +\n  geom_sf(data = LGA_SEQ, fill = \"purple3\", alpha = 0.5, color = \"black\", size = 0.2) +\n  theme_minimal() +\n  theme(legend.position = \"none\") +\n  labs(title = \"Local Government Areas South East Queensland (SEQ)\")"
  },
  {
    "objectID": "Session 3/ICCB_Environmental_data.html#merge-into-a-single-polygon",
    "href": "Session 3/ICCB_Environmental_data.html#merge-into-a-single-polygon",
    "title": "ICCB Environmental data download",
    "section": "Merge into a single polygon",
    "text": "Merge into a single polygon\n\n\nCode\n# Merge the SEQ LGAs into one polygon\nSEQ_extent &lt;- st_union(LGA_SEQ)\n\nggplot() +\n  geom_sf(data = SEQ_extent, fill = \"purple3\", alpha = 0.5, color = \"black\", size = 0.2) +\n  theme_minimal() +\n  theme(legend.position = \"none\") +\n  ggtitle(\"South-East Queensland Spatial Extent\") + \n  theme_bw()"
  },
  {
    "objectID": "Session 3/ICCB_Environmental_data.html#save-seq-extent-for-other-scripts",
    "href": "Session 3/ICCB_Environmental_data.html#save-seq-extent-for-other-scripts",
    "title": "ICCB Environmental data download",
    "section": "Save SEQ extent for other scripts",
    "text": "Save SEQ extent for other scripts\n\n\nCode\n# Convert our SEQ extent to a SpatExtent object by converting to a SpatVector\nSEQ_extent.vect &lt;- terra::vect(SEQ_extent)\n\n# Write the SEQ extent to a shapefile\nwriteVector(SEQ_extent.vect, \"Data/Environmental_variables/SEQ_extent.shp\", overwrite = T)"
  },
  {
    "objectID": "Session 3/ICCB_Environmental_data.html#load-current-environmental-data",
    "href": "Session 3/ICCB_Environmental_data.html#load-current-environmental-data",
    "title": "ICCB Environmental data download",
    "section": "Load current environmental data",
    "text": "Load current environmental data\nLayers were made available to us by the EcoCommons team and were created by Toombs and Ma (2025):\nToombs, N., and Ma S., 2025, A High-Resolution Dataset of 19 Bioclimatic Indices over Australia, Climate Projections and Services – Queensland Treasury, Brisbane, Queensland. [https://longpaddock.qld.gov.au/qld-future-climate/data-info/tern/]\n\n\nCode\nfiles &lt;- list.files(\"Data/Environmental_variables/Current_climate_QLD\", \n             pattern = \".tif$\", \n             full.names = TRUE)\n\n# Load all bioclim rasters\ncurrent_bioclim &lt;- lapply(files, terra::rast) \n\n# Make into one raster stack\ncurrent_bioclim &lt;- rast(current_bioclim)\n\n# Plot the current bioclimatic variables\nplot(current_bioclim)\n\n\n\n\n\n\n\n\n\nCode\n# Examine the resolution\ncurrent_bioclim\n\n\nclass       : SpatRaster \ndimensions  : 681, 841, 19  (nrow, ncol, nlyr)\nresolution  : 0.05, 0.05  (x, y)\nextent      : 111.975, 154.025, -44.025, -9.975  (xmin, xmax, ymin, ymax)\ncoord. ref. : lon/lat WGS 84 (EPSG:4326) \nsources     : bioclim_01.tif  \n              bioclim_02.tif  \n              bioclim_03.tif  \n              ... and 16 more sources\nnames       : bioclim_01, bioclim_02, bioclim_03, bioclim_04, bioclim_05, bioclim_06, ... \n\n\nCode\n# Check the CRS\ncrs(current_bioclim)\n\n\n[1] \"GEOGCRS[\\\"WGS 84\\\",\\n    ENSEMBLE[\\\"World Geodetic System 1984 ensemble\\\",\\n        MEMBER[\\\"World Geodetic System 1984 (Transit)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G730)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G873)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G1150)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G1674)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G1762)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G2139)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G2296)\\\"],\\n        ELLIPSOID[\\\"WGS 84\\\",6378137,298.257223563,\\n            LENGTHUNIT[\\\"metre\\\",1]],\\n        ENSEMBLEACCURACY[2.0]],\\n    PRIMEM[\\\"Greenwich\\\",0,\\n        ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n    CS[ellipsoidal,2],\\n        AXIS[\\\"geodetic latitude (Lat)\\\",north,\\n            ORDER[1],\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n        AXIS[\\\"geodetic longitude (Lon)\\\",east,\\n            ORDER[2],\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n    USAGE[\\n        SCOPE[\\\"Horizontal component of 3D system.\\\"],\\n        AREA[\\\"World.\\\"],\\n        BBOX[-90,-180,90,180]],\\n    ID[\\\"EPSG\\\",4326]]\"\n\n\nCode\n# Update CRS to EPSG:7856 (GDA2020 / MGA zone 56)\ncurrent_bioclim &lt;- terra::project(current_bioclim, \"EPSG:7856\")\n\n# Our resolution is now ~5km by 5km\ncurrent_bioclim\n\n\nclass       : SpatRaster \ndimensions  : 834, 898, 19  (nrow, ncol, nlyr)\nresolution  : 5590.925, 5590.925  (x, y)\nextent      : -4407995, 612655.7, 4234346, 8897178  (xmin, xmax, ymin, ymax)\ncoord. ref. : GDA2020 / MGA zone 56 (EPSG:7856) \nsource(s)   : memory\nnames       : bioclim_01, bioclim_02, bioclim_03, bioclim_04, bioclim_05, bioclim_06, ... \nmin values  :   5.182303,   5.520304,   35.25507,   105.7126,   16.82971,  -4.954343, ... \nmax values  :  29.453394,  16.870607,   61.84691,   680.0889,   42.45033,  22.998774, ..."
  },
  {
    "objectID": "Session 3/ICCB_Environmental_data.html#mask-and-crop-to-seq-extent",
    "href": "Session 3/ICCB_Environmental_data.html#mask-and-crop-to-seq-extent",
    "title": "ICCB Environmental data download",
    "section": "Mask and crop to SEQ extent",
    "text": "Mask and crop to SEQ extent\n\n\nCode\n# Mask the current bioclimatic variables to the SEQ extent\ncurrent_bioclim &lt;- terra::mask(current_bioclim, SEQ_extent.vect)\n\n# Crop to the SEQ region\ncurrent_bioclim &lt;- terra::crop(current_bioclim, SEQ_extent.vect)\n\n# Plot all current bioclimatic variables\nplot(current_bioclim)\n\n\n\n\n\n\n\n\n\nCode\n# Save the current environmental covariates\nwriteRaster(current_bioclim,\n            filename = \"Data/Environmental_variables/SEQ_current_bioclim.tif\",\n            overwrite = T)"
  },
  {
    "objectID": "Session 3/ICCB_Environmental_data.html#load-future-environmental-data",
    "href": "Session 3/ICCB_Environmental_data.html#load-future-environmental-data",
    "title": "ICCB Environmental data download",
    "section": "Load future environmental data",
    "text": "Load future environmental data\nHere we load outputs from a moderate-high emissions shared socio-economic path scenario (SSP 3.70) for the year 2090 (2080 - 2099).\n\n\nCode\nfiles &lt;- list.files(\"Data/Environmental_variables/Future_climate_SSP370_2090\", \n             pattern = \".tif$\", \n             full.names = TRUE)\n\n# Load all bioclim rasters\nfuture_bioclim &lt;- lapply(files, terra::rast) \n\n# Make into one raster stack\nfuture_bioclim &lt;- rast(future_bioclim)\n\n# Plot the future bioclimatic variables\nplot(future_bioclim)\n\n\n\n\n\n\n\n\n\nCode\n# Examine the resolution\nfuture_bioclim\n\n\nclass       : SpatRaster \ndimensions  : 681, 841, 19  (nrow, ncol, nlyr)\nresolution  : 0.05, 0.05  (x, y)\nextent      : 111.975, 154.025, -44.025, -9.975  (xmin, xmax, ymin, ymax)\ncoord. ref. : lon/lat WGS 84 (EPSG:4326) \nsources     : bioclim_01.tif  \n              bioclim_02.tif  \n              bioclim_03.tif  \n              ... and 16 more sources\nnames       : bioclim_01, bioclim_02, bioclim_03, bioclim_04, bioclim_05, bioclim_06, ... \n\n\nCode\n# Check the CRS\ncrs(future_bioclim)\n\n\n[1] \"GEOGCRS[\\\"WGS 84\\\",\\n    ENSEMBLE[\\\"World Geodetic System 1984 ensemble\\\",\\n        MEMBER[\\\"World Geodetic System 1984 (Transit)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G730)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G873)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G1150)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G1674)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G1762)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G2139)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G2296)\\\"],\\n        ELLIPSOID[\\\"WGS 84\\\",6378137,298.257223563,\\n            LENGTHUNIT[\\\"metre\\\",1]],\\n        ENSEMBLEACCURACY[2.0]],\\n    PRIMEM[\\\"Greenwich\\\",0,\\n        ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n    CS[ellipsoidal,2],\\n        AXIS[\\\"geodetic latitude (Lat)\\\",north,\\n            ORDER[1],\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n        AXIS[\\\"geodetic longitude (Lon)\\\",east,\\n            ORDER[2],\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n    USAGE[\\n        SCOPE[\\\"Horizontal component of 3D system.\\\"],\\n        AREA[\\\"World.\\\"],\\n        BBOX[-90,-180,90,180]],\\n    ID[\\\"EPSG\\\",4326]]\"\n\n\nCode\n# Update CRS \nfuture_bioclim &lt;- terra::project(future_bioclim, \"EPSG:7856\")\n\n# Our resolution is now ~5km by 5km\nfuture_bioclim\n\n\nclass       : SpatRaster \ndimensions  : 834, 898, 19  (nrow, ncol, nlyr)\nresolution  : 5590.925, 5590.925  (x, y)\nextent      : -4407995, 612655.7, 4234346, 8897178  (xmin, xmax, ymin, ymax)\ncoord. ref. : GDA2020 / MGA zone 56 (EPSG:7856) \nsource(s)   : memory\nnames       : bioclim_01, bioclim_02, bioclim_03, bioclim_04, bioclim_05, bioclim_06, ... \nmin values  :    0.00000,    0.00000,     0.0000,     0.0000,    0.00000,  -2.243844, ... \nmax values  :   33.02249,   16.09955,    66.1461,   706.1523,   46.24717,  25.827158, ..."
  },
  {
    "objectID": "Session 3/ICCB_Environmental_data.html#mask-to-seq-extent",
    "href": "Session 3/ICCB_Environmental_data.html#mask-to-seq-extent",
    "title": "ICCB Environmental data download",
    "section": "Mask to SEQ extent",
    "text": "Mask to SEQ extent\nWe can see that for these layers the water surrounding Australia is not NA, but are values of 0. In some cells this introduces an artifact on the coastline where the values in some cells are an average between realistic values and 0, which results in cells with unusual and unrealistic values. We will do our best to mask these out.\n\n\nCode\n# First mask and crop by the SEQ extent\nfuture_bioclim &lt;- terra::mask(future_bioclim, SEQ_extent.vect) \nfuture_bioclim &lt;- terra::crop(future_bioclim, SEQ_extent.vect)\n\n# Plot one of the variables - max temp of the warmest month\nplot(future_bioclim[[5]], main = \"Future BIO5\")\n\n\n\n\n\n\n\n\n\nWe can clearly see the artifacts in BIO5, which are not present in the current layers.\n\n\nCode\nplot(current_bioclim[[5]], main = \"Current BIO5\")\n\n\n\n\n\n\n\n\n\nIf we plot a histogram of the values we can see where we can set a threshold to exclude those lower values on the coastline. We tested values to ensure that we were removing as many of the dodgy values at the coast whilst retaining all real values, and the best balance was 28 degrees.\nUnfortunately now we have slightly fewer cells on the coastline, but as these were artifacts we don’t have the true data for those cells anyway.\n\n\nCode\n# plot the distribution of values in BIO5\nhist(future_bioclim[[5]], breaks = 100)\n\n\n\n\n\n\n\n\n\nCode\n# create a mask for the artifacts, which we will apply across all of the layers\nartifact_mask &lt;- future_bioclim[[5]] &gt; 28\nnames(artifact_mask) &lt;- \"artifact_mask\"\n\n# plot the artifact mask\nplot(artifact_mask)\n\n\n\n\n\n\n\n\n\nCode\n# plot the updated future BIO5 layer\nplot(future_bioclim[[5]], main = \"Future BIO5 - unmasked\")\n\n\n\n\n\n\n\n\n\nCode\n# set all artifact values to NA (across all layers)\nfuture_bioclim &lt;- terra::mask(future_bioclim, artifact_mask, maskvalues = 0) # Set all values of 0 to NA\n\n# plot the updated future BIO5 layer\nplot(future_bioclim[[5]], main = \"Future BIO5 - masked\")\n\n\n\n\n\n\n\n\n\nCode\nplot(current_bioclim[[5]], main = \"Current BIO5\")\n\n\n\n\n\n\n\n\n\nCode\n# this removes those lower values\nhist(future_bioclim[[5]], breaks = 100)\n\n\n\n\n\n\n\n\n\nNow that we have applied the artifact mask across all layers, they look better.\n\n\nCode\nplot(future_bioclim)\n\n\n\n\n\n\n\n\n\nNow we can save the future environmental covariates for SEQ.\n\n\nCode\n# Save the cropped and masked future environmental covariates\nwriteRaster(future_bioclim,\n            filename = \"Data/Environmental_variables/SEQ_future_bioclim.2090.SSP370.tif\",\n            overwrite = T)"
  },
  {
    "objectID": "Session 3/ICCB_Environmental_data.html#load-future-environmental-data-2",
    "href": "Session 3/ICCB_Environmental_data.html#load-future-environmental-data-2",
    "title": "ICCB Environmental data download",
    "section": "Load future environmental data 2",
    "text": "Load future environmental data 2\nHere we load outputs from a low emissions shared socio-economic path scenario (SSP 1.26) for the year 2090 (2080 - 2099).\n\n\nCode\nfiles &lt;- list.files(\"Data/Environmental_variables/Future_climate_SSP126_2090\", \n             pattern = \".tif$\", \n             full.names = TRUE)\n\n# Load all bioclim rasters\nfuture_bioclim &lt;- lapply(files, terra::rast) \n\n# Make into one raster stack\nfuture_bioclim &lt;- rast(future_bioclim)\n\nplot(future_bioclim)\n\n\n\n\n\n\n\n\n\nCode\n# Examine the resolution\nfuture_bioclim\n\n\nclass       : SpatRaster \ndimensions  : 681, 841, 19  (nrow, ncol, nlyr)\nresolution  : 0.05, 0.05  (x, y)\nextent      : 111.975, 154.025, -44.025, -9.975  (xmin, xmax, ymin, ymax)\ncoord. ref. : lon/lat WGS 84 (EPSG:4326) \nsources     : bioclim_01.tif  \n              bioclim_02.tif  \n              bioclim_03.tif  \n              ... and 16 more sources\nnames       : bioclim_01, bioclim_02, bioclim_03, bioclim_04, bioclim_05, bioclim_06, ... \nmin values  :    0.00000,    0.00000,     0.0000,         ? ,         ? ,         ? , ... \nmax values  :   30.47033,   16.75114,    63.2751,         ? ,         ? ,         ? , ... \n\n\nCode\n# Check the CRS\ncrs(future_bioclim)\n\n\n[1] \"GEOGCRS[\\\"WGS 84\\\",\\n    ENSEMBLE[\\\"World Geodetic System 1984 ensemble\\\",\\n        MEMBER[\\\"World Geodetic System 1984 (Transit)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G730)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G873)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G1150)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G1674)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G1762)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G2139)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G2296)\\\"],\\n        ELLIPSOID[\\\"WGS 84\\\",6378137,298.257223563,\\n            LENGTHUNIT[\\\"metre\\\",1]],\\n        ENSEMBLEACCURACY[2.0]],\\n    PRIMEM[\\\"Greenwich\\\",0,\\n        ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n    CS[ellipsoidal,2],\\n        AXIS[\\\"geodetic latitude (Lat)\\\",north,\\n            ORDER[1],\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n        AXIS[\\\"geodetic longitude (Lon)\\\",east,\\n            ORDER[2],\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n    USAGE[\\n        SCOPE[\\\"Horizontal component of 3D system.\\\"],\\n        AREA[\\\"World.\\\"],\\n        BBOX[-90,-180,90,180]],\\n    ID[\\\"EPSG\\\",4326]]\"\n\n\nCode\n# Update CRS \nfuture_bioclim &lt;- terra::project(future_bioclim, \"EPSG:7856\")\n\n# Our resolution is now ~5km by 5km\nfuture_bioclim\n\n\nclass       : SpatRaster \ndimensions  : 834, 898, 19  (nrow, ncol, nlyr)\nresolution  : 5590.925, 5590.925  (x, y)\nextent      : -4407995, 612655.7, 4234346, 8897178  (xmin, xmax, ymin, ymax)\ncoord. ref. : GDA2020 / MGA zone 56 (EPSG:7856) \nsource(s)   : memory\nnames       : bioclim_01, bioclim_02, bioclim_03, bioclim_04, bioclim_05, bioclim_06, ... \nmin values  :    0.00000,    0.00000,    0.00000,     0.0000,    0.00000,  -4.081378, ... \nmax values  :   30.78085,   16.89395,   63.34254,   687.5474,   43.83962,  23.968334, ..."
  },
  {
    "objectID": "Session 3/ICCB_Environmental_data.html#mask-to-seq-extent-1",
    "href": "Session 3/ICCB_Environmental_data.html#mask-to-seq-extent-1",
    "title": "ICCB Environmental data download",
    "section": "Mask to SEQ extent",
    "text": "Mask to SEQ extent\nWe will crop and mask the future bioclimatic variables to the SEQ extent, and apply the artifact mask as we did for the SSP 3.70 layers.\n\n\nCode\n# First mask and crop by the SEQ extent\nfuture_bioclim &lt;- terra::mask(future_bioclim, SEQ_extent.vect) \nfuture_bioclim &lt;- terra::crop(future_bioclim, SEQ_extent.vect)\n\n# set all artifact values to NA\nfuture_bioclim &lt;- terra::mask(future_bioclim, artifact_mask, maskvalues = 0) # Set all values of 0 to NA\nplot(future_bioclim[[5]])\n\n\n\n\n\n\n\n\n\nCode\nplot(future_bioclim)\n\n\n\n\n\n\n\n\n\nCode\n# Save the future environmental covariates\nwriteRaster(future_bioclim,\n            filename = \"Data/Environmental_variables/SEQ_future_bioclim.2090.SSP126.tif\",\n            overwrite = T)"
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html",
    "href": "Session 3/ICCB_Modelling_and_validation.html",
    "title": "ICCB Species distribution modelling",
    "section": "",
    "text": "We wrote this script drawing on some of the following resources:",
    "crumbs": [
      "Session 3",
      "ICCB Species distribution modelling"
    ]
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#import-packages",
    "href": "Session 3/ICCB_Modelling_and_validation.html#import-packages",
    "title": "ICCB Species distribution modelling",
    "section": "Import packages",
    "text": "Import packages\n\n\nCode\n# general R functions\nlibrary(tidyverse)\nlibrary(RColorBrewer)\n\n# for downloading species data\nlibrary(galah)\n\n# for general spatial operations\nlibrary(terra)\nlibrary(sf)\nlibrary(tidyterra)\n\n# for SDM analyses\nlibrary(predicts)\nlibrary(blockCV)\nlibrary(ecospat)\nlibrary(usdm)\nlibrary(precrec)\nlibrary(corrplot)",
    "crumbs": [
      "Session 3",
      "ICCB Species distribution modelling"
    ]
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#load-south-east-queensland-seq-boundary",
    "href": "Session 3/ICCB_Modelling_and_validation.html#load-south-east-queensland-seq-boundary",
    "title": "ICCB Species distribution modelling",
    "section": "Load South East Queensland (SEQ) boundary",
    "text": "Load South East Queensland (SEQ) boundary\nWe start by defining our study area, which is the South East Queensland (SEQ) region. In a previous session we used the Local Government Areas (LGA) shapefile to define the extent of SEQ.\nWhat we’ll load is a polygon of our boundary which becomes our model domain.\nFor our coordinate reference system throughout, we’ll be using GDA2020 / MGA zone 56, which is identified by the EPSG code 7856.\n\n\nCode\nSEQ_extent.vect &lt;- vect(\"Data/Environmental_variables/seq_boundary.gpkg\")\n\n# Define an sf object as well (used later)\nSEQ_extent &lt;- st_as_sf(SEQ_extent.vect, \n                        coords = c(\"x\", \"y\"), \n                        crs = 7856)\n\nplot(SEQ_extent.vect)",
    "crumbs": [
      "Session 3",
      "ICCB Species distribution modelling"
    ]
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#random-background-sampling",
    "href": "Session 3/ICCB_Modelling_and_validation.html#random-background-sampling",
    "title": "ICCB Species distribution modelling",
    "section": "Random background sampling",
    "text": "Random background sampling\nWe need to load a template grid for creating background points. This matches the grid our covariates are on, which we’ll load soon.\nWe’re using a function from the predicts package for this.\n\n\nCode\ndomain &lt;- rast(\"Data/Environmental_variables/SEQ_current_bioclim.tif\")\n\n# Make a blank raster of all 1s of the same dimensions as our covariate grid\ndomain &lt;- domain[[1]]\ndomain &lt;- ifel(is.na(domain), NA, 1) # Set all values to 1 except for NA values (which are outside the SEQ extent\n\nnames(domain) &lt;- \"SEQ_extent\"\n\nplot(domain, main = \"SEQ extent for background sampling\")\n\n\n\n\n\n\n\n\n\nCode\n# Set the location and number of background points\n# The mask means that any NA (not SEQ) locations do not include background points\nbackground &lt;- predicts::backgroundSample(mask = domain, \n                                         n = 2500)\n\n# Convert to terra SpatVector object\nbackground &lt;- terra::vect(background[,1:2], crs = \"EPSG:7856\")\n\n# Convert background points (SpatVector) to data frame\nbackground_df &lt;- as.data.frame(geom(background))\n\nkoala_occ.vect &lt;- vect(koala_occ_sf)\n\n# Plot the presences (blue) and the background points (grey)\nggplot() +\n  geom_sf(data = SEQ_extent, fill = \"purple3\", alpha = 0.5, color = \"black\", size = 0.2) +\n  geom_spatvector(data = background,                           # Add koala presence locations\n             color = \"gray\", cex = 0.5) +               # Add points for occurrences\n  geom_spatvector(data = koala_occ.vect, \n                  aes(geometry = geometry), \n                  color = \"blue\", cex = 0.5) + # Add background points\n  ggtitle(\"Koala occurrences (blue) and background points (grey) in South East Queensland\") +      # Add title\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\nCombine koala presence and background points as dataframes\n\n\nCode\n# Make a dataframe of just x, y and presence\nkoala_occ_df &lt;- koala_occ_sf %&gt;%\n  dplyr::mutate(x = sf::st_coordinates(.)[,1],\n                y = sf::st_coordinates(.)[,2]) %&gt;%\n                st_drop_geometry() %&gt;% \n  dplyr::select(x,y) %&gt;% \n  mutate(Presence = 1)\n  \nhead(koala_occ_df)\n\n\n\n  \n\n\n\nCode\nbackground_df &lt;- background %&gt;% \n  as.data.frame(geom = \"XY\") %&gt;% \n  dplyr::select(x,y) %&gt;% \n  mutate(Presence = 0)\n\nhead(background_df)\n\n\n\n  \n\n\n\nCode\n# Combine to one dataframe\npr_bg &lt;- rbind(koala_occ_df, background_df)",
    "crumbs": [
      "Session 3",
      "ICCB Species distribution modelling"
    ]
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#covariate-to-account-for-sampling-bias",
    "href": "Session 3/ICCB_Modelling_and_validation.html#covariate-to-account-for-sampling-bias",
    "title": "ICCB Species distribution modelling",
    "section": "Covariate to account for sampling bias",
    "text": "Covariate to account for sampling bias\nAs these data were collected from a wide number of sources, we have to consider whether any of the data, such as that which was opportunistically collected (Kéry et al. 2010), might be biased towards areas of higher human activity. This is a common issue in species occurrence data and is typically called sampling bias or preferential sampling, and occurs because areas that are more accessible and/or have higher human activity are more likely to be opportunistically sampled (Conn, Thorson, and Johnson 2017).\nThis means that if there are environmental variables that happen correlated with human activity (which is often the case, humans also select for favourable environmental conditions), it will appear that these variables are more influential than they actually are, because we associating that environmental covariate with ‘more’ presence records.\nThere are several different ways to account for this when modelling (Pennino et al. 2019; Mäkinen, Merow, and Jetz 2024; Dubos et al. 2022). Some of the common approaches include:\n\nSampling pseudo-absences more points where there is higher sampling effort.\nUsing a covariate to attempt to capture the sampling bias, such as human population density or distance to roads.\nUsing a model or model structure that explicitly accounts for sampling bias, such as including a spatial random effect or using an integrated model to include presence-only and presence-absence data (Foster et al. 2024).\n\nIn our case, we will use a covariate for the Global Human Footprint Index (HFP) , which is a measure of human impact on the environment. This is a raster layer with continuous (percentage values) that we will use to account for sampling bias in our model.\nYou will be able to see Brisbane as the largest area of human footprint, with Moreton Bay visible to the right, followed by the Gold Coast to the south, the Sunshine Coast to the north, and Toowoomba to the west (about 2 hours drive).\n\n\nCode\nhuman_footprint &lt;- rast(\"Data/Environmental_variables/cost_hfp2013.tif\")\nnames(human_footprint) &lt;- \"human_footprint\"\n\n# Update CRS to EPSG:7856 (GDA2020 / MGA zone 56)\nhuman_footprint &lt;- terra::project(human_footprint, \"EPSG:7856\")\n\n# Resample to match the extent and resolution of the covariates\nhuman_footprint &lt;- resample(human_footprint, covs_current_expert, method = \"bilinear\")\n\n# Mask to SEQ extent\nhuman_footprint &lt;- terra::mask(human_footprint, covs_current_expert[[1]]) \n\nplot(human_footprint, main = \"Human Footprint Index\")\n\n\n\n\n\n\n\n\n\nAlthough this isn’t a formal comparison, we can see that this variable is correlated with the presence of koalas.\n\n\nCode\nplot(human_footprint, main = \"Human Footprint Index\")\npoints(koala_occ_sf, col = \"red\", alpha = 0.1, pch = 20, cex = 0.5)\n\n\n\n\n\n\n\n\n\nYou would want to put some more thought into your own study and the best way to account for sampling bias, but in our case we will try using the human footprint index as a covariate in our model, and assess how our predictions change.\n\nAdd the human footprint layer to our covariates\n\n\nCode\ncovs_current_expert_HF &lt;- c(covs_current_expert, human_footprint)\nplot(covs_current_expert_HF)\n\n\n\n\n\n\n\n\n\n\n\nExtract environmental covariate values from presence and background locations (training locations)\nThis will create a dataframe where each row is a koala presence or background location and each column is a value for our four bioclimatic variables at that location.\nWe use a function from terra for this.\n\n\nCode\n# this will give us the covariate values for each presence and background point\nPB_covs &lt;- terra::extract(\n  x = covs_current_expert_HF,   # Raster with environmental variables\n  y = pr_bg[, c(\"x\", \"y\")],  # Dataframe with x, y and presence\n  ID = FALSE                 # Don't return an ID column for each location\n)\n\ntrain_PB_covs &lt;- cbind(pr_bg, PB_covs) # Combine the presence column with the covariate values\n\n# drop any NAs\ntrain_PB_covs &lt;- train_PB_covs %&gt;% drop_na()\n\nhead(train_PB_covs)",
    "crumbs": [
      "Session 3",
      "ICCB Species distribution modelling"
    ]
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#thin-the-koala-presence-points-for-tutorial-only",
    "href": "Session 3/ICCB_Modelling_and_validation.html#thin-the-koala-presence-points-for-tutorial-only",
    "title": "ICCB Species distribution modelling",
    "section": "Thin the koala presence points (for tutorial only)",
    "text": "Thin the koala presence points (for tutorial only)\nWe now thin the presences to reduce the number of points to a manageable size for plotting and modelling. This is just for the purpose of this tutorial, and is done here to make the tutorial run faster and to make the plots clearer. There are some reasons you would want to thin (such as bias correction), but you would want to carefully consider whether this is appropriate for your modelling.\nWe only thin the presence points as the background points are already limited by the number of cells in the SEQ region.\n\n\nCode\ntrain_PB_covs_pres &lt;- train_PB_covs %&gt;% filter(Presence == 1)\ntrain_PB_covs_bg &lt;- train_PB_covs %&gt;% filter(Presence == 0)\n\n# Thin the presences - 10000 presence points\ntrain_PB_covs_pres_thinned &lt;- train_PB_covs_pres[sample(nrow(train_PB_covs_pres), 10000), ]\n\n# Combine back into both presence and background\ntrain_PB_covs_thinned &lt;- rbind(train_PB_covs_pres_thinned, train_PB_covs_bg, make.row.names = FALSE)",
    "crumbs": [
      "Session 3",
      "ICCB Species distribution modelling"
    ]
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#check-correlation-and-multicollinearity-of-covariates",
    "href": "Session 3/ICCB_Modelling_and_validation.html#check-correlation-and-multicollinearity-of-covariates",
    "title": "ICCB Species distribution modelling",
    "section": "Check correlation and multicollinearity of covariates",
    "text": "Check correlation and multicollinearity of covariates\nAlthough we’ve narrowed down our covariates already based on discussion with experts, there’s a chance that our remaining variables might be correlated or collinear. This would cause issues with models, particularly because we’re hoping to predict our model into the future. We’re going to inspect our covariates for signs of correlation and multicolinearity.\nThere are several different methods for creating correlation plots, we just show two.\n\nCorrelation plot from the ecospat package\n\n\nCode\n# use the dataframe we just created, dropping the x, y, and presence columns (1-3)\necospat::ecospat.cor.plot(train_PB_covs_thinned[, -1:-3])\n\n\n\n\n\n\n\n\n\nWhat the correlation test plot suggests is that we have some correlated covariates. Particularly our Bio6 and Bio12.\nOften a rule of thumb of ~ 0.7 correlation is used to decide what a ‘too correlated’ covariate pair are (REF). In practice, it’s important to think carefully before dropping covariates.\n\n\nVariance Inflation Factor (VIF)\nIf you find corrplot is hard for you to use to make decisions, we can also look at the Variance Inflation Factor (VIF). VIF is another statistical measure used to detect multicollinearity in a set of explanatory (independent) variables in a regression model.\nInterpretation:\n\nVIF = 1: No correlation\nVIF &gt; 1 and &lt;= 5: Moderate correlation; may not require corrective action.\nVIF &gt; 5: Indicates high correlation. Multicollinearity may be problematic, and further investigation is recommended.\nVIF &gt; 10: Strong multicollinearity. The variable is highly collinear with others, and steps should be taken to address this.\n\n\n\nCode\nusdm::vifstep(covs_current_expert_HF) # Variance Inflation Factor and test for multicollinearity\n\n\nNo variable from the 5 input variables has collinearity problem. \n\nThe linear correlation coefficients ranges between: \nmin correlation ( BIO15_Precip_Seasonality ~ BIO6_Min_Temp_Coldest_Month ):  -0.1420642 \nmax correlation ( BIO12_Annual_Precipitation ~ BIO6_Min_Temp_Coldest_Month ):  0.8762638 \n\n---------- VIFs of the remained variables -------- \n                    Variables      VIF\n1 BIO5_Max_Temp_Warmest_Month 2.658798\n2 BIO6_Min_Temp_Coldest_Month 5.916991\n3  BIO12_Annual_Precipitation 7.552088\n4    BIO15_Precip_Seasonality 1.330505\n5             human_footprint 1.551557",
    "crumbs": [
      "Session 3",
      "ICCB Species distribution modelling"
    ]
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#scaling-the-covariates",
    "href": "Session 3/ICCB_Modelling_and_validation.html#scaling-the-covariates",
    "title": "ICCB Species distribution modelling",
    "section": "Scaling the covariates",
    "text": "Scaling the covariates\nIt is common to scale the covariates before fitting a model. This is because some models, such as Generalised Linear Models (GLMs), can be sensitive to the scale of the covariates. Scaling the covariates can also make the coefficients more comparable, as they are now on a similar scale to each other.\nA typical scaling approach is to subtract the mean and divide by the standard deviation of each covariate, which is also known as z-scaling or z-scoring. After this operation, all covariates will have a mean of 0 and a standard deviation of 1.\nWe can use a base R function to scale the covariates, and the default is to centre (subtract the mean) and scale (divide by the standard deviation).\n\n\nCode\n# pull out just the covariate values from the dataframe\ncovariate_values &lt;- train_PB_covs_thinned[, -1:-3]\n\n# scale the covariates - returns a matrix\nscaled_covariates &lt;- base::scale(covariate_values, \n                                 center = TRUE, \n                                 scale = TRUE)\n\n# convert back to a dataframe (and remove row names)\nscaled_covariates_df &lt;- data.frame(scaled_covariates)\n\nhead(scaled_covariates_df)\n\n\n\n  \n\n\n\nCode\n# Add the presence column back to the scaled covariates\ntrain_PB_covs_thinned_scaled &lt;- cbind(train_PB_covs_thinned[, 1:3], scaled_covariates_df)\n\n\nThe scaling operation also returns the particular scaling values that were used, which is helpful for generating predictions later on. We can access these using the attributes of the returned dataframe. We only need the scaling factor, as we will rescale the coefficients before generating predictions.\n\n\nCode\n# Get the attributes of the scaled covariates\nscaled_attributes &lt;- attributes(scaled_covariates)\nscaled_attributes$`scaled:scale` # the SD/scaling factor of each covariate\n\n\nBIO5_Max_Temp_Warmest_Month BIO6_Min_Temp_Coldest_Month \n                  0.9834556                   1.7631559 \n BIO12_Annual_Precipitation    BIO15_Precip_Seasonality \n                228.2763322                   3.3004337 \n            human_footprint \n                 11.0620142",
    "crumbs": [
      "Session 3",
      "ICCB Species distribution modelling"
    ]
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#null-model",
    "href": "Session 3/ICCB_Modelling_and_validation.html#null-model",
    "title": "ICCB Species distribution modelling",
    "section": "Null model",
    "text": "Null model\nNull model: no explanatory variables or predictors are included.\nIt is always helpful to create a null model as a benchmark to assess how the inclusion of explanatory variables improves the model.\n\n\nCode\n# Fit a null model with only the intercept\nnull_model &lt;- glm(Presence ~ 1,\n                  data = train_PB_covs_thinned_scaled,\n                  family = binomial(link = \"logit\"))\n\n# Check the model results\nsummary(null_model)\n\n\n\nCall:\nglm(formula = Presence ~ 1, family = binomial(link = \"logit\"), \n    data = train_PB_covs_thinned_scaled)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  2.10046    0.03028   69.37   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 7734  on 11223  degrees of freedom\nResidual deviance: 7734  on 11223  degrees of freedom\nAIC: 7736\n\nNumber of Fisher Scoring iterations: 4",
    "crumbs": [
      "Session 3",
      "ICCB Species distribution modelling"
    ]
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#glm---expert-variables-with-linear-terms",
    "href": "Session 3/ICCB_Modelling_and_validation.html#glm---expert-variables-with-linear-terms",
    "title": "ICCB Species distribution modelling",
    "section": "GLM - expert variables with linear terms",
    "text": "GLM - expert variables with linear terms\nIn this model, we include linear terms for the covariates. You can also do things like add quadratic terms to account for non-linear relationships between the predictors and the response variable. This increases the complexity of the model and allows for more flexibility in fitting the data.\nYou can also try fitting the model with and without the scaled covariates. The z- and p-values of each covariate should be the same (but not for the intercept and centering the covariates affects that), as well as the AIC.\n\n\nCode\nglm_model &lt;- glm(Presence ~\n                     BIO5_Max_Temp_Warmest_Month +\n                     BIO6_Min_Temp_Coldest_Month +\n                     BIO12_Annual_Precipitation +\n                     BIO15_Precip_Seasonality +\n                     human_footprint,\n                   data=train_PB_covs_thinned_scaled,\n                   family = binomial(link = \"logit\"))\n\n# Check the model results\nsummary(glm_model)\n\n\n\nCall:\nglm(formula = Presence ~ BIO5_Max_Temp_Warmest_Month + BIO6_Min_Temp_Coldest_Month + \n    BIO12_Annual_Precipitation + BIO15_Precip_Seasonality + human_footprint, \n    family = binomial(link = \"logit\"), data = train_PB_covs_thinned_scaled)\n\nCoefficients:\n                            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)                  3.53786    0.07602  46.538  &lt; 2e-16 ***\nBIO5_Max_Temp_Warmest_Month -0.46584    0.05579  -8.350  &lt; 2e-16 ***\nBIO6_Min_Temp_Coldest_Month  0.41535    0.07490   5.545 2.94e-08 ***\nBIO12_Annual_Precipitation  -0.12314    0.07884  -1.562    0.118    \nBIO15_Precip_Seasonality     0.69417    0.04457  15.574  &lt; 2e-16 ***\nhuman_footprint              1.44861    0.06802  21.298  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 7734.0  on 11223  degrees of freedom\nResidual deviance: 4445.8  on 11218  degrees of freedom\nAIC: 4457.8\n\nNumber of Fisher Scoring iterations: 7",
    "crumbs": [
      "Session 3",
      "ICCB Species distribution modelling"
    ]
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#model-effect-evaluation",
    "href": "Session 3/ICCB_Modelling_and_validation.html#model-effect-evaluation",
    "title": "ICCB Species distribution modelling",
    "section": "Model effect evaluation",
    "text": "Model effect evaluation\nHere we use a function presented in an EcoCommons Australia notebook to evaluate the model performance. The notebook can be found on their GitHub: https://github.com/EcoCommonsAustralia/notebooks/tree/main/notebooks.\n\n\nCode\n# Function to plot effect size graph\nplot_effect_size &lt;- function(glm_model) {\n  # Check if required libraries are installed\n  if (!requireNamespace(\"ggplot2\", quietly = TRUE)) {\n    stop(\"Please install the 'ggplot2' package to use this function.\")\n  }\n  library(ggplot2)\n\n  # Extract effect sizes (coefficients) from the model\n  coefs &lt;- summary(glm_model)$coefficients\n  effect_sizes &lt;- data.frame(\n    Variable = rownames(coefs)[-1],  # Exclude the intercept\n    Effect_Size = coefs[-1, \"Estimate\"],\n    Std_Error = coefs[-1, \"Std. Error\"]\n  )\n\n  # Sort by effect size\n  effect_sizes &lt;- effect_sizes[order(-abs(effect_sizes$Effect_Size)), ]\n\n  # Plot the effect sizes with error bars\n  ggplot(effect_sizes, aes(x = reorder(Variable, Effect_Size), y = Effect_Size)) +\n    geom_hline(yintercept = 0, linetype = \"dashed\", color = \"black\", alpha = 0.5) +\n    geom_point(stat = \"identity\", colour = \"#11aa96\") +\n    geom_errorbar(aes(ymin = Effect_Size - Std_Error, ymax = Effect_Size + Std_Error), \n                  colour = \"#11aa96\", width = 0.1) +\n    coord_flip() +\n    labs(\n      title = \"Effect Sizes of Variables\",\n      x = \"Variable\",\n      y = \"Effect Size (Coefficient Estimate)\"\n    ) +\n    theme_bw()\n}\n\n\nRun the function on the covariates used in the model.\nInterestingly, the human footprint index has the largest effect size, followed by the annual precipitation and the minimum temperature of the coldest month, both of which were positive. The maximum temperature of the warmest month has a negative coefficient, which suggests that koalas are less likely to be found in areas with higher temperatures during the warmest month.\n\n\nCode\nplot_effect_size(glm_model)",
    "crumbs": [
      "Session 3",
      "ICCB Species distribution modelling"
    ]
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#response-curves",
    "href": "Session 3/ICCB_Modelling_and_validation.html#response-curves",
    "title": "ICCB Species distribution modelling",
    "section": "Response curves",
    "text": "Response curves\nAgain, we can use a function from the EcoCommons notebook to plot the response curves from the model.\n\n\nCode\nplot_species_response &lt;- function(glm_model, predictors, data) {\n  # Check if required libraries are installed\n  if (!requireNamespace(\"ggplot2\", quietly = TRUE) || !requireNamespace(\"gridExtra\", quietly = TRUE)) {\n    stop(\"Please install the 'ggplot2' and 'gridExtra' packages to use this function.\")\n  }\n  library(ggplot2)\n  library(gridExtra)\n\n  # Create empty list to store response plots\n  response_plots &lt;- list()\n\n  # Loop through each predictor variable\n  for (predictor in predictors) {\n    # Create new data frame to vary predictor while keeping others constant\n    pred_range &lt;- seq(\n      min(data[[predictor]], na.rm = TRUE),\n      max(data[[predictor]], na.rm = TRUE),\n      length.out = 100\n    )\n    const_data &lt;- data[1, , drop = FALSE]  # Use first row to keep other predictors constant\n    response_data &lt;- const_data[rep(1, 100), ]  # Duplicate the row\n    response_data[[predictor]] &lt;- pred_range\n\n    # Predict probabilities\n    predicted_response &lt;- predict(glm_model, newdata = response_data, type = \"response\")\n\n    # Create data frame for plotting\n    plot_data &lt;- data.frame(\n      Predictor_Value = pred_range,\n      Predicted_Probability = predicted_response\n    )\n\n    # Add presence and absence data\n    presence_absence_data &lt;- data.frame(\n      Predictor_Value = data[[predictor]],\n      Presence_Absence = data$Presence\n    )\n\n    # Generate the response plot\n    p &lt;- ggplot() +\n\n      geom_line(data = plot_data,\n                aes(x = Predictor_Value, y = Predicted_Probability),\n                color = \"#61c6fa\", linewidth = 1) +\n\n      geom_point(data = presence_absence_data[presence_absence_data$Presence_Absence == 1, ],\n                 aes(x = Predictor_Value, y = Presence_Absence),\n                 color = \"#11aa96\", alpha = 0.2) +\n\n      geom_point(data = presence_absence_data[presence_absence_data$Presence_Absence == 0, ],\n                 aes(x = Predictor_Value, y = Presence_Absence),\n                 color = \"#f6aa70\", alpha = 0.2) +\n\n      labs(x = predictor, y = NULL) +\n      theme_bw() +\n      theme(axis.title.y = element_blank())\n\n    # Store the plot in the list\n    response_plots[[predictor]] &lt;- p\n  }\n\n  # Arrange all plots in one combined plot with a single shared y-axis label\n  grid.arrange(\n    grobs = response_plots,\n    ncol = 3,\n    left = \"Predicted Probability / Presence-Absence\"\n  )\n}\n\n\n\nPlot the response curves\n\n\nCode\n# get the names of the covariates in the model (drop the intercept)\npredictors &lt;- names(glm_model$coefficients)[-1]\n\n# Plot the response curves for the predictors in the model\nplot_species_response(glm_model, predictors, train_PB_covs_thinned_scaled)\n\n\n\n\n\n\n\n\n\n\n\nScale the raster layers with the same scaling as the covariates\n\n\nCode\n# Scale your prediction rasters using the same scaling parameters\ncovs_current_expert_HF_scaled &lt;- scale(covs_current_expert_HF, \n                                   center = attr(scaled_covariates, \"scaled:center\"),\n                                   scale = attr(scaled_covariates, \"scaled:scale\"))\n\n# plot to check the scaling worked\nplot(covs_current_expert_HF_scaled)",
    "crumbs": [
      "Session 3",
      "ICCB Species distribution modelling"
    ]
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#glm-predictions-to-current-environment",
    "href": "Session 3/ICCB_Modelling_and_validation.html#glm-predictions-to-current-environment",
    "title": "ICCB Species distribution modelling",
    "section": "GLM predictions to current environment",
    "text": "GLM predictions to current environment\n\n\nCode\n# Predict the presence probability across the entire raster extent\npredicted_current_biased &lt;- predicts::predict(covs_current_expert_HF_scaled, glm_model, type = \"response\")\n\n# Plot the species distribution raster\nplot(\n  predicted_current_biased,\n  range = c(0, 1),  # Set min and max values for the color scale\n  main = \"Climatic Suitability of Koalas in SEQ (biased)\"\n)",
    "crumbs": [
      "Session 3",
      "ICCB Species distribution modelling"
    ]
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#accounting-for-the-sampling-bias",
    "href": "Session 3/ICCB_Modelling_and_validation.html#accounting-for-the-sampling-bias",
    "title": "ICCB Species distribution modelling",
    "section": "Accounting for the sampling bias",
    "text": "Accounting for the sampling bias\nWhat we did above did not account for the sampling bias, as the predictions we generated maintained the bias process. We need to instead set the human footprint index to a constant value across the entire extent, which represents if the process that produces the bias is the same everywhere.\nThe approach that we’ve taken is not perfect, and would require some thinking and investigation, but it illustrates the potential impact of sampling bias and how you might account for it.\n\n\nCode\n# pull out the scaled human footprint index layer\nconstant_HF &lt;- covs_current_expert_HF_scaled[[5]]\n\n# Set the human footprint index to a constant value across the entire extent\n# Mean value of the human footprint index\nconstant_HF[] &lt;- mean(constant_HF[], na.rm = TRUE)\n# mask to the extent of the covariates\nconstant_HF &lt;- terra::mask(constant_HF, covs_current_expert_HF_scaled[[5]])\n\n# add the constant human footprint back into the raster layers\ncovs_current_expert_constHF_scaled &lt;- c(covs_current_expert_HF_scaled[[1:4]], constant_HF)\n\n# check the new human footprint layer\nplot(covs_current_expert_constHF_scaled)",
    "crumbs": [
      "Session 3",
      "ICCB Species distribution modelling"
    ]
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#generate-predictions-with-the-constant-human-footprint-layer",
    "href": "Session 3/ICCB_Modelling_and_validation.html#generate-predictions-with-the-constant-human-footprint-layer",
    "title": "ICCB Species distribution modelling",
    "section": "Generate predictions with the constant human footprint layer",
    "text": "Generate predictions with the constant human footprint layer\n\n\nCode\n# Predict the presence probability across the entire raster extent\npredicted_current &lt;- predicts::predict(covs_current_expert_constHF_scaled, glm_model, type = \"response\")\n\n# Plot the species distribution raster\nplot(\n  predicted_current,\n  range = c(0, 1),  # Set min and max values for the color scale\n  main = \"Climatic Suitability of Koalas in SEQ - Current\"\n)\n\n\n\n\n\n\n\n\n\nCode\n# Save the plot as a png\npng(filename=\"Outputs/GLM_outputs/predicted_current.png\",\n    width = 150, height = 130, units = \"mm\", res = 600)\nplot(predicted_current,\n  range = c(0, 1),  # Set min and max values for the color scale\n  main = \"Climatic Suitability of Koalas in SEQ - Current\")\ndev.off()\n\n\nquartz_off_screen \n                2 \n\n\nCode\n# Write the raster to file\nwriteRaster(predicted_current, \"Outputs/GLM_outputs/predicted_current.tif\", overwrite = TRUE)",
    "crumbs": [
      "Session 3",
      "ICCB Species distribution modelling"
    ]
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#run-the-model-for-every-fold-and-evaluate",
    "href": "Session 3/ICCB_Modelling_and_validation.html#run-the-model-for-every-fold-and-evaluate",
    "title": "ICCB Species distribution modelling",
    "section": "Run the model for every fold and evaluate",
    "text": "Run the model for every fold and evaluate\n\nModel evaluation - metrics\nTypically, it helps to evaluate your model with several metrics that describe different features of model performance and prediction. Here, we define a function to feed in a model prediction and calculate several evaluation metrics.\nThe metrics are:\nArea under the receiver operating characteristic curve (AUC ROC)\n\nHigher values of this (closer to 1) suggest a model is good at distinguishing presence points from the background.\n\nContinuous boyce index\n\nHigher values of this (closer to 1) suggest a model is good at predicting higher suitability at spots where there were presences.\n\n\n\nCode\n# Start a dataframe to save results\neval_df &lt;- data.frame(fold = numeric(),\n                      ROC = numeric(),\n                      boyce = numeric())\n\nfor(f in seq_along(spfolds)) {\n\n  # Subset the training and testing data (spatial cross validation) (for the fth fold)\n\n  train_PB_covs_scv &lt;- train_PB_covs_thinned[spfolds[[f]][[1]], ]\n  test_PB_covs_scv &lt;- train_PB_covs_thinned[spfolds[[f]][[2]], ]\n\n  glm_model_fold &lt;- glm(Presence ~\n                          BIO5_Max_Temp_Warmest_Month +\n                          BIO6_Min_Temp_Coldest_Month +\n                          BIO12_Annual_Precipitation +\n                          BIO15_Precip_Seasonality +\n                          human_footprint,\n                        data=train_PB_covs_scv,\n                        family = binomial(link = \"logit\"))\n\n    # Predict to the testing data of fold f\n  test_PB_covs_scv$pred &lt;- predict(glm_model_fold, newdata = test_PB_covs_scv, type = \"response\")\n\n  # Evaluate prediction on test set\n  ROC = precrec::auc(precrec::evalmod(scores = test_PB_covs_scv$pred, labels = test_PB_covs_scv$Presence))[1,4]\n\n  boyce = ecospat::ecospat.boyce(fit = test_PB_covs_scv$pred,\n                                 obs = test_PB_covs_scv$pred[which(test_PB_covs_scv$Presence==1)],\n                                 nclass = 0, # Calculate continuous index\n                                 method = \"pearson\",\n                                 PEplot = F)[[\"cor\"]]\n\n  # Add results to dataframe\n  eval_df &lt;- eval_df %&gt;% add_row(fold = f, ROC = ROC, boyce = boyce)\n\n}\n\n\n\n\nSummarise the evaluation metrics\n\n\nCode\n# Mean AUC & boyce\neval_df %&gt;%\n  summarise(mean_AUC = mean(ROC),\n            mean_boyce = mean(boyce),\n            sd_AUC = sd(ROC),\n            sd_boyce = sd(boyce))",
    "crumbs": [
      "Session 3",
      "ICCB Species distribution modelling"
    ]
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#load-future-environmental-data",
    "href": "Session 3/ICCB_Modelling_and_validation.html#load-future-environmental-data",
    "title": "ICCB Species distribution modelling",
    "section": "Load future environmental data",
    "text": "Load future environmental data\n\n\nCode\ncovs_future_SSP370 &lt;- rast(\"Data/Environmental_variables/SEQ_future_bioclim.2090.SSP370.tif\")\nnames(covs_future_SSP370) &lt;- layer_names\ncovs_future_SSP370\n\n\nclass       : SpatRaster \ndimensions  : 44, 51, 19  (nrow, ncol, nlyr)\nresolution  : 5590.925, 5590.925  (x, y)\nextent      : 271609.2, 556746.4, 6862081, 7108082  (xmin, xmax, ymin, ymax)\ncoord. ref. : GDA2020 / MGA zone 56 (EPSG:7856) \nsource      : SEQ_future_bioclim.2090.SSP370.tif \nnames       : BIO1_~_Temp, BIO2_~Range, BIO3_~ality, BIO4_~ality, BIO5_~Month, BIO6_~Month, ... \nmin values  :    19.07255,     6.59230,    38.32245,    301.0822,    28.04017,    6.774293, ... \nmax values  :    24.52122,    14.53494,    50.96117,    530.5290,    37.41868,   15.740561, ... \n\n\nCode\ncovs_future_SSP370 &lt;- terra::mask(covs_future_SSP370, covs_current) # Crop to SEQ extent using current layers\n\ncovs_future_SSP370_expert &lt;- subset(covs_future_SSP370, \n                                    names(covs_future_SSP370) %in% c(\"BIO5_Max_Temp_Warmest_Month\",\n                                                                     \"BIO6_Min_Temp_Coldest_Month\",\n                                                                     \"BIO12_Annual_Precipitation\",\n                                                                     \"BIO15_Precip_Seasonality\"))",
    "crumbs": [
      "Session 3",
      "ICCB Species distribution modelling"
    ]
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#plot-the-future-rasters",
    "href": "Session 3/ICCB_Modelling_and_validation.html#plot-the-future-rasters",
    "title": "ICCB Species distribution modelling",
    "section": "Plot the future rasters",
    "text": "Plot the future rasters\n\n\nCode\nplot(covs_future_SSP370_expert)\n\n\n\n\n\n\n\n\n\n\nCompare the current and future rasters\n\n\nCode\nplot(covs_future_SSP370_expert - covs_current_expert)",
    "crumbs": [
      "Session 3",
      "ICCB Species distribution modelling"
    ]
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#test-the-environmental-distance-between-current-data-and-future-conditions",
    "href": "Session 3/ICCB_Modelling_and_validation.html#test-the-environmental-distance-between-current-data-and-future-conditions",
    "title": "ICCB Species distribution modelling",
    "section": "Test the environmental distance between current data and future conditions",
    "text": "Test the environmental distance between current data and future conditions\n\n\nCode\nmess &lt;- predicts::mess(covs_future_SSP370_expert,\n                       train_PB_covs_thinned[, c(\"BIO5_Max_Temp_Warmest_Month\",\n                                                 \"BIO6_Min_Temp_Coldest_Month\",\n                                                 \"BIO12_Annual_Precipitation\",\n                                                 \"BIO15_Precip_Seasonality\")])\n\nplot(mess)\n\n\n\n\n\n\n\n\n\nCode\nr_mess_mask &lt;- mess &lt; 0\nplot(r_mess_mask)\n\n\n\n\n\n\n\n\n\nTest which areas you might mask out because they are ‘novel’ in environmental space and therefore require model extrapolation.\n\n\nCode\nanalog_fut &lt;- predicted_current\n\nvalues(analog_fut)[values(mess)&lt;0] &lt;- NA\n\nplot(analog_fut,\n     range = c(0, 1),  # Set min and max values for the color scale\n     main = \"Koala relative occurrence in regions with analogue conditions\")\n\n\n\n\n\n\n\n\n\nCode\nnovel_fut &lt;- predicted_current\n\nvalues(novel_fut)[values(mess)&gt;0] &lt;- NA\n\nplot(novel_fut,\n     range = c(0, 1),  # Set min and max values for the color scale\n     main = \"Koala relative occurrence in regions with novel conditions\")",
    "crumbs": [
      "Session 3",
      "ICCB Species distribution modelling"
    ]
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#scale-future-layers-and-add-human-footprint",
    "href": "Session 3/ICCB_Modelling_and_validation.html#scale-future-layers-and-add-human-footprint",
    "title": "ICCB Species distribution modelling",
    "section": "Scale future layers and add human footprint",
    "text": "Scale future layers and add human footprint\n\n\nCode\n# Scale the future covariates using the same scaling parameters as the training data\ncovs_future_SSP370_expert_scaled &lt;- scale(covs_future_SSP370_expert, \n                                   center = attr(scaled_covariates, \"scaled:center\")[-5],\n                                   scale = attr(scaled_covariates, \"scaled:scale\")[-5])\n\n# Add the human footprint layer to the future covariates\ncovs_future_SSP370_expert_HF_scaled &lt;- c(covs_future_SSP370_expert_scaled, constant_HF)",
    "crumbs": [
      "Session 3",
      "ICCB Species distribution modelling"
    ]
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#make-projections",
    "href": "Session 3/ICCB_Modelling_and_validation.html#make-projections",
    "title": "ICCB Species distribution modelling",
    "section": "Make projections",
    "text": "Make projections\n\n\nCode\n# Predict the presence probability across the entire raster extent\npredicted_future370 &lt;- predict(covs_future_SSP370_expert_HF_scaled, glm_model, type = \"response\")\n\n# Plot the species distribution raster\nplot(\n  predicted_future370,\n  range = c(0, 1),  # Set min and max values for the color scale\n  main = \"Climatic Suitability of Koalas - Future(SSP370)\"\n)\n\n\n\n\n\n\n\n\n\nCode\n# Save the plot as a png\npng(filename=\"Outputs/GLM_outputs/predicted_future370.png\",\n    width = 150, height = 130, units = \"mm\", res = 600)\nplot(predicted_future370,\n  range = c(0, 1),  # Set min and max values for the color scale\n  main = \"Climatic Suitability of Koalas - Future(SSP370)\")\ndev.off()\n\n\nquartz_off_screen \n                2 \n\n\nCode\n# Write the raster to file\nwriteRaster(predicted_future370, \"Outputs/GLM_outputs/predicted_future370.tif\", overwrite = TRUE)",
    "crumbs": [
      "Session 3",
      "ICCB Species distribution modelling"
    ]
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#show-the-predictions-side-by-side",
    "href": "Session 3/ICCB_Modelling_and_validation.html#show-the-predictions-side-by-side",
    "title": "ICCB Species distribution modelling",
    "section": "Show the predictions side-by-side",
    "text": "Show the predictions side-by-side\n\n\nCode\npar(mfrow = c(1, 2))\n\nplot(\n  predicted_current,\n  range = c(0, 1),\n  main = \"Current\"\n)\n\nplot(\n  predicted_future370,\n  range = c(0, 1),\n  main = \"Future (SSP 3.70)\"\n)",
    "crumbs": [
      "Session 3",
      "ICCB Species distribution modelling"
    ]
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#plot-the-different-between-current-and-future",
    "href": "Session 3/ICCB_Modelling_and_validation.html#plot-the-different-between-current-and-future",
    "title": "ICCB Species distribution modelling",
    "section": "Plot the different between current and future",
    "text": "Plot the different between current and future\nRed is less suitable in the Future SSP370 scenario, and blue is more suitable in the Future SSP370 scenario.\n\n\nCode\n# return to single plotting\npar(mfrow = c(1, 1))\n\n# Create symmetric breaks centered at 0\nbreaks &lt;- seq(-1, 1, length.out = 101)\n\n# Create the color palette\ncols &lt;- colorRampPalette(c(\"red\", \"white\", \"blue\"))(100)\n\n\nplot(predicted_future370 - predicted_current,\n     main = \"Future (SSP370) - Current Predictions \",\n     col = cols,\n     range = c(-1, 1))\n\n\n\n\n\n\n\n\n\nCode\n# Save the plot as a png\npng(filename=\"Outputs/GLM_outputs/future370-current.png\",\n    width = 150, height = 130, units = \"mm\", res = 600)\nplot(predicted_future370 - predicted_current,\n     main = \"Future (SSP370) - Current Predictions \",\n     col = cols,\n     range = c(-1, 1))\ndev.off()\n\n\nquartz_off_screen \n                2 \n\n\nCode\n# Write the raster to file\nwriteRaster(predicted_future370 - predicted_current, \n            \"Outputs/GLM_outputs/future370-current.tif\", overwrite = TRUE)",
    "crumbs": [
      "Session 3",
      "ICCB Species distribution modelling"
    ]
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#presenting-predictions-with-uncertainty",
    "href": "Session 3/ICCB_Modelling_and_validation.html#presenting-predictions-with-uncertainty",
    "title": "ICCB Species distribution modelling",
    "section": "Presenting predictions with uncertainty",
    "text": "Presenting predictions with uncertainty\nThere are many sources of model uncertainty that should be explored and ideally, presented alongside model predictions.\nOne that we’ll focus on here is climate scenario uncertainty. We do so by fitting a second model to future climate data from a lower emission shared socioeconomic path scenario (SSP 1.26).",
    "crumbs": [
      "Session 3",
      "ICCB Species distribution modelling"
    ]
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#load-future-environmental-data-ssp-1.26",
    "href": "Session 3/ICCB_Modelling_and_validation.html#load-future-environmental-data-ssp-1.26",
    "title": "ICCB Species distribution modelling",
    "section": "Load future environmental data (SSP 1.26)",
    "text": "Load future environmental data (SSP 1.26)\n\n\nCode\ncovs_future_SSP126 &lt;- rast(\"Data/Environmental_variables/SEQ_future_bioclim.2090.SSP126.tif\")\nnames(covs_future_SSP126) &lt;- layer_names\ncovs_future_SSP126\n\n\nclass       : SpatRaster \ndimensions  : 44, 51, 19  (nrow, ncol, nlyr)\nresolution  : 5590.925, 5590.925  (x, y)\nextent      : 271609.2, 556746.4, 6862081, 7108082  (xmin, xmax, ymin, ymax)\ncoord. ref. : GDA2020 / MGA zone 56 (EPSG:7856) \nsource      : SEQ_future_bioclim.2090.SSP126.tif \nnames       : BIO1_~_Temp, BIO2_~Range, BIO3_~ality, BIO4_~ality, BIO5_~Month, BIO6_~Month, ... \nmin values  :    17.11955,    6.654293,    39.11226,    298.1248,    26.08138,     3.96662, ... \nmax values  :    22.42196,   14.853741,    51.27921,    546.6645,    35.57761,    13.50076, ... \n\n\nCode\ncovs_future_SSP126_expert &lt;- subset(covs_future_SSP126, names(covs_future_SSP126) %in% c(\"BIO5_Max_Temp_Warmest_Month\",\n                                                                                          \"BIO6_Min_Temp_Coldest_Month\",\n                                                                                          \"BIO12_Annual_Precipitation\",\n                                                                                          \"BIO15_Precip_Seasonality\"))\n\nplot(covs_future_SSP126_expert) # to plot the layers\n\n\n\n\n\n\n\n\n\n\nPlot the difference between the two future scenarios\nThis is SSP370 - SSP126, so positive values indicate that the SSP370 scenario has higher values than the SSP126 scenario.\n\n\nCode\nterra::plot(covs_future_SSP370_expert - covs_future_SSP126_expert)",
    "crumbs": [
      "Session 3",
      "ICCB Species distribution modelling"
    ]
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#glm-future-predictions-ssp-1.26",
    "href": "Session 3/ICCB_Modelling_and_validation.html#glm-future-predictions-ssp-1.26",
    "title": "ICCB Species distribution modelling",
    "section": "GLM future predictions (SSP 1.26)",
    "text": "GLM future predictions (SSP 1.26)\n\n\nCode\n# Scale the future covariates using the same scaling parameters as the training data\ncovs_future_SSP126_expert_scaled &lt;- scale(covs_future_SSP126_expert, \n                                   center = attr(scaled_covariates, \"scaled:center\")[-5],\n                                   scale = attr(scaled_covariates, \"scaled:scale\")[-5])\n\n# Add the human footprint layer to the future covariates\ncovs_future_SSP126_expert_HF_scaled &lt;- c(covs_future_SSP126_expert_scaled, constant_HF)\n\n# Predict the presence probability across the entire raster extent\npredicted_future126 &lt;- predict(covs_future_SSP126_expert_HF_scaled, glm_model, type = \"response\")\n\n# Plot the species distribution raster\nplot(\n  predicted_future126,\n  range = c(0, 1),  # Set min and max values for the color scale\n  main = \"Climatic Suitability of Koalas - Future(SSP126)\"\n)\n\n\n\n\n\n\n\n\n\nCode\n# Save the plot as a png\npng(filename=\"Outputs/GLM_outputs/predicted_future126.png\",\n    width = 150, height = 130, units = \"mm\", res = 600)\nplot(predicted_future126,\n  range = c(0, 1),  # Set min and max values for the color scale\n  main = \"Climatic Suitability of Koalas - Future(SSP126)\")\ndev.off()\n\n\nquartz_off_screen \n                2 \n\n\nCode\n# Write the raster to file\nwriteRaster(predicted_future370, \"Outputs/GLM_outputs/predicted_future126.tif\", overwrite = TRUE)",
    "crumbs": [
      "Session 3",
      "ICCB Species distribution modelling"
    ]
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#plot-the-different-between-current-and-future-ssp126",
    "href": "Session 3/ICCB_Modelling_and_validation.html#plot-the-different-between-current-and-future-ssp126",
    "title": "ICCB Species distribution modelling",
    "section": "Plot the different between current and future (SSP126)",
    "text": "Plot the different between current and future (SSP126)\nRed is less suitable in the Future SSP126 scenario, and blue is more suitable in the Future SSP126 scenario.\n\n\nCode\n# return to single plotting\npar(mfrow = c(1, 1))\n\n# Create symmetric breaks centered at 0\nbreaks &lt;- seq(-1, 1, length.out = 101)\n\n# Create the color palette\ncols &lt;- colorRampPalette(c(\"red\", \"white\", \"blue\"))(100)\n\n\nplot(predicted_future126 - predicted_current,\n     main = \"Future (SSP126) - Current Predictions \",\n     col = cols,\n     range = c(-1, 1))\n\n\n\n\n\n\n\n\n\nCode\n# Save the plot as a png\npng(filename=\"Outputs/GLM_outputs/future126-current.png\",\n    width = 150, height = 130, units = \"mm\", res = 600)\nplot(predicted_future126 - predicted_current,\n     main = \"Future (SSP126) - Current Predictions \",\n     col = cols,\n     range = c(-1, 1))\ndev.off()\n\n\nquartz_off_screen \n                2 \n\n\nCode\n# Write the raster to file\nwriteRaster(predicted_future126 - predicted_current, \n            \"Outputs/GLM_outputs/future126-current.tif\", overwrite = TRUE)",
    "crumbs": [
      "Session 3",
      "ICCB Species distribution modelling"
    ]
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#compare-the-two-future-predictions",
    "href": "Session 3/ICCB_Modelling_and_validation.html#compare-the-two-future-predictions",
    "title": "ICCB Species distribution modelling",
    "section": "Compare the two future predictions",
    "text": "Compare the two future predictions\n\n\nCode\npar(mfrow = c(1, 2))\n\n# Plot the predicted suitability \nplot(\n  predicted_future126,\n  range = c(0,1),\n  main = \"Suitability SSP126\"\n)\n\nplot(\n  predicted_future370,\n  range = c(0,1),\n  main = \"Suitability SSP370\"\n)",
    "crumbs": [
      "Session 3",
      "ICCB Species distribution modelling"
    ]
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#plot-the-different-between-the-two-future-predictions",
    "href": "Session 3/ICCB_Modelling_and_validation.html#plot-the-different-between-the-two-future-predictions",
    "title": "ICCB Species distribution modelling",
    "section": "Plot the different between the two future predictions",
    "text": "Plot the different between the two future predictions\nRed is less suitable in the Future SSP370 scenario than the SSP126 scenario, and blue is more suitable in Future SSP370 scenario than the SSP126 scenario.\n\n\nCode\n# return to single plotting\npar(mfrow = c(1, 1))\n\n# Create symmetric breaks centered at 0\nbreaks &lt;- seq(-1, 1, length.out = 101)\n\n# Create the color palette\ncols &lt;- colorRampPalette(c(\"red\", \"white\", \"blue\"))(100)\n\n\nplot(predicted_future370 - predicted_future126,\n     main = \"Future (SSP370) - Future (SSP126) Predictions \",\n     col = cols,\n     range = c(-1, 1))\n\n\n\n\n\n\n\n\n\nCode\n# Save the plot as a png\npng(filename=\"Outputs/GLM_outputs/future370-future126.png\",\n    width = 150, height = 130, units = \"mm\", res = 600)\nplot(predicted_future370 - predicted_future126,\n     main = \"Future (SSP370) - Future (SSP126) Predictions \",\n     col = cols,\n     range = c(-1, 1))\ndev.off()\n\n\nquartz_off_screen \n                2 \n\n\nCode\n# Write the raster to file\nwriteRaster(predicted_future370 - predicted_future126, \n            \"Outputs/GLM_outputs/future370-future126.tif\", overwrite = TRUE)",
    "crumbs": [
      "Session 3",
      "ICCB Species distribution modelling"
    ]
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#model-uncertainty",
    "href": "Session 3/ICCB_Modelling_and_validation.html#model-uncertainty",
    "title": "ICCB Species distribution modelling",
    "section": "Model uncertainty",
    "text": "Model uncertainty\nAnother element of uncertainty that can be represented is model uncertainty, or the standard error around the coefficient estimates.\n\n\nCode\n# Extract standard errors of coefficients\ncoef_se &lt;- summary(glm_model)$coefficients[, \"Std. Error\"]\nprint(coef_se)\n\n\n                (Intercept) BIO5_Max_Temp_Warmest_Month \n                 0.07602152                  0.05579197 \nBIO6_Min_Temp_Coldest_Month  BIO12_Annual_Precipitation \n                 0.07490498                  0.07884380 \n   BIO15_Precip_Seasonality             human_footprint \n                 0.04457251                  0.06801767",
    "crumbs": [
      "Session 3",
      "ICCB Species distribution modelling"
    ]
  },
  {
    "objectID": "Session 3/ICCB_Modelling_and_validation.html#projecting-with-uncertainty",
    "href": "Session 3/ICCB_Modelling_and_validation.html#projecting-with-uncertainty",
    "title": "ICCB Species distribution modelling",
    "section": "Projecting with uncertainty",
    "text": "Projecting with uncertainty\n\n\nCode\ncovs_df &lt;- as.data.frame(covs_future_SSP126_expert_HF_scaled, na.rm = FALSE)\n\npred_link &lt;- predict(glm_model, newdata = covs_df, type = \"link\", se.fit = TRUE)\n\n# Linear predictor (eta)\neta &lt;- pred_link$fit\nse_eta &lt;- pred_link$se.fit\n\n# Confidence intervals (95%)\nz &lt;- 1.96\neta_lower &lt;- eta - z * se_eta\neta_upper &lt;- eta + z * se_eta\n\n# Transform back to response scale\nlinkinv &lt;- glm_model$family$linkinv\npredicted &lt;- linkinv(eta)\nlower_ci &lt;- linkinv(eta_lower)\nupper_ci &lt;- linkinv(eta_upper)\n\n\n# Add to covs_df\ncovs_df$predicted &lt;- predicted\ncovs_df$lower_ci &lt;- lower_ci\ncovs_df$upper_ci &lt;- upper_ci\n\n\npredicted_r &lt;- setValues(rast(covs_future_SSP126_expert_HF_scaled, nlyr = 1), predicted)\nlower_ci_r &lt;- setValues(rast(covs_future_SSP126_expert_HF_scaled, nlyr = 1), lower_ci)\nupper_ci_r &lt;- setValues(rast(covs_future_SSP126_expert_HF_scaled, nlyr = 1), upper_ci)\n\n# Step 2: Name the layers\nnames(predicted_r) &lt;- \"SSP126 Mean Estimate\"\nnames(lower_ci_r) &lt;- \"SSP126 Lower CI\"\nnames(upper_ci_r) &lt;- \"SSP126 Upper CI\"\n\nprediction_w_uncertainty &lt;- c(predicted_r, lower_ci_r, upper_ci_r)\n\nplot(prediction_w_uncertainty, range = c(0, 1))",
    "crumbs": [
      "Session 3",
      "ICCB Species distribution modelling"
    ]
  },
  {
    "objectID": "Session 2/session_2_home.html",
    "href": "Session 2/session_2_home.html",
    "title": "Session 2",
    "section": "",
    "text": "This repository has all of the scripts and data for the ICCB 2025 workshop ‘Using downscaled climate projections in R’. The powerpoint slides include instructions for running through the scripts and pictures of what the output should look like.\n\n\nWe have provided data for three downscaled climate models. These models were downscaled from the CMIP6 GCMs (Global Climate Models) using the CCAM model to a 10km resolution over Australia. The model name refers to the CMIP6 GCM which acted as the host model and provided input to CCAM. Further information on the downscaling technique is available in Chapman et al. (2023) and information on the climate change impacts shown in these models is available in Chapman et al. (2024).\nWe have selected three models which represent the span from the full ensemble (set of all downscaled climate models):\n\nACCESS-ESM1-5 r6i1p1f1 - dry model\nEC-Earth3 r1i1p1f1 - wet model\nGFDL-ESM4 r1i1p1f1 - this model is close to the ensemble average for both temperature and precipitation changes at the end of the century\n\nWe have provided data for three climate change scenarios:\n\nSSP126 - a low emission pathway, with on average 2°C of global warming at the end of century compared to pre-industrial times.\nSSP245 - a medium emission pathway, with on average 3°C of warming.\nSSP370 - a high emission pathway, with on average 4°C of warming.\n\nNote that there can be a great deal of variation within a model ensemble, and for each scenario there will be models that are warmer or cooler than the ensemble average.\n\n\n\n\nannual: annual average precipitation (mm/day) and temperature (celsius) for 1981 - 2100 for Queensland.\n\nmonthly: monthly pr (mm/day), tasmax and tasmin (celsius) for 1981 - 2100 for South-East Queensland.\n\nobs: observational data from the Australian Gridded Climate Dataset (AGCD). Variables include daily maximum and minimum temperature and precipitation for 1981 - 2020 at a 5km resolution. See Jones et al (2009) for further details.\n\nshp: Shapefiles for Queensland and the Sunshine Coast.\n\n\n\n\n\nICCB_Training.R: the training script. This is what will be used in the workshop.\n\nICCB_Training_complete.R: the training script with additional examples. Try not to look at these until you’ve had a go yourself!\n\nThe remaining scripts in this folder were used to prepare the workshop data and are included for interest only.\n\n\n\nFurther information on the models and datasets used here can be found in the following papers:\nChapman, S., Syktus, J., Trancoso, R., Thatcher, M., Toombs, N., Wong, K. K.-H., & Takbash, A. (2023). Evaluation of Dynamically Downscaled CMIP6-CCAM Models Over Australia. Earth’s Future, 11(11), e2023EF003548. https://doi.org/10.1029/2023EF003548\nChapman, S., Syktus, J., Trancoso, R., Toombs, N., & Eccles, R. (2024). Projected changes in mean climate and extremes from downscaled high-resolution CMIP6 simulations in Australia. Weather and Climate Extremes, 46, 100733. https://doi.org/10.1016/j.wace.2024.10073\nJones, D. A., Wang, W., & Fawcett, R. (2009). High-quality spatial climate data-sets for Australia. Australian Meteorlogical and Oceangraphic Journal, 58, 233–248.\n\n\n\nDownload a PDF of the slides",
    "crumbs": [
      "Session 2"
    ]
  },
  {
    "objectID": "Session 2/session_2_home.html#models-and-climate-change-scenarios",
    "href": "Session 2/session_2_home.html#models-and-climate-change-scenarios",
    "title": "Session 2",
    "section": "",
    "text": "We have provided data for three downscaled climate models. These models were downscaled from the CMIP6 GCMs (Global Climate Models) using the CCAM model to a 10km resolution over Australia. The model name refers to the CMIP6 GCM which acted as the host model and provided input to CCAM. Further information on the downscaling technique is available in Chapman et al. (2023) and information on the climate change impacts shown in these models is available in Chapman et al. (2024).\nWe have selected three models which represent the span from the full ensemble (set of all downscaled climate models):\n\nACCESS-ESM1-5 r6i1p1f1 - dry model\nEC-Earth3 r1i1p1f1 - wet model\nGFDL-ESM4 r1i1p1f1 - this model is close to the ensemble average for both temperature and precipitation changes at the end of the century\n\nWe have provided data for three climate change scenarios:\n\nSSP126 - a low emission pathway, with on average 2°C of global warming at the end of century compared to pre-industrial times.\nSSP245 - a medium emission pathway, with on average 3°C of warming.\nSSP370 - a high emission pathway, with on average 4°C of warming.\n\nNote that there can be a great deal of variation within a model ensemble, and for each scenario there will be models that are warmer or cooler than the ensemble average.",
    "crumbs": [
      "Session 2"
    ]
  },
  {
    "objectID": "Session 2/session_2_home.html#data",
    "href": "Session 2/session_2_home.html#data",
    "title": "Session 2",
    "section": "",
    "text": "annual: annual average precipitation (mm/day) and temperature (celsius) for 1981 - 2100 for Queensland.\n\nmonthly: monthly pr (mm/day), tasmax and tasmin (celsius) for 1981 - 2100 for South-East Queensland.\n\nobs: observational data from the Australian Gridded Climate Dataset (AGCD). Variables include daily maximum and minimum temperature and precipitation for 1981 - 2020 at a 5km resolution. See Jones et al (2009) for further details.\n\nshp: Shapefiles for Queensland and the Sunshine Coast.",
    "crumbs": [
      "Session 2"
    ]
  },
  {
    "objectID": "Session 2/session_2_home.html#scripts",
    "href": "Session 2/session_2_home.html#scripts",
    "title": "Session 2",
    "section": "",
    "text": "ICCB_Training.R: the training script. This is what will be used in the workshop.\n\nICCB_Training_complete.R: the training script with additional examples. Try not to look at these until you’ve had a go yourself!\n\nThe remaining scripts in this folder were used to prepare the workshop data and are included for interest only.",
    "crumbs": [
      "Session 2"
    ]
  },
  {
    "objectID": "Session 2/session_2_home.html#references",
    "href": "Session 2/session_2_home.html#references",
    "title": "Session 2",
    "section": "",
    "text": "Further information on the models and datasets used here can be found in the following papers:\nChapman, S., Syktus, J., Trancoso, R., Thatcher, M., Toombs, N., Wong, K. K.-H., & Takbash, A. (2023). Evaluation of Dynamically Downscaled CMIP6-CCAM Models Over Australia. Earth’s Future, 11(11), e2023EF003548. https://doi.org/10.1029/2023EF003548\nChapman, S., Syktus, J., Trancoso, R., Toombs, N., & Eccles, R. (2024). Projected changes in mean climate and extremes from downscaled high-resolution CMIP6 simulations in Australia. Weather and Climate Extremes, 46, 100733. https://doi.org/10.1016/j.wace.2024.10073\nJones, D. A., Wang, W., & Fawcett, R. (2009). High-quality spatial climate data-sets for Australia. Australian Meteorlogical and Oceangraphic Journal, 58, 233–248.",
    "crumbs": [
      "Session 2"
    ]
  },
  {
    "objectID": "Session 2/session_2_home.html#slides",
    "href": "Session 2/session_2_home.html#slides",
    "title": "Session 2",
    "section": "",
    "text": "Download a PDF of the slides",
    "crumbs": [
      "Session 2"
    ]
  },
  {
    "objectID": "Session 2/data/shp/QLD_State_Mask.html",
    "href": "Session 2/data/shp/QLD_State_Mask.html",
    "title": "ICCB - Open Geospatial Tools",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;  Mainland  ENG dataset\n\nMainlands - Queensland\n\nThis dataset depicts the land extent of continental Queensland. The boundary of the area shown coincides with theFrameworkBoundaries dataset.\nUSER NOTICE This feature class will be no longer updated after April 26th, 2024. New feature classes have been created to replace it. This feature class will be removed after June 1st without notification. To provide digital data depicting the land extent of continental Queensland for use in land administration, topographic mapping and in the production of navigational and web based mapping applications.  Queensland coastline mean high water state border mainland BOUNDARIES coastline mean high water state border mainland   BOUNDARIES    \n\n\n  &lt;city&gt;&lt;/city&gt;\n  &lt;administrativearea&gt;&lt;/administrativearea&gt;\n  &lt;postalcode&gt;&lt;/postalcode&gt;\n  &lt;country&gt;&lt;/country&gt;\n&lt;/contactAddress&gt;\n&lt;name&gt;Resources, Georesources, SI, SD, SDM, Senior Spatial Information Officer&lt;/name&gt;\n&lt;organization&gt;Department of Resources&lt;/organization&gt;\n&lt;position&gt;Senior Spatial Information Officer, Spatial Data Management, Spatial Data, Spatial Information&lt;/position&gt;\n&lt;voice&gt;(07) 3330 4738&lt;/voice&gt;\n&lt;fax&gt;&lt;/fax&gt;\n&lt;email&gt;SIIMTopoDataManagement@resources.qld.gov.au&lt;/email&gt;\n&lt;role&gt;Point of contact&lt;/role&gt;\n    This dataset is GDA2020 compatible. The source data, and therefore the captured features, are georeferenced as GDA94 (horizontal only). The horizontal accuracy of the geo-referencing and/or data collection method for this example is greater than the datum offset between GDA94 and GDA2020 (1.8 meters). The resulting dataset has been nominated as a low-accuracy GDA2020 dataset. As this data has not been directly captured in GDA2020, nor transformed to GDA2020, the resulting data is ‘GDA2020 Compatible’ not ‘GDA2020 Compliant’. This dataset was derived from and is coincident with the FrameworkBoundaries_Queensland dataset. Within the FrameworkBoundaries_Queensland dataset., the coastline was digitized from the most current imagery by defining mean high water from sand coloration and debris lines. Where available, the highest astronomical tide line generated from LiDAR was used to help define the line. Were the line is obscured by vegetation, in particular mangroves; the seaward edge of the vegetation is adopted. The coastline feature does not cross the entrances to large inland waterbodies. In these instances, a feature type Junction is used to seamlessly connect the coastline. The state border was captured and coincides with the position as shown by the Queensland Digital Cadastral Database, Feature Types: Mainland - The area of continental Queensland. Data source: Queensland Digital Cadastral Database  Features have been captured or updated from the best available imagery or data sources, with an attribute within the data describing the source and reliability. Unrestricted to all levels of government and community. Data is available to all government agencies, community groups and individuals. Dataset is available through physical supply and may be made available via web delivery tools, for example, through DNRME’s internet sites. The State of Queensland (Department of Resources) � State of Queensland (Department of Resources) 2023 This material is licensed under a Creative Commons - Attribution 4.0 International licence. ? The Department of Resources requests attribution in the following manner: � State of Queensland (Department of Resources) 2021. Updated data available at http://qldspatial.information.qld.gov.au/catalogue/ .    GEOGCRS[“GDA94”,DATUM[“Geocentric Datum of Australia 1994”,ELLIPSOID[“GRS 1980”,6378137,298.257222101,LENGTHUNIT[“metre”,1]]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“Australia including Lord Howe Island, Macquarie Island, Ashmore and Cartier Islands, Christmas Island, Cocos (Keeling) Islands, Norfolk Island. All onshore and offshore.”],BBOX[-60.55,93.41,-8.47,173.34]],ID[“EPSG”,4283]] +proj=longlat +ellps=GRS80 +no_defs 3415 4283 EPSG:4283 GDA94 longlat EPSG:7019 true       2018-05-21T14:00:00Z           \n\n\n\n Back to top"
  },
  {
    "objectID": "Session 5/docs/part1a-add-data.html",
    "href": "Session 5/docs/part1a-add-data.html",
    "title": "Ref 1a: Add Data",
    "section": "",
    "text": "In this course, we will be using vector and raster spatial data as well as images to complete our poster.\n\n\n\nPoint\n\nPopulation_centres Line\nRivers Polygon\nLocal Government Boundaries\nSEQ boundary\n\n\n\n\nGeotiff\n\ncurrent_distribution_RF_1.tiff\n\n\n\n\nImages\n\nkoala_1.jpeg\nqld_tas_changes.png\nqld_tas_fut.png\nqld_tas_hist.png\nscenario_3_lock_in.png\n\nAll text for the captions can be found in the content.txt",
    "crumbs": [
      "Session 5",
      "Ref 1a: Add Data"
    ]
  },
  {
    "objectID": "Session 5/docs/part1a-add-data.html#data-types",
    "href": "Session 5/docs/part1a-add-data.html#data-types",
    "title": "Ref 1a: Add Data",
    "section": "",
    "text": "In this course, we will be using vector and raster spatial data as well as images to complete our poster.\n\n\n\nPoint\n\nPopulation_centres Line\nRivers Polygon\nLocal Government Boundaries\nSEQ boundary\n\n\n\n\nGeotiff\n\ncurrent_distribution_RF_1.tiff\n\n\n\n\nImages\n\nkoala_1.jpeg\nqld_tas_changes.png\nqld_tas_fut.png\nqld_tas_hist.png\nscenario_3_lock_in.png\n\nAll text for the captions can be found in the content.txt",
    "crumbs": [
      "Session 5",
      "Ref 1a: Add Data"
    ]
  },
  {
    "objectID": "Session 5/docs/part1a-add-data.html#loading-data",
    "href": "Session 5/docs/part1a-add-data.html#loading-data",
    "title": "Ref 1a: Add Data",
    "section": "Loading data",
    "text": "Loading data\nLoading data can occur in multiple ways. For this course, we will use the Browser and the Data Source Manager.\nOne of the important aspects to an efficient mapping product, is keeping it tidy. A way to do this is to create Groups in the Layers panel.\n\n&gt; - Create the above groups in the layers panel by right mouse clicking in the layer panel and selecting Add group. &gt; \n\nBrowser\nAccessing the data via the Browser panel, we will add the data to the groups. &gt; - Ensure you have the Browser panel open.\n&gt; \n&gt; - At the top of the Browser, click on the arrow next to Project Home to expand it\n&gt; \n&gt; - Expand the Data folder\nWe are going to select multiple files and load them under the group headings &gt; - First, in the Layers panel, click on the group ‘Original data’\n&gt; \n&gt; - Then head over to the Browser panel and whilst holding down the ctrl key, click on ‘current_distribution_RF_1.tif’, and the ‘seq_boundary’ (in the geopackage)\n&gt; - With all of these selected, click on the Add selected layer button at the top of the Browser panel\n&gt; \n&gt; - This results in layers nested under the ‘Original data’ group\n&gt; \n\n\nData source manager\nWe are going to access some data now from the service we have loaded. We can use the Browser panel to do so, but to select data that only occurs in the map extent. In this instance, our Area of Interest - South East Queensland.\n&gt; - In the Layers panel, select turn on the ‘seq_boundary’ layer\n&gt; - Right mouse click on the layer and select Zoom to layer\n&gt; - Click on the Open Data Source Manager' button   &gt; ![Browser panel](../media/data-source-manager.png)   &gt; - On the left hand side of theData Source Managerscroll down until you see the ArcGIS REST Server and click on it   &gt; - On the right hand side, click the drop down and select 'QLD' (or whatever you named the Qld Spatial Government service)   &gt; - Click onConnect&gt; - Click on Boundaries &gt; AdminBoundariesFramework &gt; Local Government area (you will need to scroll down quite a bit) &gt; - TickOnly request features overlapping the current view extent&gt; - Click onAdd`\n&gt;\nWe won’t close this yet as we need to add in watercourses.\n\n\nAbove the layer list, there is a search bar, type in ‘water’, we are looking for polyline dataset for a river\n\nExpand ‘Inland River’ and select ‘WatercourseIdentificationMap’ &gt; ‘Watercourse’ \nClick Add with Filter\n\nThe Expression Builder will come up. Add in the following \"name\" is NOT NULL and click on OK \nClick Add, then Close\nTurn off the watercourse dataset as we do not need it at the moment.\n\n\nNow add in Population centres using the Data source manager - but be careful to select only those covering the extent.\n- It is in the QLD service under Location &gt; Places\n- Use the search function to find it quickly",
    "crumbs": [
      "Session 5",
      "Ref 1a: Add Data"
    ]
  },
  {
    "objectID": "Session 5/docs/part1-styling-data.html",
    "href": "Session 5/docs/part1-styling-data.html",
    "title": "Part 1: Styling Data",
    "section": "",
    "text": "Loading data can occur in multiple ways. For this course, we will use the Browser and the Data Source Manager.\nOne of the important aspects to an efficient mapping product, is keeping it tidy. A way to do this is to create Groups in the Layers panel.\n\n&gt; - Create the above groups in the layers panel by right mouse clicking in the layer panel and selecting Add group.\n&gt; \n\n\nAccessing the data via the Browser panel, we will add the data to the groups. &gt; - Ensure you have the Browser panel open.\n&gt; \n&gt; - At the top of the Browser, click on the arrow next to Project Home to expand it\n&gt; \n&gt; - Expand the Data folder\nWe are going to select multiple files and load them under the group headings &gt; - First, in the Layers panel, click on the group ‘Original data’\n&gt; \n&gt; - Then head over to the Browser panel and expand the data folder.\nWe want to select multiple files and load them into the ‘Original data’ group. We can do this by holding down the ctrl key whilst clicking on multiple the files. &gt; - Hold down the ctrlkey, and click on the following files &gt; - ‘current_distribution_RF_1.tif’\n&gt; - Expand the geopackage and click on all the layers*\n&gt; - With all of these selected, click on the Add selected layer button at the top of the Browser panel\n&gt; \n&gt; - This results in layers nested under the ‘Original data’ group\n&gt; \n&gt; - Turn off the layers, population_centres and watercourse\n&gt; - Save your project\nN.B. The layers in the geopackage have been extracted from the ArcGIS REST Service from the Queensland Government. Refer to Ref A - Add Data for step by step instructions for other methods.\nNearly there with the data, we just need to add in a basemap.\n&gt; - In the Layers panel, click on the group ‘Base’\n&gt; - In the Browser, under XYZ Tiles, click on ‘Qld Imagery’\n&gt; - Click on the Add selected layer button at the top of the Browser panel\nNext, we are going to add in the picture of the Koala. We are doing this as we want to be a little bit clever for some tricks later on. Usually we would just add the picture to the Print Layout. &gt; - In the Layers panel, click on the group ‘Decorations’ &gt; - In the Browser, under the ‘Data’ folder, click on koala_1.jpeg &gt; - Click on the Add selected layer button at the top of the Browser panel &gt; - Save your project",
    "crumbs": [
      "Session 5",
      "Part 1: Styling Data"
    ]
  },
  {
    "objectID": "Session 5/docs/part1-styling-data.html#loading-data",
    "href": "Session 5/docs/part1-styling-data.html#loading-data",
    "title": "Part 1: Styling Data",
    "section": "",
    "text": "Loading data can occur in multiple ways. For this course, we will use the Browser and the Data Source Manager.\nOne of the important aspects to an efficient mapping product, is keeping it tidy. A way to do this is to create Groups in the Layers panel.\n\n&gt; - Create the above groups in the layers panel by right mouse clicking in the layer panel and selecting Add group.\n&gt; \n\n\nAccessing the data via the Browser panel, we will add the data to the groups. &gt; - Ensure you have the Browser panel open.\n&gt; \n&gt; - At the top of the Browser, click on the arrow next to Project Home to expand it\n&gt; \n&gt; - Expand the Data folder\nWe are going to select multiple files and load them under the group headings &gt; - First, in the Layers panel, click on the group ‘Original data’\n&gt; \n&gt; - Then head over to the Browser panel and expand the data folder.\nWe want to select multiple files and load them into the ‘Original data’ group. We can do this by holding down the ctrl key whilst clicking on multiple the files. &gt; - Hold down the ctrlkey, and click on the following files &gt; - ‘current_distribution_RF_1.tif’\n&gt; - Expand the geopackage and click on all the layers*\n&gt; - With all of these selected, click on the Add selected layer button at the top of the Browser panel\n&gt; \n&gt; - This results in layers nested under the ‘Original data’ group\n&gt; \n&gt; - Turn off the layers, population_centres and watercourse\n&gt; - Save your project\nN.B. The layers in the geopackage have been extracted from the ArcGIS REST Service from the Queensland Government. Refer to Ref A - Add Data for step by step instructions for other methods.\nNearly there with the data, we just need to add in a basemap.\n&gt; - In the Layers panel, click on the group ‘Base’\n&gt; - In the Browser, under XYZ Tiles, click on ‘Qld Imagery’\n&gt; - Click on the Add selected layer button at the top of the Browser panel\nNext, we are going to add in the picture of the Koala. We are doing this as we want to be a little bit clever for some tricks later on. Usually we would just add the picture to the Print Layout. &gt; - In the Layers panel, click on the group ‘Decorations’ &gt; - In the Browser, under the ‘Data’ folder, click on koala_1.jpeg &gt; - Click on the Add selected layer button at the top of the Browser panel &gt; - Save your project",
    "crumbs": [
      "Session 5",
      "Part 1: Styling Data"
    ]
  },
  {
    "objectID": "Session 5/docs/part1-styling-data.html#styling",
    "href": "Session 5/docs/part1-styling-data.html#styling",
    "title": "Part 1: Styling Data",
    "section": "Styling",
    "text": "Styling\nNow it is time to style the:\n- Koala distribution: ‘current_distribution_RF_1.tif’\n- LGA: local_government_area\n- Mask: seq_boundary\n\nCreate a Palette\nWe all consume branding everyday and choosing a palette of colors is a part of it. Artists will also look to a set of colors, a palette, to help harmonise their work. So let’s create a palette from the Koala picture you have.\n&gt; - In the Layers panel, expand the ‘Decorations’ group\n&gt; - Right mouse click on the ’koala_1.jpeg’and click on Zoom to layers\n&gt; - On the top menu, click on Settings &gt; Options'   &gt; - In theOptions, selectColorson the left side   &gt;  ![palette](../media/palette3.png)   &gt; - Click on the drop down where it says *Standard colors* and select *Project colors*   &gt; - Click on the green plus button to bring up theSelect colordialog &gt; ![palette_sample](../media/palette_sample.png)   &gt; - Click on theSamplingtab   &gt; - To start collecting the colors for the palette click theSample colorbutton   &gt; - Let's start with a light grey first, so click the background of the koala image to pick up the grey and clickOK`\n&gt;  &gt; - Save your project\nThe grey now appears in the palette. you can change the label it you want. Repeat the above to capture the following: - Browns from the trunk - Greens from the leaves - Greys from the fur and nose - Pinks from the fur &gt; \n&gt; - click OK\n&gt; - Save your project\nThese project colors are now built into this project file. They will appear when you go to the palette option to select colors.\n\n\nAOI Map\nFirst, we are going to create our “AOI” map - our area of interest. For this we will want the following datasets turned on:\n- Mask: seq_boundary\n- LGA: local_government_area\n- Qld Imagery\n\nCreate the Mask\n\n\nUnder ‘Original data’ turn on the layer seq_boundary and zoom to it (right mouse click)\nRight mouse click on it and select Duplicate Layer\n\nMove this layer to the sit under the ‘Mask’ group\n\nRename it to AOI (right mouse click &gt; Rename Layer) and click on it so it becomes the Active layer\n\nRight mouse click anywhere in a blank area on the toolbar at the top and select Panels &gt; Layer Styling Panel\n\n\nIn the Layer Styling panel, select from the drop down `Inverted Polygons’\n\nClick on Simple Fill and remove the outline and change the colour to white\n\nSave your project\n\n\nThis is the mask we want for the ‘Island’ look for the Grid data, but for the AOI, we want to still see the surrounds so it helps us get our bearings. To do this, we are going to create an additional style for the AOI layer.\n\n\nRight mouse click on the AOI Layer and click Styles &gt; Add. Call this ‘AOI’\n\n\nIn the Layers Styling panel, click on the Simple Fill and change it to Shapeburst Fill\n\n\nThe Shapeburst Fill is a great effect and can also be used for styling water bodies. But we are going to create a transparent mask so we can still see the aerial image under it &gt; - For the Gradient Colours select the Colour ramp option and click in the color bar to bring up our options.\n&gt; \nWe are going to use the greens from our Project colors palette\n&gt; - For Color 1, select the darkest green you have\n&gt; - For Color 2, select white\n&gt; - Click ok &gt; \n&gt; - Save your project\nLast step for this AOI, we want to make it transparent.\n&gt; - In Layer Styling, at the bottom, expand the Lyaer Rendering options\n&gt; - Nect to Opacity click in the percentage field and make it 66%\n&gt; \nAs you can see here, the QLD Imagery does not extend into the Coral Sea enough, so this is where we may have to replace it with another service. Ensure you have the rights to use it. An easy fix it to set the map property background colour to that of the sea. \nLet’s sort out our LGA’s now with boundaries and some labels.\nBoundaries\n&gt; - Under ‘Original data’ duplicate ‘local_government_area’ and move the dupe into the ‘Context data’ group &gt; - Rename it ‘LGA’ &gt; - In the Layer Styling, click on Simple Fill and change the outline to a light grey (#d9d9d9)\nLabels &gt; - In the Layer Styling, click on the label tab\n&gt; \n&gt; - Select from the dropdown Single Labels\n&gt; - For the value, select ‘abbrev_name’\n&gt; - Select the font ‘Roboto Black’, size 6\n&gt; - For the color, select the same color as the outline - this should be on the palette\n&gt; - Click on the next tab and add in Multiple lines based on spacing\n&gt; - Add a Text Buffer of 0.7\n&gt; - Select a dark color form the Project colors palette",
    "crumbs": [
      "Session 5",
      "Part 1: Styling Data"
    ]
  },
  {
    "objectID": "Session 5/docs/part2-build-map.html",
    "href": "Session 5/docs/part2-build-map.html",
    "title": "Part 2: Build a Beautiful Map",
    "section": "",
    "text": "We will cover:\n- Adding items\n- Rounded frames\n- Adding pictures and other items",
    "crumbs": [
      "Session 5",
      "Part 2: Build a Beautiful Map"
    ]
  },
  {
    "objectID": "Session 5/docs/part2-build-map.html#study-area",
    "href": "Session 5/docs/part2-build-map.html#study-area",
    "title": "Part 2: Build a Beautiful Map",
    "section": "Study Area",
    "text": "Study Area\nSEQ",
    "crumbs": [
      "Session 5",
      "Part 2: Build a Beautiful Map"
    ]
  },
  {
    "objectID": "Session 5/docs/part2-build-map.html#how-will-the-climate-change-in-seq",
    "href": "Session 5/docs/part2-build-map.html#how-will-the-climate-change-in-seq",
    "title": "Part 2: Build a Beautiful Map",
    "section": "How will the climate change in SEQ",
    "text": "How will the climate change in SEQ\nData from the workshop conducted by Sarah Chapman and Rohan Eccles",
    "crumbs": [
      "Session 5",
      "Part 2: Build a Beautiful Map"
    ]
  },
  {
    "objectID": "Session 5/docs/part2-build-map.html#how-could-the-distribution-of-koalas-change-under-this-new-climate.",
    "href": "Session 5/docs/part2-build-map.html#how-could-the-distribution-of-koalas-change-under-this-new-climate.",
    "title": "Part 2: Build a Beautiful Map",
    "section": "How could the distribution of koalas change under this new climate.",
    "text": "How could the distribution of koalas change under this new climate.\nData from the workshop conducted by Scott Forrest and Charlotte Ruby Patterson",
    "crumbs": [
      "Session 5",
      "Part 2: Build a Beautiful Map"
    ]
  },
  {
    "objectID": "Session 5/docs/part2-build-map.html#where-should-we-focus-our-efforts-to-conserve-koalas",
    "href": "Session 5/docs/part2-build-map.html#where-should-we-focus-our-efforts-to-conserve-koalas",
    "title": "Part 2: Build a Beautiful Map",
    "section": "Where should we focus our efforts to conserve koalas",
    "text": "Where should we focus our efforts to conserve koalas\nData from the workshop conducted by Brooke Williams and Caitie Kuempel",
    "crumbs": [
      "Session 5",
      "Part 2: Build a Beautiful Map"
    ]
  },
  {
    "objectID": "Session 5/docs/part2-build-map.html#problem-statement",
    "href": "Session 5/docs/part2-build-map.html#problem-statement",
    "title": "Part 2: Build a Beautiful Map",
    "section": "Problem statement",
    "text": "Problem statement\nImage of Koala Text: Koalas (Phascolarctos cinereus) in South East Queensland (SEQ) inhabit fragmented eucalypt woodlands and rely heavily on Eucalyptus species for food and shelter. The population is already under pressure from habitat loss, disease (notably chlamydia), and vehicle collisions. Climate change poses additional threats through increased frequency of heatwaves, droughts, and bushfires, which reduce food quality, water availability, and suitable habitat. This workshop set out to apply open source geospatial tools to better understanding how future climate may impact these populations, and how resources can be best directed towards conserving this iconic species.",
    "crumbs": [
      "Session 5",
      "Part 2: Build a Beautiful Map"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ICCB - Open Source Geospatial Tools for Conservation under Climate Change",
    "section": "",
    "text": "This repo contains the materials for the ICCB workshop titled “Open Source Geospatial Tools for Conservation under Climate Change”."
  },
  {
    "objectID": "index.html#sessions",
    "href": "index.html#sessions",
    "title": "ICCB - Open Source Geospatial Tools for Conservation under Climate Change",
    "section": "Sessions",
    "text": "Sessions\n\nIntro to to geospatial data and tools\nDownscaled climate projections\nKoala species distribution modeling\nSpatial conservation planning\nMaking maps with QGIS\n\n\n\n\nWorkshop session outline"
  },
  {
    "objectID": "index.html#about-the-organisers-and-supporters",
    "href": "index.html#about-the-organisers-and-supporters",
    "title": "ICCB - Open Source Geospatial Tools for Conservation under Climate Change",
    "section": "About the organisers and supporters",
    "text": "About the organisers and supporters\n\n\n\n\n\nThis workshop was organised by Geospatial Share, a grassroots group of spatial enthusiasts whose mission is to build a supportive and inclusive community where students, researchers, and professionals can grow their geospatial skills together. See https://brisbane-geocommunity.netlify.app/ for more.\nThis workshop was made possible by generous contributions by members of the following organisations."
  },
  {
    "objectID": "Session 1/session_1_home.html",
    "href": "Session 1/session_1_home.html",
    "title": "Session 1",
    "section": "",
    "text": "Landing page for Session 1.\n\n\n\n Back to top"
  }
]